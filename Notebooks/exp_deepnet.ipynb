{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast-cancer-wisconsin.data.csv  names_test.csv.gz   raw\n",
      "diabetes.csv.gz\t\t\t  names_train.csv.gz  shakespeare.txt.gz\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from collections import Counter\n",
    "\n",
    "import pathlib as plib\n",
    "import pdb\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield val.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globals\n",
    "ROOT = plib.Path(\"/root/fastai/Playground/LUNA\")\n",
    "nRuns = 5 #number of test runs per unit\n",
    "RSEED = 11;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/fastai/Playground/LUNA\n"
     ]
    }
   ],
   "source": [
    "cd $ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/fastai/Playground/LUNA'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['builtins',\n",
       " 'builtins',\n",
       " 'torch',\n",
       " 'torch.nn',\n",
       " 'torch.optim',\n",
       " 'torch.nn.functional',\n",
       " 'numpy',\n",
       " 'matplotlib.pyplot',\n",
       " 'pandas',\n",
       " 'sklearn.externals.joblib',\n",
       " 'pathlib',\n",
       " 'pdb',\n",
       " 'types']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To list all packages imported\n",
    "list(imports())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.Tensor([[1,2,3,4]]).view(4,1)\n",
    "y_data = torch.Tensor([0,0,1,1]).view(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.]]) \n",
      " tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 1.],\n",
      "        [ 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(x_data, '\\n', y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 9)\n",
      "[[-0.294118   0.487437   0.180328  ... -0.53117   -0.0333333  0.       ]\n",
      " [-0.882353  -0.145729   0.0819672 ... -0.766866  -0.666667   1.       ]\n",
      " [-0.0588235  0.839196   0.0491803 ... -0.492741  -0.633333   0.       ]\n",
      " ...\n",
      " [-0.411765   0.21608    0.180328  ... -0.857387  -0.7        1.       ]\n",
      " [-0.882353   0.266332  -0.0163934 ... -0.768574  -0.133333   0.       ]\n",
      " [-0.882353  -0.0653266  0.147541  ... -0.797609  -0.933333   1.       ]]\n"
     ]
    }
   ],
   "source": [
    "fpath_diabetes = '../PytorchStarter/data/diabetes.csv.gz'\n",
    "xy = np.loadtxt(fpath_diabetes, delimiter=',', dtype=np.float32)\n",
    "print(xy.shape); print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8)\n",
      "(759,)\n"
     ]
    }
   ],
   "source": [
    "X = xy[:,:-1]; print(X.shape)\n",
    "y = xy[:,-1]; print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X) #share the same memory \n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data loader [OLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "# class DiabetesDataset(Dataset):\n",
    "#     def __init__(self, ids):\n",
    "#         # Ideally we wouldn't load all data here.\n",
    "#         # Rather, read each file when __getitem__ is called\n",
    "#         xy = np.loadtxt('../data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "#         self.x_data = xy[:,:-1]\n",
    "#         self.y_data = xy[:, -1]\n",
    "        \n",
    "#         self.ids = ids\n",
    "#         self.len = len(ids)\n",
    "\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "#         \"Returns a sample in the format of [x_data[ID], y_data[ID]]\"\n",
    "# #         print(\"idx: \", idx)\n",
    "#         ID = self.ids[idx]\n",
    "#         return self.x_data[ID,:], self.y_data[ID]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LunaCsvDataset [NEW]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Refer to repair_analysis.ipynb for filtering out fraud datasets and relabelling the rest of data   \n",
    "label_dict = {'KGB':0, 'Cracked':1, 'Repaired':2, 'NoPSA':0, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys,os\n",
    "# sys.path.append(os.path.abspath(\"../Scripts/\"))\n",
    "# from data_helpers import LunaCsvDataset, LunaPickleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaCsvDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        #todo: add ids, modify __len__\n",
    "        \"\"\"\n",
    "        - csv_file (string): path to the csv file\n",
    "        - root_dir (string or pathlib.Path object): directory with all the images\n",
    "        - transform (callable, optional): optional transform to be applied to a sample\n",
    "        \"\"\"\n",
    "        all_data = pd.read_csv(csv_file, header=0, index_col=0)\n",
    "        # Filter out fruad datapoints\n",
    "        is_not_fraud = [False if 'Fraud' in all_data.state[i] else True for i in range(len(all_data))]\n",
    "        all_data = all_data[is_not_fraud]        \n",
    "        self.data = np.array(all_data.drop('state', axis=1)) \n",
    "        self.target = np.array(all_data['state'])\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    #todo\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"returns a sample of format (feature 1,...,featureD, class)\"\n",
    "        return (self.data[idx, :], self.target[idx])\n",
    "    \n",
    "    #todo\n",
    "    def set_label_dict(self, new_dict):\n",
    "        self.label_dict = new_dict\n",
    "\n",
    "class LunaPickleDataset(Dataset):\n",
    "    def __init__(self, pk_file, ids, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        - pk_file (string): path to the pickled file\n",
    "        - root_dir (string): directory with all the images\n",
    "        - transform (callable, optional): optional transform to be applied to a sample\n",
    "        \"\"\"\n",
    "        all_data = joblib.load(pk_file) \n",
    "#         is_not_fraud = [False if 'Fraud' in all_data.state[i] else True for i in range(len(all_data))]\n",
    "#         all_data = all_data[is_not_fraud]\n",
    "        self.data = np.array(all_data.drop(['sn', 'state'], axis=1),\n",
    "                            dtype=np.float32) # for compatibility with torch.FloatTensor\n",
    "#         self.label_dict = {'KGB':0, 'Cracked':1, 'Repaired':2, 'NoPSA':0, }\n",
    "        self.targets = np.array(all_data.state, \n",
    "                               dtype=np.int)\n",
    "    \n",
    "        self.ids = ids\n",
    "        self.len = len(self.ids)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"returns a sample of format [ [feature 1,...,featureD], target, idx]\"\n",
    "        ID = self.ids[idx]\n",
    "        sample = (self.data[ID, :], self.targets[ID], idx)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test LunaDataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0_rr', '1_rr', '2_rr', '3_rr', '4_rr', '5_rr', '6_rr', '7_rr', '8_rr',\n",
       "       '9_rr', '10_rr', '11_rr', '12_rr', '13_rr', '14_rr', '15_rr', '16_rr',\n",
       "       '17_rr', '18_rr', '19_rr', '20_rr', '21_rr', '22_rr', '23_rr', '24_rr',\n",
       "       '25_rr', '26_rr', '27_rr', '28_rr', '29_rr', '30_rr', '31_rr', '32_rr',\n",
       "       '33_rr', '34_rr', '35_rr', '36_rr', '37_rr', '38_rr', '39_rr', '40_rr',\n",
       "       '41_rr', '42_rr', '43_rr', '44_rr', '45_rr', '46_rr', '47_rr', '0_rrr',\n",
       "       '1_rrr', '2_rrr', '3_rrr', '4_rrr', '5_rrr', '6_rrr', '7_rrr', '8_rrr',\n",
       "       '9_rrr', '10_rrr', '11_rrr', '12_rrr', '13_rrr', '14_rrr', '15_rrr',\n",
       "       '16_rrr', '17_rrr', '18_rrr', '19_rrr', '20_rrr', '21_rrr', '22_rrr',\n",
       "       '23_rrr', '24_rrr', '25_rrr', '26_rrr', '27_rrr', '28_rrr', '29_rrr',\n",
       "       '30_rrr', '31_rrr', '32_rrr', '33_rrr', '34_rrr', '35_rrr', '36_rrr',\n",
       "       '37_rrr', '38_rrr', '39_rrr', '40_rrr', '41_rrr', '42_rrr', '43_rrr',\n",
       "       '44_rrr', '45_rrr', '46_rrr', '47_rrr', 'sn', 'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath_luna = ROOT/'Data/DataMatrix/D_rr_rrr.csv'\n",
    "d = pd.read_csv(fpath_luna, header=0, index_col=0);\n",
    "d.columns\n",
    "dataset = LunaCsvDataset(fpath_luna ,root_dir=ROOT)\n",
    "print(dataset.data.shape, dataset.target.shape)\n",
    "print('labels: ', np.unique(dataset.target))\n",
    "print('11th sample: ', dataset[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Luna data without fraud units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = ROOT/'Data/DataMatrix/D_rr_rrr_noFraud.pkl' #0: KGB or NoPSA, 1: Cracked, 2: BadRepair\n",
    "# fpath = ROOT/'Data/DataMatrix/D_rr_rrr_only_kgb_cracked.pkl' #0:KGB, 1:Cracked\n",
    "fpath = ROOT/'Data/DataMatrix/D_rr_rrr_only_kgb_badrepair.pkl' #0:KGB, 1:BadRepair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Luna data with ONLY kgb and badrepair info\n",
      "data and target sizes:  (507, 96) (507,)\n",
      "Labels:  [0 2]\n"
     ]
    }
   ],
   "source": [
    "d = joblib.load(ROOT/fpath)\n",
    "dataset = LunaPickleDataset(fpath, range(len(d)), root_dir=ROOT) #load entire dataset\n",
    "print(\"Loaded Luna data with ONLY kgb and badrepair info\")\n",
    "print(\"data and target sizes: \", dataset.data.shape, dataset.target.shape)\n",
    "print(\"Labels: \", np.unique(dataset.target)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the kgb-badrepair data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean and variance from all kgb samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: 372\n",
      "class 2: 135\n"
     ]
    }
   ],
   "source": [
    "for name, g in d.groupby('state'):\n",
    "    print(f\"class {int(name)}: {g.state.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372, 96)\n",
      "(96,)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "d_kgb = d[d.state==0].drop(['sn','state'], axis=1); print(d_kgb.shape)\n",
    "mu_kgb = d_kgb.mean(axis=0); print(mu_kgb.shape); #mu_kgb\n",
    "std_kgb = d_kgb.std(axis=0); print(std_kgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizer = transforms.Normalize(mean=mu_kgb, std=std_kgb)\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(d_kgb)\n",
    "#print(scaler.mean_, scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.transform(d.drop(['sn', 'state'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_d = d.copy()\n",
    "scaled_d.iloc[:,:-2] = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_rr</th>\n",
       "      <th>1_rr</th>\n",
       "      <th>2_rr</th>\n",
       "      <th>3_rr</th>\n",
       "      <th>4_rr</th>\n",
       "      <th>5_rr</th>\n",
       "      <th>6_rr</th>\n",
       "      <th>7_rr</th>\n",
       "      <th>8_rr</th>\n",
       "      <th>9_rr</th>\n",
       "      <th>...</th>\n",
       "      <th>40_rrr</th>\n",
       "      <th>41_rrr</th>\n",
       "      <th>42_rrr</th>\n",
       "      <th>43_rrr</th>\n",
       "      <th>44_rrr</th>\n",
       "      <th>45_rrr</th>\n",
       "      <th>46_rrr</th>\n",
       "      <th>47_rrr</th>\n",
       "      <th>sn</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.931533</td>\n",
       "      <td>2.102955</td>\n",
       "      <td>6.210149</td>\n",
       "      <td>3.117742</td>\n",
       "      <td>2.696490</td>\n",
       "      <td>2.425905</td>\n",
       "      <td>2.493749</td>\n",
       "      <td>1.779586</td>\n",
       "      <td>2.878011</td>\n",
       "      <td>2.857698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093967</td>\n",
       "      <td>-0.102755</td>\n",
       "      <td>-0.343265</td>\n",
       "      <td>-0.138225</td>\n",
       "      <td>-0.132029</td>\n",
       "      <td>0.137913</td>\n",
       "      <td>-0.168386</td>\n",
       "      <td>-0.075813</td>\n",
       "      <td>FK3VL2VLJCL6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.810072</td>\n",
       "      <td>-0.453475</td>\n",
       "      <td>-0.411790</td>\n",
       "      <td>-0.121522</td>\n",
       "      <td>-0.390715</td>\n",
       "      <td>-0.645898</td>\n",
       "      <td>-0.573187</td>\n",
       "      <td>-0.586418</td>\n",
       "      <td>-0.699149</td>\n",
       "      <td>1.438080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121667</td>\n",
       "      <td>-0.205135</td>\n",
       "      <td>-0.444325</td>\n",
       "      <td>-0.148888</td>\n",
       "      <td>-0.217568</td>\n",
       "      <td>-0.181909</td>\n",
       "      <td>-0.240998</td>\n",
       "      <td>-0.089408</td>\n",
       "      <td>C39VMC1YJCL7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.444275</td>\n",
       "      <td>1.831775</td>\n",
       "      <td>7.111072</td>\n",
       "      <td>4.575378</td>\n",
       "      <td>4.089973</td>\n",
       "      <td>3.769078</td>\n",
       "      <td>4.501199</td>\n",
       "      <td>2.621409</td>\n",
       "      <td>5.369341</td>\n",
       "      <td>5.491001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117539</td>\n",
       "      <td>-0.193247</td>\n",
       "      <td>-0.389859</td>\n",
       "      <td>-0.144120</td>\n",
       "      <td>-0.205769</td>\n",
       "      <td>-0.172912</td>\n",
       "      <td>-0.228944</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>G0NVN150JCLJ</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-0.491840</td>\n",
       "      <td>-0.104167</td>\n",
       "      <td>-0.293582</td>\n",
       "      <td>-0.164649</td>\n",
       "      <td>-0.513360</td>\n",
       "      <td>-0.343525</td>\n",
       "      <td>-0.577840</td>\n",
       "      <td>-0.315793</td>\n",
       "      <td>-0.570568</td>\n",
       "      <td>-0.665754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059889</td>\n",
       "      <td>0.885310</td>\n",
       "      <td>-0.372617</td>\n",
       "      <td>-0.135244</td>\n",
       "      <td>-0.185002</td>\n",
       "      <td>-0.075759</td>\n",
       "      <td>-0.164602</td>\n",
       "      <td>-0.085176</td>\n",
       "      <td>FK2VQ5TTJCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.988062</td>\n",
       "      <td>-0.476608</td>\n",
       "      <td>-0.885162</td>\n",
       "      <td>-0.691764</td>\n",
       "      <td>-0.696767</td>\n",
       "      <td>-0.932271</td>\n",
       "      <td>-1.221469</td>\n",
       "      <td>-0.901348</td>\n",
       "      <td>-1.056595</td>\n",
       "      <td>-1.127827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105480</td>\n",
       "      <td>-0.143271</td>\n",
       "      <td>-0.383236</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.163893</td>\n",
       "      <td>-0.212574</td>\n",
       "      <td>-0.085267</td>\n",
       "      <td>F17VK4C1JCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-1.217828</td>\n",
       "      <td>-0.554401</td>\n",
       "      <td>-0.886535</td>\n",
       "      <td>-0.625021</td>\n",
       "      <td>-0.843715</td>\n",
       "      <td>-1.192816</td>\n",
       "      <td>-1.354224</td>\n",
       "      <td>-1.058467</td>\n",
       "      <td>-1.140791</td>\n",
       "      <td>-1.135582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103140</td>\n",
       "      <td>0.084072</td>\n",
       "      <td>-0.288756</td>\n",
       "      <td>-0.140267</td>\n",
       "      <td>-0.190331</td>\n",
       "      <td>-0.164269</td>\n",
       "      <td>-0.212860</td>\n",
       "      <td>-0.078226</td>\n",
       "      <td>DNPVLSKCJCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-0.982644</td>\n",
       "      <td>-0.516823</td>\n",
       "      <td>-0.772645</td>\n",
       "      <td>-0.546408</td>\n",
       "      <td>-0.700692</td>\n",
       "      <td>-0.991409</td>\n",
       "      <td>-1.133810</td>\n",
       "      <td>-0.879561</td>\n",
       "      <td>-0.986921</td>\n",
       "      <td>-0.922317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059520</td>\n",
       "      <td>-0.178140</td>\n",
       "      <td>-0.386450</td>\n",
       "      <td>-0.137607</td>\n",
       "      <td>-0.192649</td>\n",
       "      <td>-0.155499</td>\n",
       "      <td>-0.129220</td>\n",
       "      <td>-0.086006</td>\n",
       "      <td>G6TVJ0XUJCLJ</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.859935</td>\n",
       "      <td>0.455642</td>\n",
       "      <td>3.388609</td>\n",
       "      <td>2.869466</td>\n",
       "      <td>1.137428</td>\n",
       "      <td>1.121021</td>\n",
       "      <td>0.868471</td>\n",
       "      <td>0.947952</td>\n",
       "      <td>0.779132</td>\n",
       "      <td>1.335907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119711</td>\n",
       "      <td>-0.194094</td>\n",
       "      <td>-0.427129</td>\n",
       "      <td>-0.147372</td>\n",
       "      <td>-0.213068</td>\n",
       "      <td>-0.177680</td>\n",
       "      <td>-0.235176</td>\n",
       "      <td>-0.088869</td>\n",
       "      <td>F2MVP5CLJCLH</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.827368</td>\n",
       "      <td>0.417818</td>\n",
       "      <td>2.758361</td>\n",
       "      <td>2.153674</td>\n",
       "      <td>0.950922</td>\n",
       "      <td>1.534312</td>\n",
       "      <td>1.387566</td>\n",
       "      <td>1.130540</td>\n",
       "      <td>1.049769</td>\n",
       "      <td>1.658898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097878</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-0.376738</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.156532</td>\n",
       "      <td>-0.170993</td>\n",
       "      <td>-0.141437</td>\n",
       "      <td>-0.088470</td>\n",
       "      <td>G6VVRG07JCLJ</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.605124</td>\n",
       "      <td>-0.224952</td>\n",
       "      <td>0.100056</td>\n",
       "      <td>-0.119018</td>\n",
       "      <td>0.275660</td>\n",
       "      <td>-0.131941</td>\n",
       "      <td>0.264571</td>\n",
       "      <td>-0.167182</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>0.698942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120944</td>\n",
       "      <td>-0.197538</td>\n",
       "      <td>-0.402356</td>\n",
       "      <td>-0.147181</td>\n",
       "      <td>-0.213209</td>\n",
       "      <td>-0.178259</td>\n",
       "      <td>-0.215681</td>\n",
       "      <td>-0.085343</td>\n",
       "      <td>DNQVR0H7JCL9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-1.075973</td>\n",
       "      <td>-0.107299</td>\n",
       "      <td>-0.069349</td>\n",
       "      <td>-0.436939</td>\n",
       "      <td>-0.595849</td>\n",
       "      <td>-0.677410</td>\n",
       "      <td>-0.854722</td>\n",
       "      <td>-0.906743</td>\n",
       "      <td>-0.711780</td>\n",
       "      <td>-0.777570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086517</td>\n",
       "      <td>-0.175815</td>\n",
       "      <td>-0.272897</td>\n",
       "      <td>-0.079196</td>\n",
       "      <td>-0.194467</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.189196</td>\n",
       "      <td>-0.086642</td>\n",
       "      <td>FK1VM89TJCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.428781</td>\n",
       "      <td>-0.264216</td>\n",
       "      <td>-0.613354</td>\n",
       "      <td>-0.631711</td>\n",
       "      <td>-0.493136</td>\n",
       "      <td>-0.777886</td>\n",
       "      <td>-0.734094</td>\n",
       "      <td>-0.856169</td>\n",
       "      <td>-0.508824</td>\n",
       "      <td>-0.655797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102853</td>\n",
       "      <td>-0.081119</td>\n",
       "      <td>0.099172</td>\n",
       "      <td>-0.134623</td>\n",
       "      <td>-0.187003</td>\n",
       "      <td>-0.148707</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>-0.074757</td>\n",
       "      <td>FK4VP392JCL6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4.626893</td>\n",
       "      <td>1.881020</td>\n",
       "      <td>7.534346</td>\n",
       "      <td>3.163560</td>\n",
       "      <td>3.010840</td>\n",
       "      <td>3.697735</td>\n",
       "      <td>3.420169</td>\n",
       "      <td>1.936471</td>\n",
       "      <td>3.886361</td>\n",
       "      <td>2.879675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119380</td>\n",
       "      <td>-0.201845</td>\n",
       "      <td>-0.424896</td>\n",
       "      <td>-0.147004</td>\n",
       "      <td>-0.213720</td>\n",
       "      <td>-0.178218</td>\n",
       "      <td>-0.236713</td>\n",
       "      <td>-0.088930</td>\n",
       "      <td>DNQVRLSDJCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-0.285217</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.090280</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>-0.439697</td>\n",
       "      <td>-0.216353</td>\n",
       "      <td>-0.446804</td>\n",
       "      <td>-0.525933</td>\n",
       "      <td>-0.315758</td>\n",
       "      <td>-0.394554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096762</td>\n",
       "      <td>-0.174947</td>\n",
       "      <td>-0.256687</td>\n",
       "      <td>-0.138829</td>\n",
       "      <td>-0.148563</td>\n",
       "      <td>27.827937</td>\n",
       "      <td>-0.176879</td>\n",
       "      <td>-0.078479</td>\n",
       "      <td>F17VQ2LRJCLG</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2.482609</td>\n",
       "      <td>0.917034</td>\n",
       "      <td>1.806220</td>\n",
       "      <td>0.604668</td>\n",
       "      <td>1.499171</td>\n",
       "      <td>0.755456</td>\n",
       "      <td>0.816113</td>\n",
       "      <td>-0.413977</td>\n",
       "      <td>1.124052</td>\n",
       "      <td>1.049304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120675</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>-0.439113</td>\n",
       "      <td>-0.148366</td>\n",
       "      <td>-0.216552</td>\n",
       "      <td>-0.179887</td>\n",
       "      <td>-0.238795</td>\n",
       "      <td>-0.088857</td>\n",
       "      <td>DNQVN9MJJCL6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-0.925559</td>\n",
       "      <td>-0.542873</td>\n",
       "      <td>-1.042550</td>\n",
       "      <td>-0.588600</td>\n",
       "      <td>-0.853068</td>\n",
       "      <td>-1.031429</td>\n",
       "      <td>-1.119944</td>\n",
       "      <td>-1.017637</td>\n",
       "      <td>-1.206022</td>\n",
       "      <td>-1.228571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101897</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.316577</td>\n",
       "      <td>-0.136666</td>\n",
       "      <td>-0.118975</td>\n",
       "      <td>-0.134651</td>\n",
       "      <td>-0.206776</td>\n",
       "      <td>0.821217</td>\n",
       "      <td>F2LVN55FJCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-0.931642</td>\n",
       "      <td>-0.462275</td>\n",
       "      <td>-0.784649</td>\n",
       "      <td>-0.573981</td>\n",
       "      <td>-0.656839</td>\n",
       "      <td>-0.921936</td>\n",
       "      <td>-1.245861</td>\n",
       "      <td>-0.904010</td>\n",
       "      <td>-0.741092</td>\n",
       "      <td>-0.582446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108907</td>\n",
       "      <td>0.831432</td>\n",
       "      <td>-0.309364</td>\n",
       "      <td>-0.136335</td>\n",
       "      <td>-0.072038</td>\n",
       "      <td>0.803855</td>\n",
       "      <td>-0.197073</td>\n",
       "      <td>-0.068380</td>\n",
       "      <td>G6WVN1Y8JCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-1.000768</td>\n",
       "      <td>-0.472878</td>\n",
       "      <td>-0.850079</td>\n",
       "      <td>-0.282603</td>\n",
       "      <td>-0.838015</td>\n",
       "      <td>-0.826702</td>\n",
       "      <td>-1.004902</td>\n",
       "      <td>-0.711181</td>\n",
       "      <td>-1.193276</td>\n",
       "      <td>-1.166062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355274</td>\n",
       "      <td>-0.191463</td>\n",
       "      <td>-0.253703</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.200547</td>\n",
       "      <td>-0.169853</td>\n",
       "      <td>-0.196894</td>\n",
       "      <td>-0.085423</td>\n",
       "      <td>G6VVV63HJCL6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2.369178</td>\n",
       "      <td>0.935518</td>\n",
       "      <td>2.820109</td>\n",
       "      <td>0.847896</td>\n",
       "      <td>1.691254</td>\n",
       "      <td>1.953322</td>\n",
       "      <td>1.667512</td>\n",
       "      <td>1.290666</td>\n",
       "      <td>2.282400</td>\n",
       "      <td>2.405110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107868</td>\n",
       "      <td>-0.186784</td>\n",
       "      <td>-0.306666</td>\n",
       "      <td>-0.146194</td>\n",
       "      <td>-0.123906</td>\n",
       "      <td>-0.109743</td>\n",
       "      <td>-0.216281</td>\n",
       "      <td>-0.086936</td>\n",
       "      <td>F17VQ544JCLJ</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-0.046901</td>\n",
       "      <td>-0.109149</td>\n",
       "      <td>-0.127031</td>\n",
       "      <td>-0.353464</td>\n",
       "      <td>-0.393173</td>\n",
       "      <td>-0.787888</td>\n",
       "      <td>-0.852924</td>\n",
       "      <td>-0.796092</td>\n",
       "      <td>-0.730354</td>\n",
       "      <td>-1.027411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121677</td>\n",
       "      <td>-0.204826</td>\n",
       "      <td>-0.443120</td>\n",
       "      <td>-0.148763</td>\n",
       "      <td>-0.216801</td>\n",
       "      <td>-0.181811</td>\n",
       "      <td>-0.240735</td>\n",
       "      <td>-0.089338</td>\n",
       "      <td>G6TVNU2UJCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-0.323738</td>\n",
       "      <td>-0.180411</td>\n",
       "      <td>-0.173940</td>\n",
       "      <td>-0.307937</td>\n",
       "      <td>-0.730205</td>\n",
       "      <td>-0.701429</td>\n",
       "      <td>-0.644484</td>\n",
       "      <td>-0.826931</td>\n",
       "      <td>-0.750150</td>\n",
       "      <td>-0.768283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108624</td>\n",
       "      <td>-0.178937</td>\n",
       "      <td>1.821818</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>-0.196479</td>\n",
       "      <td>-0.143266</td>\n",
       "      <td>-0.204579</td>\n",
       "      <td>-0.082357</td>\n",
       "      <td>G6YVQE61JCLH</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.342001</td>\n",
       "      <td>-0.436979</td>\n",
       "      <td>1.712324</td>\n",
       "      <td>0.815682</td>\n",
       "      <td>-0.032057</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>-0.019634</td>\n",
       "      <td>0.030024</td>\n",
       "      <td>0.219035</td>\n",
       "      <td>0.477122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117937</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>-0.396153</td>\n",
       "      <td>-0.145232</td>\n",
       "      <td>-0.160459</td>\n",
       "      <td>-0.158406</td>\n",
       "      <td>-0.204858</td>\n",
       "      <td>-0.087745</td>\n",
       "      <td>DNPVP9GJJCLJ</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-0.482019</td>\n",
       "      <td>-0.253241</td>\n",
       "      <td>0.410555</td>\n",
       "      <td>-0.285169</td>\n",
       "      <td>-0.510689</td>\n",
       "      <td>-0.080628</td>\n",
       "      <td>-0.392118</td>\n",
       "      <td>-0.779264</td>\n",
       "      <td>-0.437377</td>\n",
       "      <td>-0.625359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103711</td>\n",
       "      <td>-0.114373</td>\n",
       "      <td>-0.352826</td>\n",
       "      <td>-0.138087</td>\n",
       "      <td>-0.134099</td>\n",
       "      <td>-0.085666</td>\n",
       "      <td>1.995897</td>\n",
       "      <td>-0.054678</td>\n",
       "      <td>DNPVKWBMJCL9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-0.995587</td>\n",
       "      <td>-0.156970</td>\n",
       "      <td>0.152358</td>\n",
       "      <td>0.152548</td>\n",
       "      <td>-0.153521</td>\n",
       "      <td>-0.042626</td>\n",
       "      <td>0.407227</td>\n",
       "      <td>-0.234226</td>\n",
       "      <td>-0.269014</td>\n",
       "      <td>-0.399903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121100</td>\n",
       "      <td>-0.202855</td>\n",
       "      <td>-0.443674</td>\n",
       "      <td>-0.148812</td>\n",
       "      <td>-0.215764</td>\n",
       "      <td>-0.180151</td>\n",
       "      <td>-0.239507</td>\n",
       "      <td>-0.089356</td>\n",
       "      <td>G0NVM8S3JCLJ</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-0.118679</td>\n",
       "      <td>0.274417</td>\n",
       "      <td>0.660973</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>0.239891</td>\n",
       "      <td>-0.054170</td>\n",
       "      <td>-0.113231</td>\n",
       "      <td>0.399667</td>\n",
       "      <td>0.284454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079918</td>\n",
       "      <td>-0.140322</td>\n",
       "      <td>-0.342007</td>\n",
       "      <td>-0.137795</td>\n",
       "      <td>-0.132990</td>\n",
       "      <td>-0.044132</td>\n",
       "      <td>-0.180444</td>\n",
       "      <td>-0.069680</td>\n",
       "      <td>DNPVP67UJCL6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.055109</td>\n",
       "      <td>1.159169</td>\n",
       "      <td>-0.558682</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.606697</td>\n",
       "      <td>0.517299</td>\n",
       "      <td>-0.746417</td>\n",
       "      <td>-0.748440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117967</td>\n",
       "      <td>-0.174053</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>-0.145405</td>\n",
       "      <td>-0.201124</td>\n",
       "      <td>-0.178551</td>\n",
       "      <td>-0.231478</td>\n",
       "      <td>-0.085815</td>\n",
       "      <td>FK1VPPGUJCLH</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>-0.896599</td>\n",
       "      <td>-0.369476</td>\n",
       "      <td>-0.832634</td>\n",
       "      <td>-0.628020</td>\n",
       "      <td>-0.741386</td>\n",
       "      <td>-0.767646</td>\n",
       "      <td>-1.003386</td>\n",
       "      <td>-0.888129</td>\n",
       "      <td>-0.823391</td>\n",
       "      <td>-0.619519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108031</td>\n",
       "      <td>-0.136343</td>\n",
       "      <td>-0.142981</td>\n",
       "      <td>-0.139626</td>\n",
       "      <td>-0.167119</td>\n",
       "      <td>-0.123055</td>\n",
       "      <td>-0.212270</td>\n",
       "      <td>-0.082201</td>\n",
       "      <td>G6TVLLRSJCLJ</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.207102</td>\n",
       "      <td>-0.133413</td>\n",
       "      <td>-0.157785</td>\n",
       "      <td>0.149749</td>\n",
       "      <td>0.047976</td>\n",
       "      <td>-0.093626</td>\n",
       "      <td>0.043874</td>\n",
       "      <td>-0.592760</td>\n",
       "      <td>0.675596</td>\n",
       "      <td>0.822834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070786</td>\n",
       "      <td>-0.030608</td>\n",
       "      <td>-0.402644</td>\n",
       "      <td>-0.145096</td>\n",
       "      <td>-0.197767</td>\n",
       "      <td>-0.173037</td>\n",
       "      <td>-0.223091</td>\n",
       "      <td>-0.087076</td>\n",
       "      <td>F17VM7BJJCL9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-0.864571</td>\n",
       "      <td>-0.113717</td>\n",
       "      <td>0.365128</td>\n",
       "      <td>-0.363675</td>\n",
       "      <td>-0.510735</td>\n",
       "      <td>-0.831666</td>\n",
       "      <td>-0.669051</td>\n",
       "      <td>-0.689147</td>\n",
       "      <td>-0.084372</td>\n",
       "      <td>-0.633372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121457</td>\n",
       "      <td>-0.204866</td>\n",
       "      <td>-0.444229</td>\n",
       "      <td>-0.148865</td>\n",
       "      <td>-0.217371</td>\n",
       "      <td>-0.181933</td>\n",
       "      <td>-0.240945</td>\n",
       "      <td>-0.089417</td>\n",
       "      <td>F2LVRMF9JCL8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.514055</td>\n",
       "      <td>0.128387</td>\n",
       "      <td>0.622481</td>\n",
       "      <td>0.326019</td>\n",
       "      <td>-0.172758</td>\n",
       "      <td>0.130129</td>\n",
       "      <td>0.332284</td>\n",
       "      <td>-0.410939</td>\n",
       "      <td>0.124537</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087063</td>\n",
       "      <td>0.491221</td>\n",
       "      <td>-0.089057</td>\n",
       "      <td>-0.115810</td>\n",
       "      <td>-0.026820</td>\n",
       "      <td>-0.102517</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>-0.083579</td>\n",
       "      <td>F18VQX5EJCL6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>-1.114516</td>\n",
       "      <td>-0.527332</td>\n",
       "      <td>-0.777997</td>\n",
       "      <td>-0.543912</td>\n",
       "      <td>-0.610209</td>\n",
       "      <td>-1.248412</td>\n",
       "      <td>-1.014072</td>\n",
       "      <td>-1.013719</td>\n",
       "      <td>-0.889747</td>\n",
       "      <td>-0.692027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101825</td>\n",
       "      <td>-0.018660</td>\n",
       "      <td>-0.318343</td>\n",
       "      <td>-0.010661</td>\n",
       "      <td>-0.180407</td>\n",
       "      <td>-0.162043</td>\n",
       "      <td>-0.172675</td>\n",
       "      <td>18.795826</td>\n",
       "      <td>G6VVLC0ZJCL9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>-0.117095</td>\n",
       "      <td>0.098559</td>\n",
       "      <td>-0.154451</td>\n",
       "      <td>-0.419520</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>-0.214558</td>\n",
       "      <td>-0.270649</td>\n",
       "      <td>-0.145085</td>\n",
       "      <td>-0.011604</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102368</td>\n",
       "      <td>-0.174793</td>\n",
       "      <td>-0.344733</td>\n",
       "      <td>-0.123374</td>\n",
       "      <td>-0.178232</td>\n",
       "      <td>0.215602</td>\n",
       "      <td>-0.139916</td>\n",
       "      <td>-0.086108</td>\n",
       "      <td>G0PVT98PJCLJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.291533</td>\n",
       "      <td>0.816940</td>\n",
       "      <td>0.416752</td>\n",
       "      <td>0.543318</td>\n",
       "      <td>1.057591</td>\n",
       "      <td>-0.070080</td>\n",
       "      <td>0.254445</td>\n",
       "      <td>-0.342067</td>\n",
       "      <td>0.134545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096409</td>\n",
       "      <td>-0.157459</td>\n",
       "      <td>0.269025</td>\n",
       "      <td>-0.136090</td>\n",
       "      <td>-0.166585</td>\n",
       "      <td>-0.117926</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.081197</td>\n",
       "      <td>DNQVR8ZAJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.390581</td>\n",
       "      <td>0.202563</td>\n",
       "      <td>0.954557</td>\n",
       "      <td>0.232518</td>\n",
       "      <td>0.538187</td>\n",
       "      <td>0.418066</td>\n",
       "      <td>0.639856</td>\n",
       "      <td>0.317645</td>\n",
       "      <td>1.028062</td>\n",
       "      <td>0.552213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098113</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.092197</td>\n",
       "      <td>-0.115212</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.104496</td>\n",
       "      <td>-0.204370</td>\n",
       "      <td>-0.033137</td>\n",
       "      <td>F2MVPRBNJCL9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-0.973795</td>\n",
       "      <td>-0.582570</td>\n",
       "      <td>-0.867261</td>\n",
       "      <td>-0.683932</td>\n",
       "      <td>-0.816716</td>\n",
       "      <td>-0.853473</td>\n",
       "      <td>-0.842360</td>\n",
       "      <td>-0.536695</td>\n",
       "      <td>-1.049340</td>\n",
       "      <td>-0.955088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100478</td>\n",
       "      <td>-0.113703</td>\n",
       "      <td>-0.364673</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>-0.170359</td>\n",
       "      <td>-0.161535</td>\n",
       "      <td>-0.144043</td>\n",
       "      <td>-0.084871</td>\n",
       "      <td>F17VMG48JCLH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>-0.408153</td>\n",
       "      <td>-0.308335</td>\n",
       "      <td>-0.859958</td>\n",
       "      <td>-0.855260</td>\n",
       "      <td>-0.373376</td>\n",
       "      <td>-0.332903</td>\n",
       "      <td>-0.567652</td>\n",
       "      <td>-0.319645</td>\n",
       "      <td>-0.480720</td>\n",
       "      <td>-0.606785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106917</td>\n",
       "      <td>0.098921</td>\n",
       "      <td>-0.331408</td>\n",
       "      <td>-0.114596</td>\n",
       "      <td>-0.158331</td>\n",
       "      <td>-0.157826</td>\n",
       "      <td>-0.187064</td>\n",
       "      <td>-0.068372</td>\n",
       "      <td>F17VK09UJCLH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>-0.071362</td>\n",
       "      <td>0.105233</td>\n",
       "      <td>-0.055159</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>-0.162996</td>\n",
       "      <td>-0.240980</td>\n",
       "      <td>-0.151142</td>\n",
       "      <td>0.515596</td>\n",
       "      <td>-0.375092</td>\n",
       "      <td>-0.287314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100935</td>\n",
       "      <td>-0.144269</td>\n",
       "      <td>-0.313931</td>\n",
       "      <td>-0.136194</td>\n",
       "      <td>-0.167465</td>\n",
       "      <td>-0.111722</td>\n",
       "      <td>0.152280</td>\n",
       "      <td>-0.069776</td>\n",
       "      <td>F2LW1X2QJCLJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>0.589790</td>\n",
       "      <td>0.083567</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.297730</td>\n",
       "      <td>0.516384</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>0.221391</td>\n",
       "      <td>0.399644</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083945</td>\n",
       "      <td>0.663544</td>\n",
       "      <td>-0.254440</td>\n",
       "      <td>-0.113448</td>\n",
       "      <td>-0.147587</td>\n",
       "      <td>-0.160641</td>\n",
       "      <td>-0.106131</td>\n",
       "      <td>-0.082686</td>\n",
       "      <td>G0NVTSUJJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>1.503270</td>\n",
       "      <td>0.257579</td>\n",
       "      <td>0.356917</td>\n",
       "      <td>0.868089</td>\n",
       "      <td>0.404768</td>\n",
       "      <td>0.540736</td>\n",
       "      <td>0.868468</td>\n",
       "      <td>1.526626</td>\n",
       "      <td>0.816863</td>\n",
       "      <td>0.094637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092696</td>\n",
       "      <td>-0.163720</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>-0.134187</td>\n",
       "      <td>-0.166405</td>\n",
       "      <td>-0.055475</td>\n",
       "      <td>-0.140503</td>\n",
       "      <td>-0.083817</td>\n",
       "      <td>G6TVT9FAJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1.467254</td>\n",
       "      <td>1.158162</td>\n",
       "      <td>2.914822</td>\n",
       "      <td>1.166177</td>\n",
       "      <td>1.130718</td>\n",
       "      <td>1.097427</td>\n",
       "      <td>1.670953</td>\n",
       "      <td>1.827644</td>\n",
       "      <td>0.989679</td>\n",
       "      <td>0.849687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>-0.128336</td>\n",
       "      <td>-0.111164</td>\n",
       "      <td>-0.123668</td>\n",
       "      <td>-0.148740</td>\n",
       "      <td>-0.145325</td>\n",
       "      <td>-0.109837</td>\n",
       "      <td>-0.083111</td>\n",
       "      <td>F17VR4CEJCLH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2.153365</td>\n",
       "      <td>0.755824</td>\n",
       "      <td>2.234517</td>\n",
       "      <td>1.531406</td>\n",
       "      <td>1.284152</td>\n",
       "      <td>1.481242</td>\n",
       "      <td>2.433410</td>\n",
       "      <td>2.217365</td>\n",
       "      <td>2.037226</td>\n",
       "      <td>2.307967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021116</td>\n",
       "      <td>-0.146865</td>\n",
       "      <td>-0.329483</td>\n",
       "      <td>-0.138939</td>\n",
       "      <td>-0.175885</td>\n",
       "      <td>0.309375</td>\n",
       "      <td>-0.178527</td>\n",
       "      <td>-0.084062</td>\n",
       "      <td>C39VTTDHJCLH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-1.077493</td>\n",
       "      <td>-0.573080</td>\n",
       "      <td>-0.893232</td>\n",
       "      <td>-0.657443</td>\n",
       "      <td>-0.819092</td>\n",
       "      <td>-0.903509</td>\n",
       "      <td>-1.148579</td>\n",
       "      <td>-0.949466</td>\n",
       "      <td>-1.248528</td>\n",
       "      <td>-1.135180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061757</td>\n",
       "      <td>0.121195</td>\n",
       "      <td>-0.274607</td>\n",
       "      <td>-0.120885</td>\n",
       "      <td>-0.056983</td>\n",
       "      <td>-0.149064</td>\n",
       "      <td>-0.201769</td>\n",
       "      <td>-0.083928</td>\n",
       "      <td>FK1VQ13DJCL7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-0.950846</td>\n",
       "      <td>-0.139161</td>\n",
       "      <td>-0.512186</td>\n",
       "      <td>-0.449462</td>\n",
       "      <td>-0.821767</td>\n",
       "      <td>-0.710636</td>\n",
       "      <td>-0.980205</td>\n",
       "      <td>-0.603415</td>\n",
       "      <td>-0.743631</td>\n",
       "      <td>-0.837202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111130</td>\n",
       "      <td>-0.154350</td>\n",
       "      <td>-0.364290</td>\n",
       "      <td>-0.126382</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>-0.160208</td>\n",
       "      <td>-0.124738</td>\n",
       "      <td>-0.076729</td>\n",
       "      <td>DNQVT61RJCL7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>-1.296925</td>\n",
       "      <td>-0.632643</td>\n",
       "      <td>-1.101004</td>\n",
       "      <td>-0.656233</td>\n",
       "      <td>-0.927398</td>\n",
       "      <td>-1.180722</td>\n",
       "      <td>-1.390699</td>\n",
       "      <td>-1.091271</td>\n",
       "      <td>-1.183917</td>\n",
       "      <td>-1.218565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103848</td>\n",
       "      <td>-0.180075</td>\n",
       "      <td>-0.379917</td>\n",
       "      <td>-0.143719</td>\n",
       "      <td>-0.164509</td>\n",
       "      <td>-0.163442</td>\n",
       "      <td>-0.197631</td>\n",
       "      <td>-0.082260</td>\n",
       "      <td>F2MVQCFFJCL6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.384807</td>\n",
       "      <td>0.279770</td>\n",
       "      <td>0.298769</td>\n",
       "      <td>0.055351</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>-0.022336</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>-0.215643</td>\n",
       "      <td>-0.326474</td>\n",
       "      <td>0.068319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037617</td>\n",
       "      <td>-0.123617</td>\n",
       "      <td>0.756721</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>-0.016874</td>\n",
       "      <td>-0.142777</td>\n",
       "      <td>-0.192082</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>F2LVRH2EJCL9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.682195</td>\n",
       "      <td>0.265778</td>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.919597</td>\n",
       "      <td>0.135152</td>\n",
       "      <td>0.592071</td>\n",
       "      <td>0.395589</td>\n",
       "      <td>0.829902</td>\n",
       "      <td>0.415508</td>\n",
       "      <td>0.784766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093540</td>\n",
       "      <td>-0.165959</td>\n",
       "      <td>0.271095</td>\n",
       "      <td>-0.136651</td>\n",
       "      <td>-0.102223</td>\n",
       "      <td>0.141439</td>\n",
       "      <td>0.195586</td>\n",
       "      <td>-0.065108</td>\n",
       "      <td>DNQVWJKUJCLH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-1.080406</td>\n",
       "      <td>-0.464258</td>\n",
       "      <td>-0.775505</td>\n",
       "      <td>-0.535795</td>\n",
       "      <td>-0.808931</td>\n",
       "      <td>-1.035788</td>\n",
       "      <td>-1.268661</td>\n",
       "      <td>-0.880178</td>\n",
       "      <td>-0.888921</td>\n",
       "      <td>-0.954110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098195</td>\n",
       "      <td>-0.174630</td>\n",
       "      <td>-0.371570</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>-0.143877</td>\n",
       "      <td>-0.151384</td>\n",
       "      <td>-0.199785</td>\n",
       "      <td>-0.083173</td>\n",
       "      <td>G0NVQCUNJCLJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>-0.364960</td>\n",
       "      <td>-0.198177</td>\n",
       "      <td>-0.075487</td>\n",
       "      <td>-0.158294</td>\n",
       "      <td>0.047601</td>\n",
       "      <td>-0.438332</td>\n",
       "      <td>-0.636311</td>\n",
       "      <td>-0.292515</td>\n",
       "      <td>0.294651</td>\n",
       "      <td>-0.221169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053741</td>\n",
       "      <td>-0.140726</td>\n",
       "      <td>-0.378458</td>\n",
       "      <td>-0.142471</td>\n",
       "      <td>-0.162392</td>\n",
       "      <td>-0.127912</td>\n",
       "      <td>-0.181571</td>\n",
       "      <td>-0.082764</td>\n",
       "      <td>F2LVPR6NJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.152928</td>\n",
       "      <td>0.185546</td>\n",
       "      <td>0.670542</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>0.231764</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>0.635903</td>\n",
       "      <td>0.637913</td>\n",
       "      <td>0.353445</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.084788</td>\n",
       "      <td>-0.282943</td>\n",
       "      <td>2.721884</td>\n",
       "      <td>-0.150358</td>\n",
       "      <td>-0.133230</td>\n",
       "      <td>-0.186939</td>\n",
       "      <td>-0.073226</td>\n",
       "      <td>DNQVTPPBJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>-1.197859</td>\n",
       "      <td>-0.582051</td>\n",
       "      <td>-0.910368</td>\n",
       "      <td>-0.622947</td>\n",
       "      <td>-0.767159</td>\n",
       "      <td>-1.067248</td>\n",
       "      <td>-1.217328</td>\n",
       "      <td>-1.047384</td>\n",
       "      <td>-1.087437</td>\n",
       "      <td>-0.921782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068340</td>\n",
       "      <td>-0.166982</td>\n",
       "      <td>-0.288180</td>\n",
       "      <td>-0.138699</td>\n",
       "      <td>-0.064075</td>\n",
       "      <td>-0.139945</td>\n",
       "      <td>-0.151143</td>\n",
       "      <td>-0.081066</td>\n",
       "      <td>C39VM8V4JCLF</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.073754</td>\n",
       "      <td>-0.554064</td>\n",
       "      <td>-0.532087</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.363374</td>\n",
       "      <td>0.143957</td>\n",
       "      <td>0.028957</td>\n",
       "      <td>0.409975</td>\n",
       "      <td>0.194234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108674</td>\n",
       "      <td>-0.173003</td>\n",
       "      <td>-0.267840</td>\n",
       "      <td>-0.107651</td>\n",
       "      <td>-0.178040</td>\n",
       "      <td>0.313237</td>\n",
       "      <td>-0.189931</td>\n",
       "      <td>-0.074633</td>\n",
       "      <td>F17VPJ2TJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>-0.245619</td>\n",
       "      <td>-0.120680</td>\n",
       "      <td>0.083632</td>\n",
       "      <td>-0.204955</td>\n",
       "      <td>-0.373384</td>\n",
       "      <td>-0.184843</td>\n",
       "      <td>-0.278121</td>\n",
       "      <td>-0.185237</td>\n",
       "      <td>-0.284848</td>\n",
       "      <td>-0.294790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106904</td>\n",
       "      <td>-0.165610</td>\n",
       "      <td>-0.358985</td>\n",
       "      <td>-0.141520</td>\n",
       "      <td>-0.144199</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>-0.189262</td>\n",
       "      <td>-0.083990</td>\n",
       "      <td>FK3VQ6GYJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.390006</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.260478</td>\n",
       "      <td>0.327370</td>\n",
       "      <td>-0.112497</td>\n",
       "      <td>0.571731</td>\n",
       "      <td>0.714081</td>\n",
       "      <td>0.471396</td>\n",
       "      <td>-0.031899</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092339</td>\n",
       "      <td>-0.161893</td>\n",
       "      <td>-0.360376</td>\n",
       "      <td>-0.102105</td>\n",
       "      <td>-0.177170</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>1.751201</td>\n",
       "      <td>-0.082724</td>\n",
       "      <td>DNPVMTP6JCL7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>-0.888356</td>\n",
       "      <td>-0.604147</td>\n",
       "      <td>-1.015125</td>\n",
       "      <td>-0.760687</td>\n",
       "      <td>-0.646364</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.612045</td>\n",
       "      <td>-1.070949</td>\n",
       "      <td>-0.958372</td>\n",
       "      <td>-1.095059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094002</td>\n",
       "      <td>-0.181015</td>\n",
       "      <td>-0.272561</td>\n",
       "      <td>-0.139828</td>\n",
       "      <td>-0.190698</td>\n",
       "      <td>-0.161311</td>\n",
       "      <td>-0.204561</td>\n",
       "      <td>-0.072865</td>\n",
       "      <td>FK1VMP9XJCLH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>-0.186496</td>\n",
       "      <td>-0.320050</td>\n",
       "      <td>-0.680582</td>\n",
       "      <td>-0.331381</td>\n",
       "      <td>-0.422830</td>\n",
       "      <td>-0.360773</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>-0.333088</td>\n",
       "      <td>-0.595701</td>\n",
       "      <td>-0.418847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109882</td>\n",
       "      <td>-0.153134</td>\n",
       "      <td>0.023717</td>\n",
       "      <td>-0.091905</td>\n",
       "      <td>-0.181418</td>\n",
       "      <td>-0.157575</td>\n",
       "      <td>-0.107311</td>\n",
       "      <td>-0.084562</td>\n",
       "      <td>FK3VL2N5JCL6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>-1.114189</td>\n",
       "      <td>-0.569306</td>\n",
       "      <td>-0.799527</td>\n",
       "      <td>-0.511810</td>\n",
       "      <td>-0.702974</td>\n",
       "      <td>-1.143826</td>\n",
       "      <td>-1.197490</td>\n",
       "      <td>-0.865041</td>\n",
       "      <td>-1.068059</td>\n",
       "      <td>-1.021924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111627</td>\n",
       "      <td>-0.141243</td>\n",
       "      <td>-0.320139</td>\n",
       "      <td>-0.140981</td>\n",
       "      <td>-0.193023</td>\n",
       "      <td>-0.132044</td>\n",
       "      <td>-0.206185</td>\n",
       "      <td>-0.084702</td>\n",
       "      <td>F2MVM98FJCLJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.178382</td>\n",
       "      <td>-0.241389</td>\n",
       "      <td>-0.861680</td>\n",
       "      <td>-0.519134</td>\n",
       "      <td>-0.315002</td>\n",
       "      <td>-0.146169</td>\n",
       "      <td>-0.130714</td>\n",
       "      <td>-0.491759</td>\n",
       "      <td>-0.513878</td>\n",
       "      <td>-0.341238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098825</td>\n",
       "      <td>-0.177289</td>\n",
       "      <td>-0.357447</td>\n",
       "      <td>-0.135941</td>\n",
       "      <td>-0.183197</td>\n",
       "      <td>-0.156282</td>\n",
       "      <td>-0.115766</td>\n",
       "      <td>-0.082493</td>\n",
       "      <td>F2NVP4LNJCL6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>-0.188188</td>\n",
       "      <td>-0.171788</td>\n",
       "      <td>-0.450567</td>\n",
       "      <td>-0.407481</td>\n",
       "      <td>-0.199935</td>\n",
       "      <td>0.172380</td>\n",
       "      <td>-0.327507</td>\n",
       "      <td>-0.793090</td>\n",
       "      <td>-0.449965</td>\n",
       "      <td>-0.607267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109056</td>\n",
       "      <td>-0.156475</td>\n",
       "      <td>-0.283821</td>\n",
       "      <td>-0.140199</td>\n",
       "      <td>-0.153228</td>\n",
       "      <td>1.661736</td>\n",
       "      <td>-0.208782</td>\n",
       "      <td>-0.085911</td>\n",
       "      <td>DNQVMB2AJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.035735</td>\n",
       "      <td>-0.264979</td>\n",
       "      <td>0.593047</td>\n",
       "      <td>0.719269</td>\n",
       "      <td>-0.207199</td>\n",
       "      <td>-0.127417</td>\n",
       "      <td>-0.220232</td>\n",
       "      <td>-0.237686</td>\n",
       "      <td>0.134450</td>\n",
       "      <td>-0.351551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108958</td>\n",
       "      <td>-0.050146</td>\n",
       "      <td>-0.188895</td>\n",
       "      <td>-0.135780</td>\n",
       "      <td>-0.170496</td>\n",
       "      <td>-0.157207</td>\n",
       "      <td>-0.199011</td>\n",
       "      <td>-0.085167</td>\n",
       "      <td>F17VL8SKJCL8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>-0.780262</td>\n",
       "      <td>-0.339217</td>\n",
       "      <td>-0.755094</td>\n",
       "      <td>-0.536258</td>\n",
       "      <td>-0.739777</td>\n",
       "      <td>-0.574125</td>\n",
       "      <td>-1.219266</td>\n",
       "      <td>-0.774758</td>\n",
       "      <td>-1.176376</td>\n",
       "      <td>-1.117278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107028</td>\n",
       "      <td>-0.150693</td>\n",
       "      <td>-0.308109</td>\n",
       "      <td>-0.063215</td>\n",
       "      <td>-0.184759</td>\n",
       "      <td>-0.163797</td>\n",
       "      <td>-0.034948</td>\n",
       "      <td>-0.031915</td>\n",
       "      <td>F17VRYDXJCL9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows  98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0_rr      1_rr      2_rr      3_rr      4_rr      5_rr      6_rr  \\\n",
       "104  5.931533  2.102955  6.210149  3.117742  2.696490  2.425905  2.493749   \n",
       "105 -0.810072 -0.453475 -0.411790 -0.121522 -0.390715 -0.645898 -0.573187   \n",
       "106  5.444275  1.831775  7.111072  4.575378  4.089973  3.769078  4.501199   \n",
       "107 -0.491840 -0.104167 -0.293582 -0.164649 -0.513360 -0.343525 -0.577840   \n",
       "108 -0.988062 -0.476608 -0.885162 -0.691764 -0.696767 -0.932271 -1.221469   \n",
       "109 -1.217828 -0.554401 -0.886535 -0.625021 -0.843715 -1.192816 -1.354224   \n",
       "110 -0.982644 -0.516823 -0.772645 -0.546408 -0.700692 -0.991409 -1.133810   \n",
       "111  0.859935  0.455642  3.388609  2.869466  1.137428  1.121021  0.868471   \n",
       "112  1.827368  0.417818  2.758361  2.153674  0.950922  1.534312  1.387566   \n",
       "113 -0.605124 -0.224952  0.100056 -0.119018  0.275660 -0.131941  0.264571   \n",
       "114 -1.075973 -0.107299 -0.069349 -0.436939 -0.595849 -0.677410 -0.854722   \n",
       "115 -0.428781 -0.264216 -0.613354 -0.631711 -0.493136 -0.777886 -0.734094   \n",
       "116  4.626893  1.881020  7.534346  3.163560  3.010840  3.697735  3.420169   \n",
       "117 -0.285217  0.040004  0.090280  0.003971 -0.439697 -0.216353 -0.446804   \n",
       "118  2.482609  0.917034  1.806220  0.604668  1.499171  0.755456  0.816113   \n",
       "119 -0.925559 -0.542873 -1.042550 -0.588600 -0.853068 -1.031429 -1.119944   \n",
       "120 -0.931642 -0.462275 -0.784649 -0.573981 -0.656839 -0.921936 -1.245861   \n",
       "121 -1.000768 -0.472878 -0.850079 -0.282603 -0.838015 -0.826702 -1.004902   \n",
       "122  2.369178  0.935518  2.820109  0.847896  1.691254  1.953322  1.667512   \n",
       "123 -0.046901 -0.109149 -0.127031 -0.353464 -0.393173 -0.787888 -0.852924   \n",
       "124 -0.323738 -0.180411 -0.173940 -0.307937 -0.730205 -0.701429 -0.644484   \n",
       "125 -0.342001 -0.436979  1.712324  0.815682 -0.032057  0.439100 -0.019634   \n",
       "126 -0.482019 -0.253241  0.410555 -0.285169 -0.510689 -0.080628 -0.392118   \n",
       "127 -0.995587 -0.156970  0.152358  0.152548 -0.153521 -0.042626  0.407227   \n",
       "128 -0.118679  0.274417  0.660973  0.039800 -0.153029  0.239891 -0.054170   \n",
       "129  0.814000  0.081158  0.055109  1.159169 -0.558682  0.388563  0.606697   \n",
       "130 -0.896599 -0.369476 -0.832634 -0.628020 -0.741386 -0.767646 -1.003386   \n",
       "131  0.207102 -0.133413 -0.157785  0.149749  0.047976 -0.093626  0.043874   \n",
       "132 -0.864571 -0.113717  0.365128 -0.363675 -0.510735 -0.831666 -0.669051   \n",
       "133  0.514055  0.128387  0.622481  0.326019 -0.172758  0.130129  0.332284   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "814 -1.114516 -0.527332 -0.777997 -0.543912 -0.610209 -1.248412 -1.014072   \n",
       "815 -0.117095  0.098559 -0.154451 -0.419520  0.027573 -0.214558 -0.270649   \n",
       "816  0.006165  0.291533  0.816940  0.416752  0.543318  1.057591 -0.070080   \n",
       "817  0.390581  0.202563  0.954557  0.232518  0.538187  0.418066  0.639856   \n",
       "818 -0.973795 -0.582570 -0.867261 -0.683932 -0.816716 -0.853473 -0.842360   \n",
       "819 -0.408153 -0.308335 -0.859958 -0.855260 -0.373376 -0.332903 -0.567652   \n",
       "820 -0.071362  0.105233 -0.055159  0.166100 -0.162996 -0.240980 -0.151142   \n",
       "821  0.589790  0.083567 -0.056929 -0.297730  0.516384  0.785905  0.221391   \n",
       "822  1.503270  0.257579  0.356917  0.868089  0.404768  0.540736  0.868468   \n",
       "823  1.467254  1.158162  2.914822  1.166177  1.130718  1.097427  1.670953   \n",
       "824  2.153365  0.755824  2.234517  1.531406  1.284152  1.481242  2.433410   \n",
       "825 -1.077493 -0.573080 -0.893232 -0.657443 -0.819092 -0.903509 -1.148579   \n",
       "826 -0.950846 -0.139161 -0.512186 -0.449462 -0.821767 -0.710636 -0.980205   \n",
       "827 -1.296925 -0.632643 -1.101004 -0.656233 -0.927398 -1.180722 -1.390699   \n",
       "828  0.384807  0.279770  0.298769  0.055351  0.002772 -0.022336  0.074053   \n",
       "829  0.682195  0.265778  0.664796  0.919597  0.135152  0.592071  0.395589   \n",
       "830 -1.080406 -0.464258 -0.775505 -0.535795 -0.808931 -1.035788 -1.268661   \n",
       "831 -0.364960 -0.198177 -0.075487 -0.158294  0.047601 -0.438332 -0.636311   \n",
       "832  0.152928  0.185546  0.670542  0.057160  0.231764  0.308311  0.635903   \n",
       "833 -1.197859 -0.582051 -0.910368 -0.622947 -0.767159 -1.067248 -1.217328   \n",
       "834  0.010516  0.073754 -0.554064 -0.532087  0.025723  0.363374  0.143957   \n",
       "835 -0.245619 -0.120680  0.083632 -0.204955 -0.373384 -0.184843 -0.278121   \n",
       "836  0.390006  0.037226  0.260478  0.327370 -0.112497  0.571731  0.714081   \n",
       "837 -0.888356 -0.604147 -1.015125 -0.760687 -0.646364 -0.409822 -0.612045   \n",
       "838 -0.186496 -0.320050 -0.680582 -0.331381 -0.422830 -0.360773  0.033352   \n",
       "839 -1.114189 -0.569306 -0.799527 -0.511810 -0.702974 -1.143826 -1.197490   \n",
       "840  0.178382 -0.241389 -0.861680 -0.519134 -0.315002 -0.146169 -0.130714   \n",
       "841 -0.188188 -0.171788 -0.450567 -0.407481 -0.199935  0.172380 -0.327507   \n",
       "842  0.035735 -0.264979  0.593047  0.719269 -0.207199 -0.127417 -0.220232   \n",
       "843 -0.780262 -0.339217 -0.755094 -0.536258 -0.739777 -0.574125 -1.219266   \n",
       "\n",
       "         7_rr      8_rr      9_rr  ...      40_rrr    41_rrr    42_rrr  \\\n",
       "104  1.779586  2.878011  2.857698  ...   -0.093967 -0.102755 -0.343265   \n",
       "105 -0.586418 -0.699149  1.438080  ...   -0.121667 -0.205135 -0.444325   \n",
       "106  2.621409  5.369341  5.491001  ...   -0.117539 -0.193247 -0.389859   \n",
       "107 -0.315793 -0.570568 -0.665754  ...   -0.059889  0.885310 -0.372617   \n",
       "108 -0.901348 -1.056595 -1.127827  ...   -0.105480 -0.143271 -0.383236   \n",
       "109 -1.058467 -1.140791 -1.135582  ...   -0.103140  0.084072 -0.288756   \n",
       "110 -0.879561 -0.986921 -0.922317  ...   -0.059520 -0.178140 -0.386450   \n",
       "111  0.947952  0.779132  1.335907  ...   -0.119711 -0.194094 -0.427129   \n",
       "112  1.130540  1.049769  1.658898  ...   -0.097878 -0.191733 -0.376738   \n",
       "113 -0.167182  0.021776  0.698942  ...   -0.120944 -0.197538 -0.402356   \n",
       "114 -0.906743 -0.711780 -0.777570  ...   -0.086517 -0.175815 -0.272897   \n",
       "115 -0.856169 -0.508824 -0.655797  ...   -0.102853 -0.081119  0.099172   \n",
       "116  1.936471  3.886361  2.879675  ...   -0.119380 -0.201845 -0.424896   \n",
       "117 -0.525933 -0.315758 -0.394554  ...   -0.096762 -0.174947 -0.256687   \n",
       "118 -0.413977  1.124052  1.049304  ...   -0.120675 -0.203484 -0.439113   \n",
       "119 -1.017637 -1.206022 -1.228571  ...   -0.101897 -0.001443 -0.316577   \n",
       "120 -0.904010 -0.741092 -0.582446  ...   -0.108907  0.831432 -0.309364   \n",
       "121 -0.711181 -1.193276 -1.166062  ...    0.355274 -0.191463 -0.253703   \n",
       "122  1.290666  2.282400  2.405110  ...   -0.107868 -0.186784 -0.306666   \n",
       "123 -0.796092 -0.730354 -1.027411  ...   -0.121677 -0.204826 -0.443120   \n",
       "124 -0.826931 -0.750150 -0.768283  ...   -0.108624 -0.178937  1.821818   \n",
       "125  0.030024  0.219035  0.477122  ...   -0.117937  0.031942 -0.396153   \n",
       "126 -0.779264 -0.437377 -0.625359  ...   -0.103711 -0.114373 -0.352826   \n",
       "127 -0.234226 -0.269014 -0.399903  ...   -0.121100 -0.202855 -0.443674   \n",
       "128 -0.113231  0.399667  0.284454  ...   -0.079918 -0.140322 -0.342007   \n",
       "129  0.517299 -0.746417 -0.748440  ...   -0.117967 -0.174053 -0.403236   \n",
       "130 -0.888129 -0.823391 -0.619519  ...   -0.108031 -0.136343 -0.142981   \n",
       "131 -0.592760  0.675596  0.822834  ...    0.070786 -0.030608 -0.402644   \n",
       "132 -0.689147 -0.084372 -0.633372  ...   -0.121457 -0.204866 -0.444229   \n",
       "133 -0.410939  0.124537  0.008204  ...   -0.087063  0.491221 -0.089057   \n",
       "..        ...       ...       ...  ...         ...       ...       ...   \n",
       "814 -1.013719 -0.889747 -0.692027  ...   -0.101825 -0.018660 -0.318343   \n",
       "815 -0.145085 -0.011604  0.006807  ...   -0.102368 -0.174793 -0.344733   \n",
       "816  0.254445 -0.342067  0.134545  ...   -0.096409 -0.157459  0.269025   \n",
       "817  0.317645  1.028062  0.552213  ...   -0.098113 -0.146329 -0.092197   \n",
       "818 -0.536695 -1.049340 -0.955088  ...   -0.100478 -0.113703 -0.364673   \n",
       "819 -0.319645 -0.480720 -0.606785  ...   -0.106917  0.098921 -0.331408   \n",
       "820  0.515596 -0.375092 -0.287314  ...   -0.100935 -0.144269 -0.313931   \n",
       "821  0.399644  0.422036  0.903614  ...   -0.083945  0.663544 -0.254440   \n",
       "822  1.526626  0.816863  0.094637  ...   -0.092696 -0.163720  0.001650   \n",
       "823  1.827644  0.989679  0.849687  ...    0.079700 -0.128336 -0.111164   \n",
       "824  2.217365  2.037226  2.307967  ...   -0.021116 -0.146865 -0.329483   \n",
       "825 -0.949466 -1.248528 -1.135180  ...   -0.061757  0.121195 -0.274607   \n",
       "826 -0.603415 -0.743631 -0.837202  ...   -0.111130 -0.154350 -0.364290   \n",
       "827 -1.091271 -1.183917 -1.218565  ...   -0.103848 -0.180075 -0.379917   \n",
       "828 -0.215643 -0.326474  0.068319  ...   -0.037617 -0.123617  0.756721   \n",
       "829  0.829902  0.415508  0.784766  ...   -0.093540 -0.165959  0.271095   \n",
       "830 -0.880178 -0.888921 -0.954110  ...   -0.098195 -0.174630 -0.371570   \n",
       "831 -0.292515  0.294651 -0.221169  ...   -0.053741 -0.140726 -0.378458   \n",
       "832  0.637913  0.353445  0.043080  ...   -0.094860 -0.084788 -0.282943   \n",
       "833 -1.047384 -1.087437 -0.921782  ...   -0.068340 -0.166982 -0.288180   \n",
       "834  0.028957  0.409975  0.194234  ...   -0.108674 -0.173003 -0.267840   \n",
       "835 -0.185237 -0.284848 -0.294790  ...   -0.106904 -0.165610 -0.358985   \n",
       "836  0.471396 -0.031899  0.128052  ...   -0.092339 -0.161893 -0.360376   \n",
       "837 -1.070949 -0.958372 -1.095059  ...   -0.094002 -0.181015 -0.272561   \n",
       "838 -0.333088 -0.595701 -0.418847  ...   -0.109882 -0.153134  0.023717   \n",
       "839 -0.865041 -1.068059 -1.021924  ...   -0.111627 -0.141243 -0.320139   \n",
       "840 -0.491759 -0.513878 -0.341238  ...   -0.098825 -0.177289 -0.357447   \n",
       "841 -0.793090 -0.449965 -0.607267  ...   -0.109056 -0.156475 -0.283821   \n",
       "842 -0.237686  0.134450 -0.351551  ...   -0.108958 -0.050146 -0.188895   \n",
       "843 -0.774758 -1.176376 -1.117278  ...   -0.107028 -0.150693 -0.308109   \n",
       "\n",
       "       43_rrr    44_rrr     45_rrr    46_rrr     47_rrr            sn  state  \n",
       "104 -0.138225 -0.132029   0.137913 -0.168386  -0.075813  FK3VL2VLJCL6    2.0  \n",
       "105 -0.148888 -0.217568  -0.181909 -0.240998  -0.089408  C39VMC1YJCL7    2.0  \n",
       "106 -0.144120 -0.205769  -0.172912 -0.228944  -0.087976  G0NVN150JCLJ    2.0  \n",
       "107 -0.135244 -0.185002  -0.075759 -0.164602  -0.085176  FK2VQ5TTJCL8    2.0  \n",
       "108 -0.137069 -0.178817  -0.163893 -0.212574  -0.085267  F17VK4C1JCL8    2.0  \n",
       "109 -0.140267 -0.190331  -0.164269 -0.212860  -0.078226  DNPVLSKCJCL8    2.0  \n",
       "110 -0.137607 -0.192649  -0.155499 -0.129220  -0.086006  G6TVJ0XUJCLJ    2.0  \n",
       "111 -0.147372 -0.213068  -0.177680 -0.235176  -0.088869  F2MVP5CLJCLH    2.0  \n",
       "112 -0.136621 -0.156532  -0.170993 -0.141437  -0.088470  G6VVRG07JCLJ    2.0  \n",
       "113 -0.147181 -0.213209  -0.178259 -0.215681  -0.085343  DNQVR0H7JCL9    2.0  \n",
       "114 -0.079196 -0.194467   0.001057 -0.189196  -0.086642  FK1VM89TJCL8    2.0  \n",
       "115 -0.134623 -0.187003  -0.148707  0.036789  -0.074757  FK4VP392JCL6    2.0  \n",
       "116 -0.147004 -0.213720  -0.178218 -0.236713  -0.088930  DNQVRLSDJCL8    2.0  \n",
       "117 -0.138829 -0.148563  27.827937 -0.176879  -0.078479  F17VQ2LRJCLG    2.0  \n",
       "118 -0.148366 -0.216552  -0.179887 -0.238795  -0.088857  DNQVN9MJJCL6    2.0  \n",
       "119 -0.136666 -0.118975  -0.134651 -0.206776   0.821217  F2LVN55FJCL8    2.0  \n",
       "120 -0.136335 -0.072038   0.803855 -0.197073  -0.068380  G6WVN1Y8JCL8    2.0  \n",
       "121 -0.147147 -0.200547  -0.169853 -0.196894  -0.085423  G6VVV63HJCL6    2.0  \n",
       "122 -0.146194 -0.123906  -0.109743 -0.216281  -0.086936  F17VQ544JCLJ    2.0  \n",
       "123 -0.148763 -0.216801  -0.181811 -0.240735  -0.089338  G6TVNU2UJCL8    2.0  \n",
       "124 -0.126195 -0.196479  -0.143266 -0.204579  -0.082357  G6YVQE61JCLH    2.0  \n",
       "125 -0.145232 -0.160459  -0.158406 -0.204858  -0.087745  DNPVP9GJJCLJ    2.0  \n",
       "126 -0.138087 -0.134099  -0.085666  1.995897  -0.054678  DNPVKWBMJCL9    2.0  \n",
       "127 -0.148812 -0.215764  -0.180151 -0.239507  -0.089356  G0NVM8S3JCLJ    2.0  \n",
       "128 -0.137795 -0.132990  -0.044132 -0.180444  -0.069680  DNPVP67UJCL6    2.0  \n",
       "129 -0.145405 -0.201124  -0.178551 -0.231478  -0.085815  FK1VPPGUJCLH    2.0  \n",
       "130 -0.139626 -0.167119  -0.123055 -0.212270  -0.082201  G6TVLLRSJCLJ    2.0  \n",
       "131 -0.145096 -0.197767  -0.173037 -0.223091  -0.087076  F17VM7BJJCL9    2.0  \n",
       "132 -0.148865 -0.217371  -0.181933 -0.240945  -0.089417  F2LVRMF9JCL8    2.0  \n",
       "133 -0.115810 -0.026820  -0.102517  0.165922  -0.083579  F18VQX5EJCL6    2.0  \n",
       "..        ...       ...        ...       ...        ...           ...    ...  \n",
       "814 -0.010661 -0.180407  -0.162043 -0.172675  18.795826  G6VVLC0ZJCL9    0.0  \n",
       "815 -0.123374 -0.178232   0.215602 -0.139916  -0.086108  G0PVT98PJCLJ    0.0  \n",
       "816 -0.136090 -0.166585  -0.117926 -0.144217  -0.081197  DNQVR8ZAJCL8    0.0  \n",
       "817 -0.115212 -0.024371  -0.104496 -0.204370  -0.033137  F2MVPRBNJCL9    0.0  \n",
       "818  0.014268 -0.170359  -0.161535 -0.144043  -0.084871  F17VMG48JCLH    0.0  \n",
       "819 -0.114596 -0.158331  -0.157826 -0.187064  -0.068372  F17VK09UJCLH    0.0  \n",
       "820 -0.136194 -0.167465  -0.111722  0.152280  -0.069776  F2LW1X2QJCLJ    0.0  \n",
       "821 -0.113448 -0.147587  -0.160641 -0.106131  -0.082686  G0NVTSUJJCL8    0.0  \n",
       "822 -0.134187 -0.166405  -0.055475 -0.140503  -0.083817  G6TVT9FAJCL8    0.0  \n",
       "823 -0.123668 -0.148740  -0.145325 -0.109837  -0.083111  F17VR4CEJCLH    0.0  \n",
       "824 -0.138939 -0.175885   0.309375 -0.178527  -0.084062  C39VTTDHJCLH    0.0  \n",
       "825 -0.120885 -0.056983  -0.149064 -0.201769  -0.083928  FK1VQ13DJCL7    0.0  \n",
       "826 -0.126382  0.827890  -0.160208 -0.124738  -0.076729  DNQVT61RJCL7    0.0  \n",
       "827 -0.143719 -0.164509  -0.163442 -0.197631  -0.082260  F2MVQCFFJCL6    0.0  \n",
       "828 -0.136364 -0.016874  -0.142777 -0.192082  -0.009467  F2LVRH2EJCL9    0.0  \n",
       "829 -0.136651 -0.102223   0.141439  0.195586  -0.065108  DNQVWJKUJCLH    0.0  \n",
       "830  0.063533 -0.143877  -0.151384 -0.199785  -0.083173  G0NVQCUNJCLJ    0.0  \n",
       "831 -0.142471 -0.162392  -0.127912 -0.181571  -0.082764  F2LVPR6NJCL8    0.0  \n",
       "832  2.721884 -0.150358  -0.133230 -0.186939  -0.073226  DNQVTPPBJCL8    0.0  \n",
       "833 -0.138699 -0.064075  -0.139945 -0.151143  -0.081066  C39VM8V4JCLF    0.0  \n",
       "834 -0.107651 -0.178040   0.313237 -0.189931  -0.074633  F17VPJ2TJCL8    0.0  \n",
       "835 -0.141520 -0.144199   0.203576 -0.189262  -0.083990  FK3VQ6GYJCL8    0.0  \n",
       "836 -0.102105 -0.177170  -0.003482  1.751201  -0.082724  DNPVMTP6JCL7    0.0  \n",
       "837 -0.139828 -0.190698  -0.161311 -0.204561  -0.072865  FK1VMP9XJCLH    0.0  \n",
       "838 -0.091905 -0.181418  -0.157575 -0.107311  -0.084562  FK3VL2N5JCL6    0.0  \n",
       "839 -0.140981 -0.193023  -0.132044 -0.206185  -0.084702  F2MVM98FJCLJ    0.0  \n",
       "840 -0.135941 -0.183197  -0.156282 -0.115766  -0.082493  F2NVP4LNJCL6    0.0  \n",
       "841 -0.140199 -0.153228   1.661736 -0.208782  -0.085911  DNQVMB2AJCL8    0.0  \n",
       "842 -0.135780 -0.170496  -0.157207 -0.199011  -0.085167  F17VL8SKJCL8    0.0  \n",
       "843 -0.063215 -0.184759  -0.163797 -0.034948  -0.031915  F17VRYDXJCL9    0.0  \n",
       "\n",
       "[507 rows x 98 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/DataMatrix/D_rr_rrr_kgb_badrepair_scaled.pkl']"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaled_d, './Data/DataMatrix/D_rr_rrr_kgb_badrepair_scaled.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load normalized kgb-repaired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Luna data with ONLY kgb and badrepair info\n",
      "data and target sizes:  (507, 96) (507,)\n",
      "Labels:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "fpath = ROOT/'Data/DataMatrix/D_rr_rrr_kgb_badrepair_scaled_binary.pkl'\n",
    "d = joblib.load(ROOT/fpath)\n",
    "dataset = LunaPickleDataset(fpath, range(len(d)), root_dir=ROOT) #load entire dataset\n",
    "print(\"Loaded Luna data with ONLY kgb and badrepair info\")\n",
    "print(\"data and target sizes: \", dataset.data.shape, dataset.targets.shape)\n",
    "print(\"Labels: \", np.unique(dataset.targets)) #0: KGB or NoPSA, 1: BadRepair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if really normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.10144422734369374\n",
      "std:  1.686360767111375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_rr</th>\n",
       "      <th>1_rr</th>\n",
       "      <th>2_rr</th>\n",
       "      <th>3_rr</th>\n",
       "      <th>4_rr</th>\n",
       "      <th>5_rr</th>\n",
       "      <th>6_rr</th>\n",
       "      <th>7_rr</th>\n",
       "      <th>8_rr</th>\n",
       "      <th>9_rr</th>\n",
       "      <th>...</th>\n",
       "      <th>40_rrr</th>\n",
       "      <th>41_rrr</th>\n",
       "      <th>42_rrr</th>\n",
       "      <th>43_rrr</th>\n",
       "      <th>44_rrr</th>\n",
       "      <th>45_rrr</th>\n",
       "      <th>46_rrr</th>\n",
       "      <th>47_rrr</th>\n",
       "      <th>sn</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.931533</td>\n",
       "      <td>2.102955</td>\n",
       "      <td>6.210149</td>\n",
       "      <td>3.117742</td>\n",
       "      <td>2.696490</td>\n",
       "      <td>2.425905</td>\n",
       "      <td>2.493749</td>\n",
       "      <td>1.779586</td>\n",
       "      <td>2.878011</td>\n",
       "      <td>2.857698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093967</td>\n",
       "      <td>-0.102755</td>\n",
       "      <td>-0.343265</td>\n",
       "      <td>-0.138225</td>\n",
       "      <td>-0.132029</td>\n",
       "      <td>0.137913</td>\n",
       "      <td>-0.168386</td>\n",
       "      <td>-0.075813</td>\n",
       "      <td>FK3VL2VLJCL6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.810072</td>\n",
       "      <td>-0.453475</td>\n",
       "      <td>-0.411790</td>\n",
       "      <td>-0.121522</td>\n",
       "      <td>-0.390715</td>\n",
       "      <td>-0.645898</td>\n",
       "      <td>-0.573187</td>\n",
       "      <td>-0.586418</td>\n",
       "      <td>-0.699149</td>\n",
       "      <td>1.438080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121667</td>\n",
       "      <td>-0.205135</td>\n",
       "      <td>-0.444325</td>\n",
       "      <td>-0.148888</td>\n",
       "      <td>-0.217568</td>\n",
       "      <td>-0.181909</td>\n",
       "      <td>-0.240998</td>\n",
       "      <td>-0.089408</td>\n",
       "      <td>C39VMC1YJCL7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.444275</td>\n",
       "      <td>1.831775</td>\n",
       "      <td>7.111072</td>\n",
       "      <td>4.575378</td>\n",
       "      <td>4.089973</td>\n",
       "      <td>3.769078</td>\n",
       "      <td>4.501199</td>\n",
       "      <td>2.621409</td>\n",
       "      <td>5.369341</td>\n",
       "      <td>5.491001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117539</td>\n",
       "      <td>-0.193247</td>\n",
       "      <td>-0.389859</td>\n",
       "      <td>-0.144120</td>\n",
       "      <td>-0.205769</td>\n",
       "      <td>-0.172912</td>\n",
       "      <td>-0.228944</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>G0NVN150JCLJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-0.491840</td>\n",
       "      <td>-0.104167</td>\n",
       "      <td>-0.293582</td>\n",
       "      <td>-0.164649</td>\n",
       "      <td>-0.513360</td>\n",
       "      <td>-0.343525</td>\n",
       "      <td>-0.577840</td>\n",
       "      <td>-0.315793</td>\n",
       "      <td>-0.570568</td>\n",
       "      <td>-0.665754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059889</td>\n",
       "      <td>0.885310</td>\n",
       "      <td>-0.372617</td>\n",
       "      <td>-0.135244</td>\n",
       "      <td>-0.185002</td>\n",
       "      <td>-0.075759</td>\n",
       "      <td>-0.164602</td>\n",
       "      <td>-0.085176</td>\n",
       "      <td>FK2VQ5TTJCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.988062</td>\n",
       "      <td>-0.476608</td>\n",
       "      <td>-0.885162</td>\n",
       "      <td>-0.691764</td>\n",
       "      <td>-0.696767</td>\n",
       "      <td>-0.932271</td>\n",
       "      <td>-1.221469</td>\n",
       "      <td>-0.901348</td>\n",
       "      <td>-1.056595</td>\n",
       "      <td>-1.127827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105480</td>\n",
       "      <td>-0.143271</td>\n",
       "      <td>-0.383236</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.163893</td>\n",
       "      <td>-0.212574</td>\n",
       "      <td>-0.085267</td>\n",
       "      <td>F17VK4C1JCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-1.217828</td>\n",
       "      <td>-0.554401</td>\n",
       "      <td>-0.886535</td>\n",
       "      <td>-0.625021</td>\n",
       "      <td>-0.843715</td>\n",
       "      <td>-1.192816</td>\n",
       "      <td>-1.354224</td>\n",
       "      <td>-1.058467</td>\n",
       "      <td>-1.140791</td>\n",
       "      <td>-1.135582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103140</td>\n",
       "      <td>0.084072</td>\n",
       "      <td>-0.288756</td>\n",
       "      <td>-0.140267</td>\n",
       "      <td>-0.190331</td>\n",
       "      <td>-0.164269</td>\n",
       "      <td>-0.212860</td>\n",
       "      <td>-0.078226</td>\n",
       "      <td>DNPVLSKCJCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-0.982644</td>\n",
       "      <td>-0.516823</td>\n",
       "      <td>-0.772645</td>\n",
       "      <td>-0.546408</td>\n",
       "      <td>-0.700692</td>\n",
       "      <td>-0.991409</td>\n",
       "      <td>-1.133810</td>\n",
       "      <td>-0.879561</td>\n",
       "      <td>-0.986921</td>\n",
       "      <td>-0.922317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059520</td>\n",
       "      <td>-0.178140</td>\n",
       "      <td>-0.386450</td>\n",
       "      <td>-0.137607</td>\n",
       "      <td>-0.192649</td>\n",
       "      <td>-0.155499</td>\n",
       "      <td>-0.129220</td>\n",
       "      <td>-0.086006</td>\n",
       "      <td>G6TVJ0XUJCLJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.859935</td>\n",
       "      <td>0.455642</td>\n",
       "      <td>3.388609</td>\n",
       "      <td>2.869466</td>\n",
       "      <td>1.137428</td>\n",
       "      <td>1.121021</td>\n",
       "      <td>0.868471</td>\n",
       "      <td>0.947952</td>\n",
       "      <td>0.779132</td>\n",
       "      <td>1.335907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119711</td>\n",
       "      <td>-0.194094</td>\n",
       "      <td>-0.427129</td>\n",
       "      <td>-0.147372</td>\n",
       "      <td>-0.213068</td>\n",
       "      <td>-0.177680</td>\n",
       "      <td>-0.235176</td>\n",
       "      <td>-0.088869</td>\n",
       "      <td>F2MVP5CLJCLH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.827368</td>\n",
       "      <td>0.417818</td>\n",
       "      <td>2.758361</td>\n",
       "      <td>2.153674</td>\n",
       "      <td>0.950922</td>\n",
       "      <td>1.534312</td>\n",
       "      <td>1.387566</td>\n",
       "      <td>1.130540</td>\n",
       "      <td>1.049769</td>\n",
       "      <td>1.658898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097878</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-0.376738</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.156532</td>\n",
       "      <td>-0.170993</td>\n",
       "      <td>-0.141437</td>\n",
       "      <td>-0.088470</td>\n",
       "      <td>G6VVRG07JCLJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.605124</td>\n",
       "      <td>-0.224952</td>\n",
       "      <td>0.100056</td>\n",
       "      <td>-0.119018</td>\n",
       "      <td>0.275660</td>\n",
       "      <td>-0.131941</td>\n",
       "      <td>0.264571</td>\n",
       "      <td>-0.167182</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>0.698942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120944</td>\n",
       "      <td>-0.197538</td>\n",
       "      <td>-0.402356</td>\n",
       "      <td>-0.147181</td>\n",
       "      <td>-0.213209</td>\n",
       "      <td>-0.178259</td>\n",
       "      <td>-0.215681</td>\n",
       "      <td>-0.085343</td>\n",
       "      <td>DNQVR0H7JCL9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-1.075973</td>\n",
       "      <td>-0.107299</td>\n",
       "      <td>-0.069349</td>\n",
       "      <td>-0.436939</td>\n",
       "      <td>-0.595849</td>\n",
       "      <td>-0.677410</td>\n",
       "      <td>-0.854722</td>\n",
       "      <td>-0.906743</td>\n",
       "      <td>-0.711780</td>\n",
       "      <td>-0.777570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086517</td>\n",
       "      <td>-0.175815</td>\n",
       "      <td>-0.272897</td>\n",
       "      <td>-0.079196</td>\n",
       "      <td>-0.194467</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.189196</td>\n",
       "      <td>-0.086642</td>\n",
       "      <td>FK1VM89TJCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.428781</td>\n",
       "      <td>-0.264216</td>\n",
       "      <td>-0.613354</td>\n",
       "      <td>-0.631711</td>\n",
       "      <td>-0.493136</td>\n",
       "      <td>-0.777886</td>\n",
       "      <td>-0.734094</td>\n",
       "      <td>-0.856169</td>\n",
       "      <td>-0.508824</td>\n",
       "      <td>-0.655797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102853</td>\n",
       "      <td>-0.081119</td>\n",
       "      <td>0.099172</td>\n",
       "      <td>-0.134623</td>\n",
       "      <td>-0.187003</td>\n",
       "      <td>-0.148707</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>-0.074757</td>\n",
       "      <td>FK4VP392JCL6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4.626893</td>\n",
       "      <td>1.881020</td>\n",
       "      <td>7.534346</td>\n",
       "      <td>3.163560</td>\n",
       "      <td>3.010840</td>\n",
       "      <td>3.697735</td>\n",
       "      <td>3.420169</td>\n",
       "      <td>1.936471</td>\n",
       "      <td>3.886361</td>\n",
       "      <td>2.879675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119380</td>\n",
       "      <td>-0.201845</td>\n",
       "      <td>-0.424896</td>\n",
       "      <td>-0.147004</td>\n",
       "      <td>-0.213720</td>\n",
       "      <td>-0.178218</td>\n",
       "      <td>-0.236713</td>\n",
       "      <td>-0.088930</td>\n",
       "      <td>DNQVRLSDJCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-0.285217</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.090280</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>-0.439697</td>\n",
       "      <td>-0.216353</td>\n",
       "      <td>-0.446804</td>\n",
       "      <td>-0.525933</td>\n",
       "      <td>-0.315758</td>\n",
       "      <td>-0.394554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096762</td>\n",
       "      <td>-0.174947</td>\n",
       "      <td>-0.256687</td>\n",
       "      <td>-0.138829</td>\n",
       "      <td>-0.148563</td>\n",
       "      <td>27.827937</td>\n",
       "      <td>-0.176879</td>\n",
       "      <td>-0.078479</td>\n",
       "      <td>F17VQ2LRJCLG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2.482609</td>\n",
       "      <td>0.917034</td>\n",
       "      <td>1.806220</td>\n",
       "      <td>0.604668</td>\n",
       "      <td>1.499171</td>\n",
       "      <td>0.755456</td>\n",
       "      <td>0.816113</td>\n",
       "      <td>-0.413977</td>\n",
       "      <td>1.124052</td>\n",
       "      <td>1.049304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120675</td>\n",
       "      <td>-0.203484</td>\n",
       "      <td>-0.439113</td>\n",
       "      <td>-0.148366</td>\n",
       "      <td>-0.216552</td>\n",
       "      <td>-0.179887</td>\n",
       "      <td>-0.238795</td>\n",
       "      <td>-0.088857</td>\n",
       "      <td>DNQVN9MJJCL6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-0.925559</td>\n",
       "      <td>-0.542873</td>\n",
       "      <td>-1.042550</td>\n",
       "      <td>-0.588600</td>\n",
       "      <td>-0.853068</td>\n",
       "      <td>-1.031429</td>\n",
       "      <td>-1.119944</td>\n",
       "      <td>-1.017637</td>\n",
       "      <td>-1.206022</td>\n",
       "      <td>-1.228571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101897</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.316577</td>\n",
       "      <td>-0.136666</td>\n",
       "      <td>-0.118975</td>\n",
       "      <td>-0.134651</td>\n",
       "      <td>-0.206776</td>\n",
       "      <td>0.821217</td>\n",
       "      <td>F2LVN55FJCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-0.931642</td>\n",
       "      <td>-0.462275</td>\n",
       "      <td>-0.784649</td>\n",
       "      <td>-0.573981</td>\n",
       "      <td>-0.656839</td>\n",
       "      <td>-0.921936</td>\n",
       "      <td>-1.245861</td>\n",
       "      <td>-0.904010</td>\n",
       "      <td>-0.741092</td>\n",
       "      <td>-0.582446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108907</td>\n",
       "      <td>0.831432</td>\n",
       "      <td>-0.309364</td>\n",
       "      <td>-0.136335</td>\n",
       "      <td>-0.072038</td>\n",
       "      <td>0.803855</td>\n",
       "      <td>-0.197073</td>\n",
       "      <td>-0.068380</td>\n",
       "      <td>G6WVN1Y8JCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-1.000768</td>\n",
       "      <td>-0.472878</td>\n",
       "      <td>-0.850079</td>\n",
       "      <td>-0.282603</td>\n",
       "      <td>-0.838015</td>\n",
       "      <td>-0.826702</td>\n",
       "      <td>-1.004902</td>\n",
       "      <td>-0.711181</td>\n",
       "      <td>-1.193276</td>\n",
       "      <td>-1.166062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355274</td>\n",
       "      <td>-0.191463</td>\n",
       "      <td>-0.253703</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>-0.200547</td>\n",
       "      <td>-0.169853</td>\n",
       "      <td>-0.196894</td>\n",
       "      <td>-0.085423</td>\n",
       "      <td>G6VVV63HJCL6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2.369178</td>\n",
       "      <td>0.935518</td>\n",
       "      <td>2.820109</td>\n",
       "      <td>0.847896</td>\n",
       "      <td>1.691254</td>\n",
       "      <td>1.953322</td>\n",
       "      <td>1.667512</td>\n",
       "      <td>1.290666</td>\n",
       "      <td>2.282400</td>\n",
       "      <td>2.405110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107868</td>\n",
       "      <td>-0.186784</td>\n",
       "      <td>-0.306666</td>\n",
       "      <td>-0.146194</td>\n",
       "      <td>-0.123906</td>\n",
       "      <td>-0.109743</td>\n",
       "      <td>-0.216281</td>\n",
       "      <td>-0.086936</td>\n",
       "      <td>F17VQ544JCLJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-0.046901</td>\n",
       "      <td>-0.109149</td>\n",
       "      <td>-0.127031</td>\n",
       "      <td>-0.353464</td>\n",
       "      <td>-0.393173</td>\n",
       "      <td>-0.787888</td>\n",
       "      <td>-0.852924</td>\n",
       "      <td>-0.796092</td>\n",
       "      <td>-0.730354</td>\n",
       "      <td>-1.027411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121677</td>\n",
       "      <td>-0.204826</td>\n",
       "      <td>-0.443120</td>\n",
       "      <td>-0.148763</td>\n",
       "      <td>-0.216801</td>\n",
       "      <td>-0.181811</td>\n",
       "      <td>-0.240735</td>\n",
       "      <td>-0.089338</td>\n",
       "      <td>G6TVNU2UJCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-0.323738</td>\n",
       "      <td>-0.180411</td>\n",
       "      <td>-0.173940</td>\n",
       "      <td>-0.307937</td>\n",
       "      <td>-0.730205</td>\n",
       "      <td>-0.701429</td>\n",
       "      <td>-0.644484</td>\n",
       "      <td>-0.826931</td>\n",
       "      <td>-0.750150</td>\n",
       "      <td>-0.768283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108624</td>\n",
       "      <td>-0.178937</td>\n",
       "      <td>1.821818</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>-0.196479</td>\n",
       "      <td>-0.143266</td>\n",
       "      <td>-0.204579</td>\n",
       "      <td>-0.082357</td>\n",
       "      <td>G6YVQE61JCLH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.342001</td>\n",
       "      <td>-0.436979</td>\n",
       "      <td>1.712324</td>\n",
       "      <td>0.815682</td>\n",
       "      <td>-0.032057</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>-0.019634</td>\n",
       "      <td>0.030024</td>\n",
       "      <td>0.219035</td>\n",
       "      <td>0.477122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117937</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>-0.396153</td>\n",
       "      <td>-0.145232</td>\n",
       "      <td>-0.160459</td>\n",
       "      <td>-0.158406</td>\n",
       "      <td>-0.204858</td>\n",
       "      <td>-0.087745</td>\n",
       "      <td>DNPVP9GJJCLJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-0.482019</td>\n",
       "      <td>-0.253241</td>\n",
       "      <td>0.410555</td>\n",
       "      <td>-0.285169</td>\n",
       "      <td>-0.510689</td>\n",
       "      <td>-0.080628</td>\n",
       "      <td>-0.392118</td>\n",
       "      <td>-0.779264</td>\n",
       "      <td>-0.437377</td>\n",
       "      <td>-0.625359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103711</td>\n",
       "      <td>-0.114373</td>\n",
       "      <td>-0.352826</td>\n",
       "      <td>-0.138087</td>\n",
       "      <td>-0.134099</td>\n",
       "      <td>-0.085666</td>\n",
       "      <td>1.995897</td>\n",
       "      <td>-0.054678</td>\n",
       "      <td>DNPVKWBMJCL9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-0.995587</td>\n",
       "      <td>-0.156970</td>\n",
       "      <td>0.152358</td>\n",
       "      <td>0.152548</td>\n",
       "      <td>-0.153521</td>\n",
       "      <td>-0.042626</td>\n",
       "      <td>0.407227</td>\n",
       "      <td>-0.234226</td>\n",
       "      <td>-0.269014</td>\n",
       "      <td>-0.399903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121100</td>\n",
       "      <td>-0.202855</td>\n",
       "      <td>-0.443674</td>\n",
       "      <td>-0.148812</td>\n",
       "      <td>-0.215764</td>\n",
       "      <td>-0.180151</td>\n",
       "      <td>-0.239507</td>\n",
       "      <td>-0.089356</td>\n",
       "      <td>G0NVM8S3JCLJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-0.118679</td>\n",
       "      <td>0.274417</td>\n",
       "      <td>0.660973</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>0.239891</td>\n",
       "      <td>-0.054170</td>\n",
       "      <td>-0.113231</td>\n",
       "      <td>0.399667</td>\n",
       "      <td>0.284454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079918</td>\n",
       "      <td>-0.140322</td>\n",
       "      <td>-0.342007</td>\n",
       "      <td>-0.137795</td>\n",
       "      <td>-0.132990</td>\n",
       "      <td>-0.044132</td>\n",
       "      <td>-0.180444</td>\n",
       "      <td>-0.069680</td>\n",
       "      <td>DNPVP67UJCL6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.055109</td>\n",
       "      <td>1.159169</td>\n",
       "      <td>-0.558682</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.606697</td>\n",
       "      <td>0.517299</td>\n",
       "      <td>-0.746417</td>\n",
       "      <td>-0.748440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117967</td>\n",
       "      <td>-0.174053</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>-0.145405</td>\n",
       "      <td>-0.201124</td>\n",
       "      <td>-0.178551</td>\n",
       "      <td>-0.231478</td>\n",
       "      <td>-0.085815</td>\n",
       "      <td>FK1VPPGUJCLH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>-0.896599</td>\n",
       "      <td>-0.369476</td>\n",
       "      <td>-0.832634</td>\n",
       "      <td>-0.628020</td>\n",
       "      <td>-0.741386</td>\n",
       "      <td>-0.767646</td>\n",
       "      <td>-1.003386</td>\n",
       "      <td>-0.888129</td>\n",
       "      <td>-0.823391</td>\n",
       "      <td>-0.619519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108031</td>\n",
       "      <td>-0.136343</td>\n",
       "      <td>-0.142981</td>\n",
       "      <td>-0.139626</td>\n",
       "      <td>-0.167119</td>\n",
       "      <td>-0.123055</td>\n",
       "      <td>-0.212270</td>\n",
       "      <td>-0.082201</td>\n",
       "      <td>G6TVLLRSJCLJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.207102</td>\n",
       "      <td>-0.133413</td>\n",
       "      <td>-0.157785</td>\n",
       "      <td>0.149749</td>\n",
       "      <td>0.047976</td>\n",
       "      <td>-0.093626</td>\n",
       "      <td>0.043874</td>\n",
       "      <td>-0.592760</td>\n",
       "      <td>0.675596</td>\n",
       "      <td>0.822834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070786</td>\n",
       "      <td>-0.030608</td>\n",
       "      <td>-0.402644</td>\n",
       "      <td>-0.145096</td>\n",
       "      <td>-0.197767</td>\n",
       "      <td>-0.173037</td>\n",
       "      <td>-0.223091</td>\n",
       "      <td>-0.087076</td>\n",
       "      <td>F17VM7BJJCL9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-0.864571</td>\n",
       "      <td>-0.113717</td>\n",
       "      <td>0.365128</td>\n",
       "      <td>-0.363675</td>\n",
       "      <td>-0.510735</td>\n",
       "      <td>-0.831666</td>\n",
       "      <td>-0.669051</td>\n",
       "      <td>-0.689147</td>\n",
       "      <td>-0.084372</td>\n",
       "      <td>-0.633372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121457</td>\n",
       "      <td>-0.204866</td>\n",
       "      <td>-0.444229</td>\n",
       "      <td>-0.148865</td>\n",
       "      <td>-0.217371</td>\n",
       "      <td>-0.181933</td>\n",
       "      <td>-0.240945</td>\n",
       "      <td>-0.089417</td>\n",
       "      <td>F2LVRMF9JCL8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.514055</td>\n",
       "      <td>0.128387</td>\n",
       "      <td>0.622481</td>\n",
       "      <td>0.326019</td>\n",
       "      <td>-0.172758</td>\n",
       "      <td>0.130129</td>\n",
       "      <td>0.332284</td>\n",
       "      <td>-0.410939</td>\n",
       "      <td>0.124537</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087063</td>\n",
       "      <td>0.491221</td>\n",
       "      <td>-0.089057</td>\n",
       "      <td>-0.115810</td>\n",
       "      <td>-0.026820</td>\n",
       "      <td>-0.102517</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>-0.083579</td>\n",
       "      <td>F18VQX5EJCL6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>-1.114516</td>\n",
       "      <td>-0.527332</td>\n",
       "      <td>-0.777997</td>\n",
       "      <td>-0.543912</td>\n",
       "      <td>-0.610209</td>\n",
       "      <td>-1.248412</td>\n",
       "      <td>-1.014072</td>\n",
       "      <td>-1.013719</td>\n",
       "      <td>-0.889747</td>\n",
       "      <td>-0.692027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101825</td>\n",
       "      <td>-0.018660</td>\n",
       "      <td>-0.318343</td>\n",
       "      <td>-0.010661</td>\n",
       "      <td>-0.180407</td>\n",
       "      <td>-0.162043</td>\n",
       "      <td>-0.172675</td>\n",
       "      <td>18.795826</td>\n",
       "      <td>G6VVLC0ZJCL9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>-0.117095</td>\n",
       "      <td>0.098559</td>\n",
       "      <td>-0.154451</td>\n",
       "      <td>-0.419520</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>-0.214558</td>\n",
       "      <td>-0.270649</td>\n",
       "      <td>-0.145085</td>\n",
       "      <td>-0.011604</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102368</td>\n",
       "      <td>-0.174793</td>\n",
       "      <td>-0.344733</td>\n",
       "      <td>-0.123374</td>\n",
       "      <td>-0.178232</td>\n",
       "      <td>0.215602</td>\n",
       "      <td>-0.139916</td>\n",
       "      <td>-0.086108</td>\n",
       "      <td>G0PVT98PJCLJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.291533</td>\n",
       "      <td>0.816940</td>\n",
       "      <td>0.416752</td>\n",
       "      <td>0.543318</td>\n",
       "      <td>1.057591</td>\n",
       "      <td>-0.070080</td>\n",
       "      <td>0.254445</td>\n",
       "      <td>-0.342067</td>\n",
       "      <td>0.134545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096409</td>\n",
       "      <td>-0.157459</td>\n",
       "      <td>0.269025</td>\n",
       "      <td>-0.136090</td>\n",
       "      <td>-0.166585</td>\n",
       "      <td>-0.117926</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.081197</td>\n",
       "      <td>DNQVR8ZAJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.390581</td>\n",
       "      <td>0.202563</td>\n",
       "      <td>0.954557</td>\n",
       "      <td>0.232518</td>\n",
       "      <td>0.538187</td>\n",
       "      <td>0.418066</td>\n",
       "      <td>0.639856</td>\n",
       "      <td>0.317645</td>\n",
       "      <td>1.028062</td>\n",
       "      <td>0.552213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098113</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.092197</td>\n",
       "      <td>-0.115212</td>\n",
       "      <td>-0.024371</td>\n",
       "      <td>-0.104496</td>\n",
       "      <td>-0.204370</td>\n",
       "      <td>-0.033137</td>\n",
       "      <td>F2MVPRBNJCL9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-0.973795</td>\n",
       "      <td>-0.582570</td>\n",
       "      <td>-0.867261</td>\n",
       "      <td>-0.683932</td>\n",
       "      <td>-0.816716</td>\n",
       "      <td>-0.853473</td>\n",
       "      <td>-0.842360</td>\n",
       "      <td>-0.536695</td>\n",
       "      <td>-1.049340</td>\n",
       "      <td>-0.955088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100478</td>\n",
       "      <td>-0.113703</td>\n",
       "      <td>-0.364673</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>-0.170359</td>\n",
       "      <td>-0.161535</td>\n",
       "      <td>-0.144043</td>\n",
       "      <td>-0.084871</td>\n",
       "      <td>F17VMG48JCLH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>-0.408153</td>\n",
       "      <td>-0.308335</td>\n",
       "      <td>-0.859958</td>\n",
       "      <td>-0.855260</td>\n",
       "      <td>-0.373376</td>\n",
       "      <td>-0.332903</td>\n",
       "      <td>-0.567652</td>\n",
       "      <td>-0.319645</td>\n",
       "      <td>-0.480720</td>\n",
       "      <td>-0.606785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106917</td>\n",
       "      <td>0.098921</td>\n",
       "      <td>-0.331408</td>\n",
       "      <td>-0.114596</td>\n",
       "      <td>-0.158331</td>\n",
       "      <td>-0.157826</td>\n",
       "      <td>-0.187064</td>\n",
       "      <td>-0.068372</td>\n",
       "      <td>F17VK09UJCLH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>-0.071362</td>\n",
       "      <td>0.105233</td>\n",
       "      <td>-0.055159</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>-0.162996</td>\n",
       "      <td>-0.240980</td>\n",
       "      <td>-0.151142</td>\n",
       "      <td>0.515596</td>\n",
       "      <td>-0.375092</td>\n",
       "      <td>-0.287314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100935</td>\n",
       "      <td>-0.144269</td>\n",
       "      <td>-0.313931</td>\n",
       "      <td>-0.136194</td>\n",
       "      <td>-0.167465</td>\n",
       "      <td>-0.111722</td>\n",
       "      <td>0.152280</td>\n",
       "      <td>-0.069776</td>\n",
       "      <td>F2LW1X2QJCLJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>0.589790</td>\n",
       "      <td>0.083567</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.297730</td>\n",
       "      <td>0.516384</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>0.221391</td>\n",
       "      <td>0.399644</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083945</td>\n",
       "      <td>0.663544</td>\n",
       "      <td>-0.254440</td>\n",
       "      <td>-0.113448</td>\n",
       "      <td>-0.147587</td>\n",
       "      <td>-0.160641</td>\n",
       "      <td>-0.106131</td>\n",
       "      <td>-0.082686</td>\n",
       "      <td>G0NVTSUJJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>1.503270</td>\n",
       "      <td>0.257579</td>\n",
       "      <td>0.356917</td>\n",
       "      <td>0.868089</td>\n",
       "      <td>0.404768</td>\n",
       "      <td>0.540736</td>\n",
       "      <td>0.868468</td>\n",
       "      <td>1.526626</td>\n",
       "      <td>0.816863</td>\n",
       "      <td>0.094637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092696</td>\n",
       "      <td>-0.163720</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>-0.134187</td>\n",
       "      <td>-0.166405</td>\n",
       "      <td>-0.055475</td>\n",
       "      <td>-0.140503</td>\n",
       "      <td>-0.083817</td>\n",
       "      <td>G6TVT9FAJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1.467254</td>\n",
       "      <td>1.158162</td>\n",
       "      <td>2.914822</td>\n",
       "      <td>1.166177</td>\n",
       "      <td>1.130718</td>\n",
       "      <td>1.097427</td>\n",
       "      <td>1.670953</td>\n",
       "      <td>1.827644</td>\n",
       "      <td>0.989679</td>\n",
       "      <td>0.849687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>-0.128336</td>\n",
       "      <td>-0.111164</td>\n",
       "      <td>-0.123668</td>\n",
       "      <td>-0.148740</td>\n",
       "      <td>-0.145325</td>\n",
       "      <td>-0.109837</td>\n",
       "      <td>-0.083111</td>\n",
       "      <td>F17VR4CEJCLH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2.153365</td>\n",
       "      <td>0.755824</td>\n",
       "      <td>2.234517</td>\n",
       "      <td>1.531406</td>\n",
       "      <td>1.284152</td>\n",
       "      <td>1.481242</td>\n",
       "      <td>2.433410</td>\n",
       "      <td>2.217365</td>\n",
       "      <td>2.037226</td>\n",
       "      <td>2.307967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021116</td>\n",
       "      <td>-0.146865</td>\n",
       "      <td>-0.329483</td>\n",
       "      <td>-0.138939</td>\n",
       "      <td>-0.175885</td>\n",
       "      <td>0.309375</td>\n",
       "      <td>-0.178527</td>\n",
       "      <td>-0.084062</td>\n",
       "      <td>C39VTTDHJCLH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-1.077493</td>\n",
       "      <td>-0.573080</td>\n",
       "      <td>-0.893232</td>\n",
       "      <td>-0.657443</td>\n",
       "      <td>-0.819092</td>\n",
       "      <td>-0.903509</td>\n",
       "      <td>-1.148579</td>\n",
       "      <td>-0.949466</td>\n",
       "      <td>-1.248528</td>\n",
       "      <td>-1.135180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061757</td>\n",
       "      <td>0.121195</td>\n",
       "      <td>-0.274607</td>\n",
       "      <td>-0.120885</td>\n",
       "      <td>-0.056983</td>\n",
       "      <td>-0.149064</td>\n",
       "      <td>-0.201769</td>\n",
       "      <td>-0.083928</td>\n",
       "      <td>FK1VQ13DJCL7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-0.950846</td>\n",
       "      <td>-0.139161</td>\n",
       "      <td>-0.512186</td>\n",
       "      <td>-0.449462</td>\n",
       "      <td>-0.821767</td>\n",
       "      <td>-0.710636</td>\n",
       "      <td>-0.980205</td>\n",
       "      <td>-0.603415</td>\n",
       "      <td>-0.743631</td>\n",
       "      <td>-0.837202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111130</td>\n",
       "      <td>-0.154350</td>\n",
       "      <td>-0.364290</td>\n",
       "      <td>-0.126382</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>-0.160208</td>\n",
       "      <td>-0.124738</td>\n",
       "      <td>-0.076729</td>\n",
       "      <td>DNQVT61RJCL7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>-1.296925</td>\n",
       "      <td>-0.632643</td>\n",
       "      <td>-1.101004</td>\n",
       "      <td>-0.656233</td>\n",
       "      <td>-0.927398</td>\n",
       "      <td>-1.180722</td>\n",
       "      <td>-1.390699</td>\n",
       "      <td>-1.091271</td>\n",
       "      <td>-1.183917</td>\n",
       "      <td>-1.218565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103848</td>\n",
       "      <td>-0.180075</td>\n",
       "      <td>-0.379917</td>\n",
       "      <td>-0.143719</td>\n",
       "      <td>-0.164509</td>\n",
       "      <td>-0.163442</td>\n",
       "      <td>-0.197631</td>\n",
       "      <td>-0.082260</td>\n",
       "      <td>F2MVQCFFJCL6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.384807</td>\n",
       "      <td>0.279770</td>\n",
       "      <td>0.298769</td>\n",
       "      <td>0.055351</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>-0.022336</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>-0.215643</td>\n",
       "      <td>-0.326474</td>\n",
       "      <td>0.068319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037617</td>\n",
       "      <td>-0.123617</td>\n",
       "      <td>0.756721</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>-0.016874</td>\n",
       "      <td>-0.142777</td>\n",
       "      <td>-0.192082</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>F2LVRH2EJCL9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.682195</td>\n",
       "      <td>0.265778</td>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.919597</td>\n",
       "      <td>0.135152</td>\n",
       "      <td>0.592071</td>\n",
       "      <td>0.395589</td>\n",
       "      <td>0.829902</td>\n",
       "      <td>0.415508</td>\n",
       "      <td>0.784766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093540</td>\n",
       "      <td>-0.165959</td>\n",
       "      <td>0.271095</td>\n",
       "      <td>-0.136651</td>\n",
       "      <td>-0.102223</td>\n",
       "      <td>0.141439</td>\n",
       "      <td>0.195586</td>\n",
       "      <td>-0.065108</td>\n",
       "      <td>DNQVWJKUJCLH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-1.080406</td>\n",
       "      <td>-0.464258</td>\n",
       "      <td>-0.775505</td>\n",
       "      <td>-0.535795</td>\n",
       "      <td>-0.808931</td>\n",
       "      <td>-1.035788</td>\n",
       "      <td>-1.268661</td>\n",
       "      <td>-0.880178</td>\n",
       "      <td>-0.888921</td>\n",
       "      <td>-0.954110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098195</td>\n",
       "      <td>-0.174630</td>\n",
       "      <td>-0.371570</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>-0.143877</td>\n",
       "      <td>-0.151384</td>\n",
       "      <td>-0.199785</td>\n",
       "      <td>-0.083173</td>\n",
       "      <td>G0NVQCUNJCLJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>-0.364960</td>\n",
       "      <td>-0.198177</td>\n",
       "      <td>-0.075487</td>\n",
       "      <td>-0.158294</td>\n",
       "      <td>0.047601</td>\n",
       "      <td>-0.438332</td>\n",
       "      <td>-0.636311</td>\n",
       "      <td>-0.292515</td>\n",
       "      <td>0.294651</td>\n",
       "      <td>-0.221169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053741</td>\n",
       "      <td>-0.140726</td>\n",
       "      <td>-0.378458</td>\n",
       "      <td>-0.142471</td>\n",
       "      <td>-0.162392</td>\n",
       "      <td>-0.127912</td>\n",
       "      <td>-0.181571</td>\n",
       "      <td>-0.082764</td>\n",
       "      <td>F2LVPR6NJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.152928</td>\n",
       "      <td>0.185546</td>\n",
       "      <td>0.670542</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>0.231764</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>0.635903</td>\n",
       "      <td>0.637913</td>\n",
       "      <td>0.353445</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.084788</td>\n",
       "      <td>-0.282943</td>\n",
       "      <td>2.721884</td>\n",
       "      <td>-0.150358</td>\n",
       "      <td>-0.133230</td>\n",
       "      <td>-0.186939</td>\n",
       "      <td>-0.073226</td>\n",
       "      <td>DNQVTPPBJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>-1.197859</td>\n",
       "      <td>-0.582051</td>\n",
       "      <td>-0.910368</td>\n",
       "      <td>-0.622947</td>\n",
       "      <td>-0.767159</td>\n",
       "      <td>-1.067248</td>\n",
       "      <td>-1.217328</td>\n",
       "      <td>-1.047384</td>\n",
       "      <td>-1.087437</td>\n",
       "      <td>-0.921782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068340</td>\n",
       "      <td>-0.166982</td>\n",
       "      <td>-0.288180</td>\n",
       "      <td>-0.138699</td>\n",
       "      <td>-0.064075</td>\n",
       "      <td>-0.139945</td>\n",
       "      <td>-0.151143</td>\n",
       "      <td>-0.081066</td>\n",
       "      <td>C39VM8V4JCLF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.073754</td>\n",
       "      <td>-0.554064</td>\n",
       "      <td>-0.532087</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.363374</td>\n",
       "      <td>0.143957</td>\n",
       "      <td>0.028957</td>\n",
       "      <td>0.409975</td>\n",
       "      <td>0.194234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108674</td>\n",
       "      <td>-0.173003</td>\n",
       "      <td>-0.267840</td>\n",
       "      <td>-0.107651</td>\n",
       "      <td>-0.178040</td>\n",
       "      <td>0.313237</td>\n",
       "      <td>-0.189931</td>\n",
       "      <td>-0.074633</td>\n",
       "      <td>F17VPJ2TJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>-0.245619</td>\n",
       "      <td>-0.120680</td>\n",
       "      <td>0.083632</td>\n",
       "      <td>-0.204955</td>\n",
       "      <td>-0.373384</td>\n",
       "      <td>-0.184843</td>\n",
       "      <td>-0.278121</td>\n",
       "      <td>-0.185237</td>\n",
       "      <td>-0.284848</td>\n",
       "      <td>-0.294790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106904</td>\n",
       "      <td>-0.165610</td>\n",
       "      <td>-0.358985</td>\n",
       "      <td>-0.141520</td>\n",
       "      <td>-0.144199</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>-0.189262</td>\n",
       "      <td>-0.083990</td>\n",
       "      <td>FK3VQ6GYJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.390006</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.260478</td>\n",
       "      <td>0.327370</td>\n",
       "      <td>-0.112497</td>\n",
       "      <td>0.571731</td>\n",
       "      <td>0.714081</td>\n",
       "      <td>0.471396</td>\n",
       "      <td>-0.031899</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092339</td>\n",
       "      <td>-0.161893</td>\n",
       "      <td>-0.360376</td>\n",
       "      <td>-0.102105</td>\n",
       "      <td>-0.177170</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>1.751201</td>\n",
       "      <td>-0.082724</td>\n",
       "      <td>DNPVMTP6JCL7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>-0.888356</td>\n",
       "      <td>-0.604147</td>\n",
       "      <td>-1.015125</td>\n",
       "      <td>-0.760687</td>\n",
       "      <td>-0.646364</td>\n",
       "      <td>-0.409822</td>\n",
       "      <td>-0.612045</td>\n",
       "      <td>-1.070949</td>\n",
       "      <td>-0.958372</td>\n",
       "      <td>-1.095059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094002</td>\n",
       "      <td>-0.181015</td>\n",
       "      <td>-0.272561</td>\n",
       "      <td>-0.139828</td>\n",
       "      <td>-0.190698</td>\n",
       "      <td>-0.161311</td>\n",
       "      <td>-0.204561</td>\n",
       "      <td>-0.072865</td>\n",
       "      <td>FK1VMP9XJCLH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>-0.186496</td>\n",
       "      <td>-0.320050</td>\n",
       "      <td>-0.680582</td>\n",
       "      <td>-0.331381</td>\n",
       "      <td>-0.422830</td>\n",
       "      <td>-0.360773</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>-0.333088</td>\n",
       "      <td>-0.595701</td>\n",
       "      <td>-0.418847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109882</td>\n",
       "      <td>-0.153134</td>\n",
       "      <td>0.023717</td>\n",
       "      <td>-0.091905</td>\n",
       "      <td>-0.181418</td>\n",
       "      <td>-0.157575</td>\n",
       "      <td>-0.107311</td>\n",
       "      <td>-0.084562</td>\n",
       "      <td>FK3VL2N5JCL6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>-1.114189</td>\n",
       "      <td>-0.569306</td>\n",
       "      <td>-0.799527</td>\n",
       "      <td>-0.511810</td>\n",
       "      <td>-0.702974</td>\n",
       "      <td>-1.143826</td>\n",
       "      <td>-1.197490</td>\n",
       "      <td>-0.865041</td>\n",
       "      <td>-1.068059</td>\n",
       "      <td>-1.021924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111627</td>\n",
       "      <td>-0.141243</td>\n",
       "      <td>-0.320139</td>\n",
       "      <td>-0.140981</td>\n",
       "      <td>-0.193023</td>\n",
       "      <td>-0.132044</td>\n",
       "      <td>-0.206185</td>\n",
       "      <td>-0.084702</td>\n",
       "      <td>F2MVM98FJCLJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.178382</td>\n",
       "      <td>-0.241389</td>\n",
       "      <td>-0.861680</td>\n",
       "      <td>-0.519134</td>\n",
       "      <td>-0.315002</td>\n",
       "      <td>-0.146169</td>\n",
       "      <td>-0.130714</td>\n",
       "      <td>-0.491759</td>\n",
       "      <td>-0.513878</td>\n",
       "      <td>-0.341238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098825</td>\n",
       "      <td>-0.177289</td>\n",
       "      <td>-0.357447</td>\n",
       "      <td>-0.135941</td>\n",
       "      <td>-0.183197</td>\n",
       "      <td>-0.156282</td>\n",
       "      <td>-0.115766</td>\n",
       "      <td>-0.082493</td>\n",
       "      <td>F2NVP4LNJCL6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>-0.188188</td>\n",
       "      <td>-0.171788</td>\n",
       "      <td>-0.450567</td>\n",
       "      <td>-0.407481</td>\n",
       "      <td>-0.199935</td>\n",
       "      <td>0.172380</td>\n",
       "      <td>-0.327507</td>\n",
       "      <td>-0.793090</td>\n",
       "      <td>-0.449965</td>\n",
       "      <td>-0.607267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109056</td>\n",
       "      <td>-0.156475</td>\n",
       "      <td>-0.283821</td>\n",
       "      <td>-0.140199</td>\n",
       "      <td>-0.153228</td>\n",
       "      <td>1.661736</td>\n",
       "      <td>-0.208782</td>\n",
       "      <td>-0.085911</td>\n",
       "      <td>DNQVMB2AJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.035735</td>\n",
       "      <td>-0.264979</td>\n",
       "      <td>0.593047</td>\n",
       "      <td>0.719269</td>\n",
       "      <td>-0.207199</td>\n",
       "      <td>-0.127417</td>\n",
       "      <td>-0.220232</td>\n",
       "      <td>-0.237686</td>\n",
       "      <td>0.134450</td>\n",
       "      <td>-0.351551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108958</td>\n",
       "      <td>-0.050146</td>\n",
       "      <td>-0.188895</td>\n",
       "      <td>-0.135780</td>\n",
       "      <td>-0.170496</td>\n",
       "      <td>-0.157207</td>\n",
       "      <td>-0.199011</td>\n",
       "      <td>-0.085167</td>\n",
       "      <td>F17VL8SKJCL8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>-0.780262</td>\n",
       "      <td>-0.339217</td>\n",
       "      <td>-0.755094</td>\n",
       "      <td>-0.536258</td>\n",
       "      <td>-0.739777</td>\n",
       "      <td>-0.574125</td>\n",
       "      <td>-1.219266</td>\n",
       "      <td>-0.774758</td>\n",
       "      <td>-1.176376</td>\n",
       "      <td>-1.117278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107028</td>\n",
       "      <td>-0.150693</td>\n",
       "      <td>-0.308109</td>\n",
       "      <td>-0.063215</td>\n",
       "      <td>-0.184759</td>\n",
       "      <td>-0.163797</td>\n",
       "      <td>-0.034948</td>\n",
       "      <td>-0.031915</td>\n",
       "      <td>F17VRYDXJCL9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows  98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0_rr      1_rr      2_rr      3_rr      4_rr      5_rr      6_rr  \\\n",
       "104  5.931533  2.102955  6.210149  3.117742  2.696490  2.425905  2.493749   \n",
       "105 -0.810072 -0.453475 -0.411790 -0.121522 -0.390715 -0.645898 -0.573187   \n",
       "106  5.444275  1.831775  7.111072  4.575378  4.089973  3.769078  4.501199   \n",
       "107 -0.491840 -0.104167 -0.293582 -0.164649 -0.513360 -0.343525 -0.577840   \n",
       "108 -0.988062 -0.476608 -0.885162 -0.691764 -0.696767 -0.932271 -1.221469   \n",
       "109 -1.217828 -0.554401 -0.886535 -0.625021 -0.843715 -1.192816 -1.354224   \n",
       "110 -0.982644 -0.516823 -0.772645 -0.546408 -0.700692 -0.991409 -1.133810   \n",
       "111  0.859935  0.455642  3.388609  2.869466  1.137428  1.121021  0.868471   \n",
       "112  1.827368  0.417818  2.758361  2.153674  0.950922  1.534312  1.387566   \n",
       "113 -0.605124 -0.224952  0.100056 -0.119018  0.275660 -0.131941  0.264571   \n",
       "114 -1.075973 -0.107299 -0.069349 -0.436939 -0.595849 -0.677410 -0.854722   \n",
       "115 -0.428781 -0.264216 -0.613354 -0.631711 -0.493136 -0.777886 -0.734094   \n",
       "116  4.626893  1.881020  7.534346  3.163560  3.010840  3.697735  3.420169   \n",
       "117 -0.285217  0.040004  0.090280  0.003971 -0.439697 -0.216353 -0.446804   \n",
       "118  2.482609  0.917034  1.806220  0.604668  1.499171  0.755456  0.816113   \n",
       "119 -0.925559 -0.542873 -1.042550 -0.588600 -0.853068 -1.031429 -1.119944   \n",
       "120 -0.931642 -0.462275 -0.784649 -0.573981 -0.656839 -0.921936 -1.245861   \n",
       "121 -1.000768 -0.472878 -0.850079 -0.282603 -0.838015 -0.826702 -1.004902   \n",
       "122  2.369178  0.935518  2.820109  0.847896  1.691254  1.953322  1.667512   \n",
       "123 -0.046901 -0.109149 -0.127031 -0.353464 -0.393173 -0.787888 -0.852924   \n",
       "124 -0.323738 -0.180411 -0.173940 -0.307937 -0.730205 -0.701429 -0.644484   \n",
       "125 -0.342001 -0.436979  1.712324  0.815682 -0.032057  0.439100 -0.019634   \n",
       "126 -0.482019 -0.253241  0.410555 -0.285169 -0.510689 -0.080628 -0.392118   \n",
       "127 -0.995587 -0.156970  0.152358  0.152548 -0.153521 -0.042626  0.407227   \n",
       "128 -0.118679  0.274417  0.660973  0.039800 -0.153029  0.239891 -0.054170   \n",
       "129  0.814000  0.081158  0.055109  1.159169 -0.558682  0.388563  0.606697   \n",
       "130 -0.896599 -0.369476 -0.832634 -0.628020 -0.741386 -0.767646 -1.003386   \n",
       "131  0.207102 -0.133413 -0.157785  0.149749  0.047976 -0.093626  0.043874   \n",
       "132 -0.864571 -0.113717  0.365128 -0.363675 -0.510735 -0.831666 -0.669051   \n",
       "133  0.514055  0.128387  0.622481  0.326019 -0.172758  0.130129  0.332284   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "814 -1.114516 -0.527332 -0.777997 -0.543912 -0.610209 -1.248412 -1.014072   \n",
       "815 -0.117095  0.098559 -0.154451 -0.419520  0.027573 -0.214558 -0.270649   \n",
       "816  0.006165  0.291533  0.816940  0.416752  0.543318  1.057591 -0.070080   \n",
       "817  0.390581  0.202563  0.954557  0.232518  0.538187  0.418066  0.639856   \n",
       "818 -0.973795 -0.582570 -0.867261 -0.683932 -0.816716 -0.853473 -0.842360   \n",
       "819 -0.408153 -0.308335 -0.859958 -0.855260 -0.373376 -0.332903 -0.567652   \n",
       "820 -0.071362  0.105233 -0.055159  0.166100 -0.162996 -0.240980 -0.151142   \n",
       "821  0.589790  0.083567 -0.056929 -0.297730  0.516384  0.785905  0.221391   \n",
       "822  1.503270  0.257579  0.356917  0.868089  0.404768  0.540736  0.868468   \n",
       "823  1.467254  1.158162  2.914822  1.166177  1.130718  1.097427  1.670953   \n",
       "824  2.153365  0.755824  2.234517  1.531406  1.284152  1.481242  2.433410   \n",
       "825 -1.077493 -0.573080 -0.893232 -0.657443 -0.819092 -0.903509 -1.148579   \n",
       "826 -0.950846 -0.139161 -0.512186 -0.449462 -0.821767 -0.710636 -0.980205   \n",
       "827 -1.296925 -0.632643 -1.101004 -0.656233 -0.927398 -1.180722 -1.390699   \n",
       "828  0.384807  0.279770  0.298769  0.055351  0.002772 -0.022336  0.074053   \n",
       "829  0.682195  0.265778  0.664796  0.919597  0.135152  0.592071  0.395589   \n",
       "830 -1.080406 -0.464258 -0.775505 -0.535795 -0.808931 -1.035788 -1.268661   \n",
       "831 -0.364960 -0.198177 -0.075487 -0.158294  0.047601 -0.438332 -0.636311   \n",
       "832  0.152928  0.185546  0.670542  0.057160  0.231764  0.308311  0.635903   \n",
       "833 -1.197859 -0.582051 -0.910368 -0.622947 -0.767159 -1.067248 -1.217328   \n",
       "834  0.010516  0.073754 -0.554064 -0.532087  0.025723  0.363374  0.143957   \n",
       "835 -0.245619 -0.120680  0.083632 -0.204955 -0.373384 -0.184843 -0.278121   \n",
       "836  0.390006  0.037226  0.260478  0.327370 -0.112497  0.571731  0.714081   \n",
       "837 -0.888356 -0.604147 -1.015125 -0.760687 -0.646364 -0.409822 -0.612045   \n",
       "838 -0.186496 -0.320050 -0.680582 -0.331381 -0.422830 -0.360773  0.033352   \n",
       "839 -1.114189 -0.569306 -0.799527 -0.511810 -0.702974 -1.143826 -1.197490   \n",
       "840  0.178382 -0.241389 -0.861680 -0.519134 -0.315002 -0.146169 -0.130714   \n",
       "841 -0.188188 -0.171788 -0.450567 -0.407481 -0.199935  0.172380 -0.327507   \n",
       "842  0.035735 -0.264979  0.593047  0.719269 -0.207199 -0.127417 -0.220232   \n",
       "843 -0.780262 -0.339217 -0.755094 -0.536258 -0.739777 -0.574125 -1.219266   \n",
       "\n",
       "         7_rr      8_rr      9_rr  ...      40_rrr    41_rrr    42_rrr  \\\n",
       "104  1.779586  2.878011  2.857698  ...   -0.093967 -0.102755 -0.343265   \n",
       "105 -0.586418 -0.699149  1.438080  ...   -0.121667 -0.205135 -0.444325   \n",
       "106  2.621409  5.369341  5.491001  ...   -0.117539 -0.193247 -0.389859   \n",
       "107 -0.315793 -0.570568 -0.665754  ...   -0.059889  0.885310 -0.372617   \n",
       "108 -0.901348 -1.056595 -1.127827  ...   -0.105480 -0.143271 -0.383236   \n",
       "109 -1.058467 -1.140791 -1.135582  ...   -0.103140  0.084072 -0.288756   \n",
       "110 -0.879561 -0.986921 -0.922317  ...   -0.059520 -0.178140 -0.386450   \n",
       "111  0.947952  0.779132  1.335907  ...   -0.119711 -0.194094 -0.427129   \n",
       "112  1.130540  1.049769  1.658898  ...   -0.097878 -0.191733 -0.376738   \n",
       "113 -0.167182  0.021776  0.698942  ...   -0.120944 -0.197538 -0.402356   \n",
       "114 -0.906743 -0.711780 -0.777570  ...   -0.086517 -0.175815 -0.272897   \n",
       "115 -0.856169 -0.508824 -0.655797  ...   -0.102853 -0.081119  0.099172   \n",
       "116  1.936471  3.886361  2.879675  ...   -0.119380 -0.201845 -0.424896   \n",
       "117 -0.525933 -0.315758 -0.394554  ...   -0.096762 -0.174947 -0.256687   \n",
       "118 -0.413977  1.124052  1.049304  ...   -0.120675 -0.203484 -0.439113   \n",
       "119 -1.017637 -1.206022 -1.228571  ...   -0.101897 -0.001443 -0.316577   \n",
       "120 -0.904010 -0.741092 -0.582446  ...   -0.108907  0.831432 -0.309364   \n",
       "121 -0.711181 -1.193276 -1.166062  ...    0.355274 -0.191463 -0.253703   \n",
       "122  1.290666  2.282400  2.405110  ...   -0.107868 -0.186784 -0.306666   \n",
       "123 -0.796092 -0.730354 -1.027411  ...   -0.121677 -0.204826 -0.443120   \n",
       "124 -0.826931 -0.750150 -0.768283  ...   -0.108624 -0.178937  1.821818   \n",
       "125  0.030024  0.219035  0.477122  ...   -0.117937  0.031942 -0.396153   \n",
       "126 -0.779264 -0.437377 -0.625359  ...   -0.103711 -0.114373 -0.352826   \n",
       "127 -0.234226 -0.269014 -0.399903  ...   -0.121100 -0.202855 -0.443674   \n",
       "128 -0.113231  0.399667  0.284454  ...   -0.079918 -0.140322 -0.342007   \n",
       "129  0.517299 -0.746417 -0.748440  ...   -0.117967 -0.174053 -0.403236   \n",
       "130 -0.888129 -0.823391 -0.619519  ...   -0.108031 -0.136343 -0.142981   \n",
       "131 -0.592760  0.675596  0.822834  ...    0.070786 -0.030608 -0.402644   \n",
       "132 -0.689147 -0.084372 -0.633372  ...   -0.121457 -0.204866 -0.444229   \n",
       "133 -0.410939  0.124537  0.008204  ...   -0.087063  0.491221 -0.089057   \n",
       "..        ...       ...       ...  ...         ...       ...       ...   \n",
       "814 -1.013719 -0.889747 -0.692027  ...   -0.101825 -0.018660 -0.318343   \n",
       "815 -0.145085 -0.011604  0.006807  ...   -0.102368 -0.174793 -0.344733   \n",
       "816  0.254445 -0.342067  0.134545  ...   -0.096409 -0.157459  0.269025   \n",
       "817  0.317645  1.028062  0.552213  ...   -0.098113 -0.146329 -0.092197   \n",
       "818 -0.536695 -1.049340 -0.955088  ...   -0.100478 -0.113703 -0.364673   \n",
       "819 -0.319645 -0.480720 -0.606785  ...   -0.106917  0.098921 -0.331408   \n",
       "820  0.515596 -0.375092 -0.287314  ...   -0.100935 -0.144269 -0.313931   \n",
       "821  0.399644  0.422036  0.903614  ...   -0.083945  0.663544 -0.254440   \n",
       "822  1.526626  0.816863  0.094637  ...   -0.092696 -0.163720  0.001650   \n",
       "823  1.827644  0.989679  0.849687  ...    0.079700 -0.128336 -0.111164   \n",
       "824  2.217365  2.037226  2.307967  ...   -0.021116 -0.146865 -0.329483   \n",
       "825 -0.949466 -1.248528 -1.135180  ...   -0.061757  0.121195 -0.274607   \n",
       "826 -0.603415 -0.743631 -0.837202  ...   -0.111130 -0.154350 -0.364290   \n",
       "827 -1.091271 -1.183917 -1.218565  ...   -0.103848 -0.180075 -0.379917   \n",
       "828 -0.215643 -0.326474  0.068319  ...   -0.037617 -0.123617  0.756721   \n",
       "829  0.829902  0.415508  0.784766  ...   -0.093540 -0.165959  0.271095   \n",
       "830 -0.880178 -0.888921 -0.954110  ...   -0.098195 -0.174630 -0.371570   \n",
       "831 -0.292515  0.294651 -0.221169  ...   -0.053741 -0.140726 -0.378458   \n",
       "832  0.637913  0.353445  0.043080  ...   -0.094860 -0.084788 -0.282943   \n",
       "833 -1.047384 -1.087437 -0.921782  ...   -0.068340 -0.166982 -0.288180   \n",
       "834  0.028957  0.409975  0.194234  ...   -0.108674 -0.173003 -0.267840   \n",
       "835 -0.185237 -0.284848 -0.294790  ...   -0.106904 -0.165610 -0.358985   \n",
       "836  0.471396 -0.031899  0.128052  ...   -0.092339 -0.161893 -0.360376   \n",
       "837 -1.070949 -0.958372 -1.095059  ...   -0.094002 -0.181015 -0.272561   \n",
       "838 -0.333088 -0.595701 -0.418847  ...   -0.109882 -0.153134  0.023717   \n",
       "839 -0.865041 -1.068059 -1.021924  ...   -0.111627 -0.141243 -0.320139   \n",
       "840 -0.491759 -0.513878 -0.341238  ...   -0.098825 -0.177289 -0.357447   \n",
       "841 -0.793090 -0.449965 -0.607267  ...   -0.109056 -0.156475 -0.283821   \n",
       "842 -0.237686  0.134450 -0.351551  ...   -0.108958 -0.050146 -0.188895   \n",
       "843 -0.774758 -1.176376 -1.117278  ...   -0.107028 -0.150693 -0.308109   \n",
       "\n",
       "       43_rrr    44_rrr     45_rrr    46_rrr     47_rrr            sn  state  \n",
       "104 -0.138225 -0.132029   0.137913 -0.168386  -0.075813  FK3VL2VLJCL6      1  \n",
       "105 -0.148888 -0.217568  -0.181909 -0.240998  -0.089408  C39VMC1YJCL7      1  \n",
       "106 -0.144120 -0.205769  -0.172912 -0.228944  -0.087976  G0NVN150JCLJ      1  \n",
       "107 -0.135244 -0.185002  -0.075759 -0.164602  -0.085176  FK2VQ5TTJCL8      1  \n",
       "108 -0.137069 -0.178817  -0.163893 -0.212574  -0.085267  F17VK4C1JCL8      1  \n",
       "109 -0.140267 -0.190331  -0.164269 -0.212860  -0.078226  DNPVLSKCJCL8      1  \n",
       "110 -0.137607 -0.192649  -0.155499 -0.129220  -0.086006  G6TVJ0XUJCLJ      1  \n",
       "111 -0.147372 -0.213068  -0.177680 -0.235176  -0.088869  F2MVP5CLJCLH      1  \n",
       "112 -0.136621 -0.156532  -0.170993 -0.141437  -0.088470  G6VVRG07JCLJ      1  \n",
       "113 -0.147181 -0.213209  -0.178259 -0.215681  -0.085343  DNQVR0H7JCL9      1  \n",
       "114 -0.079196 -0.194467   0.001057 -0.189196  -0.086642  FK1VM89TJCL8      1  \n",
       "115 -0.134623 -0.187003  -0.148707  0.036789  -0.074757  FK4VP392JCL6      1  \n",
       "116 -0.147004 -0.213720  -0.178218 -0.236713  -0.088930  DNQVRLSDJCL8      1  \n",
       "117 -0.138829 -0.148563  27.827937 -0.176879  -0.078479  F17VQ2LRJCLG      1  \n",
       "118 -0.148366 -0.216552  -0.179887 -0.238795  -0.088857  DNQVN9MJJCL6      1  \n",
       "119 -0.136666 -0.118975  -0.134651 -0.206776   0.821217  F2LVN55FJCL8      1  \n",
       "120 -0.136335 -0.072038   0.803855 -0.197073  -0.068380  G6WVN1Y8JCL8      1  \n",
       "121 -0.147147 -0.200547  -0.169853 -0.196894  -0.085423  G6VVV63HJCL6      1  \n",
       "122 -0.146194 -0.123906  -0.109743 -0.216281  -0.086936  F17VQ544JCLJ      1  \n",
       "123 -0.148763 -0.216801  -0.181811 -0.240735  -0.089338  G6TVNU2UJCL8      1  \n",
       "124 -0.126195 -0.196479  -0.143266 -0.204579  -0.082357  G6YVQE61JCLH      1  \n",
       "125 -0.145232 -0.160459  -0.158406 -0.204858  -0.087745  DNPVP9GJJCLJ      1  \n",
       "126 -0.138087 -0.134099  -0.085666  1.995897  -0.054678  DNPVKWBMJCL9      1  \n",
       "127 -0.148812 -0.215764  -0.180151 -0.239507  -0.089356  G0NVM8S3JCLJ      1  \n",
       "128 -0.137795 -0.132990  -0.044132 -0.180444  -0.069680  DNPVP67UJCL6      1  \n",
       "129 -0.145405 -0.201124  -0.178551 -0.231478  -0.085815  FK1VPPGUJCLH      1  \n",
       "130 -0.139626 -0.167119  -0.123055 -0.212270  -0.082201  G6TVLLRSJCLJ      1  \n",
       "131 -0.145096 -0.197767  -0.173037 -0.223091  -0.087076  F17VM7BJJCL9      1  \n",
       "132 -0.148865 -0.217371  -0.181933 -0.240945  -0.089417  F2LVRMF9JCL8      1  \n",
       "133 -0.115810 -0.026820  -0.102517  0.165922  -0.083579  F18VQX5EJCL6      1  \n",
       "..        ...       ...        ...       ...        ...           ...    ...  \n",
       "814 -0.010661 -0.180407  -0.162043 -0.172675  18.795826  G6VVLC0ZJCL9      0  \n",
       "815 -0.123374 -0.178232   0.215602 -0.139916  -0.086108  G0PVT98PJCLJ      0  \n",
       "816 -0.136090 -0.166585  -0.117926 -0.144217  -0.081197  DNQVR8ZAJCL8      0  \n",
       "817 -0.115212 -0.024371  -0.104496 -0.204370  -0.033137  F2MVPRBNJCL9      0  \n",
       "818  0.014268 -0.170359  -0.161535 -0.144043  -0.084871  F17VMG48JCLH      0  \n",
       "819 -0.114596 -0.158331  -0.157826 -0.187064  -0.068372  F17VK09UJCLH      0  \n",
       "820 -0.136194 -0.167465  -0.111722  0.152280  -0.069776  F2LW1X2QJCLJ      0  \n",
       "821 -0.113448 -0.147587  -0.160641 -0.106131  -0.082686  G0NVTSUJJCL8      0  \n",
       "822 -0.134187 -0.166405  -0.055475 -0.140503  -0.083817  G6TVT9FAJCL8      0  \n",
       "823 -0.123668 -0.148740  -0.145325 -0.109837  -0.083111  F17VR4CEJCLH      0  \n",
       "824 -0.138939 -0.175885   0.309375 -0.178527  -0.084062  C39VTTDHJCLH      0  \n",
       "825 -0.120885 -0.056983  -0.149064 -0.201769  -0.083928  FK1VQ13DJCL7      0  \n",
       "826 -0.126382  0.827890  -0.160208 -0.124738  -0.076729  DNQVT61RJCL7      0  \n",
       "827 -0.143719 -0.164509  -0.163442 -0.197631  -0.082260  F2MVQCFFJCL6      0  \n",
       "828 -0.136364 -0.016874  -0.142777 -0.192082  -0.009467  F2LVRH2EJCL9      0  \n",
       "829 -0.136651 -0.102223   0.141439  0.195586  -0.065108  DNQVWJKUJCLH      0  \n",
       "830  0.063533 -0.143877  -0.151384 -0.199785  -0.083173  G0NVQCUNJCLJ      0  \n",
       "831 -0.142471 -0.162392  -0.127912 -0.181571  -0.082764  F2LVPR6NJCL8      0  \n",
       "832  2.721884 -0.150358  -0.133230 -0.186939  -0.073226  DNQVTPPBJCL8      0  \n",
       "833 -0.138699 -0.064075  -0.139945 -0.151143  -0.081066  C39VM8V4JCLF      0  \n",
       "834 -0.107651 -0.178040   0.313237 -0.189931  -0.074633  F17VPJ2TJCL8      0  \n",
       "835 -0.141520 -0.144199   0.203576 -0.189262  -0.083990  FK3VQ6GYJCL8      0  \n",
       "836 -0.102105 -0.177170  -0.003482  1.751201  -0.082724  DNPVMTP6JCL7      0  \n",
       "837 -0.139828 -0.190698  -0.161311 -0.204561  -0.072865  FK1VMP9XJCLH      0  \n",
       "838 -0.091905 -0.181418  -0.157575 -0.107311  -0.084562  FK3VL2N5JCL6      0  \n",
       "839 -0.140981 -0.193023  -0.132044 -0.206185  -0.084702  F2MVM98FJCLJ      0  \n",
       "840 -0.135941 -0.183197  -0.156282 -0.115766  -0.082493  F2NVP4LNJCL6      0  \n",
       "841 -0.140199 -0.153228   1.661736 -0.208782  -0.085911  DNQVMB2AJCL8      0  \n",
       "842 -0.135780 -0.170496  -0.157207 -0.199011  -0.085167  F17VL8SKJCL8      0  \n",
       "843 -0.063215 -0.184759  -0.163797 -0.034948  -0.031915  F17VRYDXJCL9      0  \n",
       "\n",
       "[507 rows x 98 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"mean: \", d.iloc[:,:-2].mean(axis=0).mean())\n",
    "print(\"std: \", d.iloc[:,:-2].std(axis=0).mean())\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, partition the dataset into train, dev, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "labels = dataset.targets\n",
    "indices = range(len(labels))\n",
    "train_dev_ids, test_ids = train_test_split(indices,\n",
    "                                        stratify=labels,\n",
    "                                        test_size=0.33, \n",
    "                                        random_state=RSEED) #stratified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counts(indices, labels, categories):\n",
    "    #todo\n",
    "    \"\"\"check ratio of 0's and 1's in the labels selected by 'indices'\n",
    "    - indices: 1D array for selected indices\n",
    "    - labels: an array of 0s and 1s\n",
    "    \"\"\"\n",
    "    filtered = labels[indices]\n",
    "    if isinstance(filtered, torch.Tensor): filtered = filtered.numpy();\n",
    "    if isinstance(filtered, list ): filtered = np.array(filtered);\n",
    "        \n",
    "    print([sum(filtered==categories[i]) for i in range(len(categories))])\n",
    "    \n",
    "def print_ratios(indices, labels, categories):\n",
    "    #todo\n",
    "    \"\"\"check ratio of 0's and 1's in the labels selected by 'indices'\n",
    "    - indices: 1D array for selected indices\n",
    "    - labels: an array of 0s and 1s\n",
    "    \"\"\"\n",
    "    filtered = labels[indices]\n",
    "    if isinstance(filtered, torch.Tensor): filtered = filtered.numpy();\n",
    "    if isinstance(filtered, list ): filtered = np.array(filtered);\n",
    "    n = len(filtered)\n",
    "        \n",
    "    print([sum(filtered==categories[i])/n for i in range(len(categories))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7345132743362832, 0.26548672566371684]\n",
      "[0.7321428571428571, 0.26785714285714285]\n"
     ]
    }
   ],
   "source": [
    "categories = np.unique(dataset.targets)\n",
    "print_ratios(train_dev_ids, labels, categories)\n",
    "print_ratios(test_ids, labels, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max indices should corresponds to 0 and 338: (0, 338)\n"
     ]
    }
   ],
   "source": [
    "# partition train_ids into train_ids and dev_ids\n",
    "train_dev_labels = labels[train_dev_ids]\n",
    "indices = range(len(train_dev_ids))\n",
    "train_ids, dev_ids = train_test_split(indices, \n",
    "                                     stratify=train_dev_labels,\n",
    "                                     test_size=0.5,\n",
    "                                     random_state=RSEED)\n",
    "imax = max(max(train_ids, dev_ids))\n",
    "imin = min(min(train_ids, dev_ids))\n",
    "print(f\"min and max indices should corresponds to 0 and {len(train_dev_labels)-1}: {imin, imax}\")\n",
    "\n",
    "# map it back to index to (the original) y\n",
    "train_ids = np.array(train_dev_ids)[train_ids]\n",
    "dev_ids = np.array(train_dev_ids)[dev_ids]\n",
    "\n",
    "# make test_ids also a np array\n",
    "test_ids = np.array(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7337278106508875, 0.26627218934911245]\n",
      "[0.7352941176470589, 0.2647058823529412]\n",
      "[0.7321428571428571, 0.26785714285714285]\n"
     ]
    }
   ],
   "source": [
    "# check ratios\n",
    "for index_array in [train_ids, dev_ids, test_ids]:\n",
    "    print_ratios(index_array, labels, categories)\n",
    "    \n",
    "        \n",
    "# intersection check\n",
    "s1 = set(train_ids); s2 = set(dev_ids); s3 = set(test_ids)\n",
    "assert( len(s1.intersection(s2).intersection(s3)) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Luna dataset and dataloader objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a transformation from numpy -> torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class npToFloatTensor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, sample):\n",
    "        datum, target, idx = sample #np.ndarray, an integer, \n",
    "        datum = torch.from_numpy(datum).type(torch.float) #float32\n",
    "        \n",
    "        # BCLoss takes in both int and float tensor\n",
    "        # CrossEntropyLoss requires target to be LongTensor, ie. int\n",
    "        target = torch.tensor(target, dtype=torch.float)\n",
    "        #todo: to int?\n",
    "        return (datum, target, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {'train': train_ids, \n",
    "             'dev': dev_ids, \n",
    "             'test': test_ids}\n",
    "train_dataset = LunaPickleDataset(fpath, \n",
    "                                  partition['train'], \n",
    "                                  root_dir=ROOT,\n",
    "                                  transform=npToFloatTensor())\n",
    "dev_dataset = LunaPickleDataset(fpath, \n",
    "                                partition['dev'],\n",
    "                                root_dir=ROOT,\n",
    "                                transform=npToFloatTensor())\n",
    "\n",
    "test_dataset = LunaPickleDataset(fpath, \n",
    "                                 partition['test'], \n",
    "                                 root_dir=ROOT,\n",
    "                                 transform=npToFloatTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. new dataloader instance\n",
    "data_params = {'batch_size': 32,\n",
    "              'shuffle': True,\n",
    "              'num_workers':4}\n",
    "train_loader = DataLoader(dataset=train_dataset, **data_params)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=len(train_ids), shuffle=True)\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=len(dev_ids), shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=len(test_ids), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cycles:  6\n",
      "[tensor([[-2.8548e-01, -2.4622e-01, -4.0994e-02,  ...,  1.0654e-01,\n",
      "         -1.8526e-01, -7.9718e-02],\n",
      "        [-5.4125e-01, -3.9697e-01, -3.3258e-01,  ..., -1.8129e-01,\n",
      "         -2.3993e-01, -8.9263e-02],\n",
      "        [ 7.6885e-01,  3.1795e-01,  1.4269e+00,  ..., -1.5648e-01,\n",
      "         -1.8455e-01, -8.4055e-02],\n",
      "        ...,\n",
      "        [ 1.0714e+00,  6.6363e-01,  3.3472e-01,  ..., -1.5603e-01,\n",
      "         -1.2652e-01, -8.4988e-02],\n",
      "        [-1.0535e+00, -5.3351e-01, -9.1984e-01,  ..., -8.0400e-02,\n",
      "         -1.6516e-01, -8.3818e-02],\n",
      "        [ 3.5735e-02, -2.6498e-01,  5.9305e-01,  ..., -1.5721e-01,\n",
      "         -1.9901e-01, -8.5167e-02]]), tensor([ 0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,\n",
      "         1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.]), tensor([   5,  118,  153,   40,  105,   58,    8,   66,  124,   78,\n",
      "         163,   28,  103,   86,   63,   20,  122,   80,   48,   10,\n",
      "          75,    7,  165,   93,  167,  130,  109,   83,   85,  139,\n",
      "          98,   36])]\n",
      "num of cycles:  1\n",
      "[tensor([[-5.4653e-01, -3.9466e-01, -8.7377e-01,  ..., -1.3138e-01,\n",
      "         -8.2106e-02, -7.4141e-02],\n",
      "        [-9.9559e-01, -1.5697e-01,  1.5236e-01,  ..., -1.8015e-01,\n",
      "         -2.3951e-01, -8.9356e-02],\n",
      "        [-9.3704e-01, -4.1263e-01,  5.6924e-01,  ..., -1.8166e-01,\n",
      "         -2.4059e-01, -8.9370e-02],\n",
      "        ...,\n",
      "        [ 1.5641e-02, -3.1554e-01, -4.4450e-01,  ...,  5.6164e-01,\n",
      "         -2.0656e-01, -8.6551e-02],\n",
      "        [-1.0214e+00, -4.5636e-01, -9.1785e-01,  ..., -1.5898e-01,\n",
      "         -1.7734e-01, -8.4374e-02],\n",
      "        [-1.0804e+00, -4.6426e-01, -7.7551e-01,  ..., -1.5138e-01,\n",
      "         -1.9978e-01, -8.3173e-02]]), tensor([ 0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "         0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
      "         1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
      "         1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "         0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "         0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.]), tensor([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "          10,   11,   12,   13,   14,   15,   16,   17,   18,   19,\n",
      "          20,   21,   22,   23,   24,   25,   26,   27,   28,   29,\n",
      "          30,   31,   32,   33,   34,   35,   36,   37,   38,   39,\n",
      "          40,   41,   42,   43,   44,   45,   46,   47,   48,   49,\n",
      "          50,   51,   52,   53,   54,   55,   56,   57,   58,   59,\n",
      "          60,   61,   62,   63,   64,   65,   66,   67,   68,   69,\n",
      "          70,   71,   72,   73,   74,   75,   76,   77,   78,   79,\n",
      "          80,   81,   82,   83,   84,   85,   86,   87,   88,   89,\n",
      "          90,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
      "         100,  101,  102,  103,  104,  105,  106,  107,  108,  109,\n",
      "         110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
      "         120,  121,  122,  123,  124,  125,  126,  127,  128,  129,\n",
      "         130,  131,  132,  133,  134,  135,  136,  137,  138,  139,\n",
      "         140,  141,  142,  143,  144,  145,  146,  147,  148,  149,\n",
      "         150,  151,  152,  153,  154,  155,  156,  157,  158,  159,\n",
      "         160,  161,  162,  163,  164,  165,  166,  167,  168,  169])]\n",
      "num of cycles:  1\n",
      "[tensor([[-7.6003e-01, -4.4975e-01, -8.7156e-01,  ..., -4.9566e-02,\n",
      "         -1.9875e-01, -8.2858e-02],\n",
      "        [ 3.8592e-01, -2.3127e-01, -7.5140e-01,  ..., -1.5737e-01,\n",
      "         -2.0606e-01, -8.5110e-02],\n",
      "        [ 9.4379e-01,  3.0591e-01,  5.0908e-01,  ..., -8.0798e-03,\n",
      "          1.4646e+01, -8.5210e-02],\n",
      "        ...,\n",
      "        [-9.5085e-01, -1.3916e-01, -5.1219e-01,  ..., -1.6021e-01,\n",
      "         -1.2474e-01, -7.6729e-02],\n",
      "        [-6.5352e-01, -3.3420e-01, -7.7142e-01,  ..., -1.3381e-01,\n",
      "         -2.0320e-01, -8.0171e-02],\n",
      "        [-9.0703e-01, -3.7683e-01, -9.2193e-01,  ..., -1.5953e-01,\n",
      "         -1.8164e-01, -7.4483e-02]]), tensor([ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,\n",
      "         1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
      "         0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
      "         1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
      "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "         0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "         1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
      "         0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,\n",
      "         1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
      "         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), tensor([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "          10,   11,   12,   13,   14,   15,   16,   17,   18,   19,\n",
      "          20,   21,   22,   23,   24,   25,   26,   27,   28,   29,\n",
      "          30,   31,   32,   33,   34,   35,   36,   37,   38,   39,\n",
      "          40,   41,   42,   43,   44,   45,   46,   47,   48,   49,\n",
      "          50,   51,   52,   53,   54,   55,   56,   57,   58,   59,\n",
      "          60,   61,   62,   63,   64,   65,   66,   67,   68,   69,\n",
      "          70,   71,   72,   73,   74,   75,   76,   77,   78,   79,\n",
      "          80,   81,   82,   83,   84,   85,   86,   87,   88,   89,\n",
      "          90,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
      "         100,  101,  102,  103,  104,  105,  106,  107,  108,  109,\n",
      "         110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
      "         120,  121,  122,  123,  124,  125,  126,  127,  128,  129,\n",
      "         130,  131,  132,  133,  134,  135,  136,  137,  138,  139,\n",
      "         140,  141,  142,  143,  144,  145,  146,  147,  148,  149,\n",
      "         150,  151,  152,  153,  154,  155,  156,  157,  158,  159,\n",
      "         160,  161,  162,  163,  164,  165,  166,  167])]\n"
     ]
    }
   ],
   "source": [
    "for loader in [train_loader, dev_loader, test_loader ]:\n",
    "    print('num of cycles: ', len(loader))\n",
    "    dataiter = iter(loader)\n",
    "#     print('dtype: ', type(dataiter.next()[0][0]))\n",
    "    print(dataiter.next())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCModel(nn.Module):    \n",
    "    def __init__(self, inDim, l1Dim, l2Dim, activation):\n",
    "        \"\"\" \n",
    "        inDim: input dimension\n",
    "        l1Dim: number of units in the first layer\n",
    "        l2Dim: number of units in the second layer\n",
    "        activation: (torch.nn.modules.activation) activation function instance\n",
    "            eg.nn.Sigmoid() or nn.Relu()\n",
    "        \"\"\"\n",
    "        super(BCModel, self).__init__()\n",
    "        self.l1 = nn.Linear(inDim, l1Dim)\n",
    "        self.l2 = nn.Linear(l1Dim, l2Dim)\n",
    "        self.l3 = nn.Linear(l2Dim, 1)\n",
    "        \n",
    "        # Hidden layers' activation\n",
    "#         self.relu = nn.ReLU() #elementwise relu\n",
    "        self.activation = activation\n",
    "    \n",
    "        # todo: batch norm layer\n",
    "        \n",
    "        # Last layer activation\n",
    "        self.sigmoid = nn.Sigmoid() #elementwise sigmoid activation\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"input and output are both tensors\"\"\"\n",
    "        out1 = self.activation(self.l1(x)) #todo: add batch norm layer\n",
    "        out2 = self.activation(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "    \n",
    "    def print_params(self):\n",
    "        for param in self.parameters():\n",
    "            print(param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick side note on nn.Sigmoid and nn.Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `nn.Sigmoid` is best considered a softmax activation for a binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9390],\n",
      "        [ 0.2637],\n",
      "        [ 0.2119],\n",
      "        [ 0.1769]])\n",
      "tensor(1.5915)\n"
     ]
    }
   ],
   "source": [
    "sig = nn.Sigmoid()\n",
    "x = torch.randn(4).view(4,-1) # 1D tensor of length 4\n",
    "out = sig(x) # apply elementwise sigmoid function to x\n",
    "print(out)\n",
    "print(out.sum()) # doesn't make it a probability density along the dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `nn.Softmax` is a classifier layer that takes in a set of numbers and make them into a probability density along the specified dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6819, -0.1159, -3.1950],\n",
      "        [-1.1939, -2.2090, -0.5325],\n",
      "        [-2.1591, -2.2516, -0.2493],\n",
      "        [-2.5157, -0.8751, -0.6884]])\n",
      "tensor([-5.9927, -3.9354, -4.6601, -4.0792])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.LogSoftmax(dim=1)\n",
    "x = torch.randn(4,3) #4 data points, each of length 3\n",
    "out = softmax(x)\n",
    "print(out)\n",
    "print(out.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification model\n",
    "# set number of hidden units\n",
    "H1 = 3\n",
    "H2 = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = BCModel(X.shape[1], H1, H2, nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1795,  0.2851,  0.1110,  0.2702,  0.1065, -0.3303, -0.0007,\n",
      "         -0.0522],\n",
      "        [ 0.0976, -0.2015, -0.1281, -0.1898,  0.2529,  0.1845,  0.1104,\n",
      "         -0.1593],\n",
      "        [ 0.2818, -0.3120,  0.0346,  0.1108,  0.1371, -0.1614,  0.2583,\n",
      "          0.2263]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0911, -0.2408, -0.0132])\n",
      "Parameter containing:\n",
      "tensor([[-0.1177,  0.5082,  0.5562],\n",
      "        [-0.2805, -0.5222,  0.2566],\n",
      "        [ 0.0169, -0.3271, -0.3990],\n",
      "        [-0.4858,  0.1549,  0.2004]])\n",
      "Parameter containing:\n",
      "tensor([-0.3915, -0.4134, -0.3627, -0.5242])\n",
      "Parameter containing:\n",
      "tensor([[ 0.2615, -0.4411, -0.4228, -0.1988]])\n",
      "Parameter containing:\n",
      "tensor([ 0.4205])\n"
     ]
    }
   ],
   "source": [
    "model.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.6692452430725098\n",
      "Epoch 10: 0.6690557599067688\n",
      "Epoch 20: 0.6688683032989502\n",
      "Epoch 30: 0.6686822175979614\n",
      "Epoch 40: 0.6684972643852234\n",
      "Epoch 50: 0.6683138012886047\n",
      "Epoch 60: 0.6681327223777771\n",
      "Epoch 70: 0.6679514646530151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([759])) that is different to the input size (torch.Size([759, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: 0.6677728295326233\n",
      "Epoch 90: 0.6675955057144165\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "ls = []\n",
    "for epoch in range(100):\n",
    "    #Forward entire dataset\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    #Compute loss\n",
    "    l = criterion(y_pred, y)\n",
    "    ls.append(l)\n",
    "    \n",
    "    if epoch%10 == 0:print(f\"Epoch {epoch}: {l}\")\n",
    "    \n",
    "    #Clear any accumulated gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Backprop\n",
    "    l.backward() \n",
    "    # now each parameter's .grad.data is set to the gradient from this \n",
    "    # forward pass\n",
    "    \n",
    "    #Update parameters\n",
    "    optimizer.step()\n",
    "    # update each registered parameter using the parameter's \n",
    "    #.grad.data and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f987ef74390>]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4FeX5//H3JwmL7DvKDhJAsCIQUFnCJosbaFUEqxU3vi6IgtLq11pb235/ba2AVKoiVsWKiIiAuEBEZROQsEMii0EhghJ2AWW9f3+coT2NwRxCwklO7td15UrmOc/M3HMdPR+eZ+bMyMxwzjnn8iIu2gU455wrujxEnHPO5ZmHiHPOuTzzEHHOOZdnHiLOOefyzEPEOedcnnmIOOecyzMPEeecc3nmIeKccy7PEqJdQEGrVq2aNWjQINplOOdckbF06dIdZlY9kr4xHyINGjQgNTU12mU451yRIemrSPv6dJZzzrk88xBxzjmXZx4izjnn8sxDxDnnXJ5FFCKSektaJ2mjpIdP0qefpDRJayVNCGuvJ2mWpPTg9QZBezdJyyStkfSKpISg/ReSVgU/n0pqGbatLyWtlrRCkp8td865KMv16ixJ8cAYoAeQCSyRNN3M0sL6JAKPAB3MbLekGmGbGA/8ycxSJJUDjkuKA14BupvZeklPALcALwKbgM7Bdi4DxgIXhW2vq5ntOJ2Dds45lz8iGYm0AzaaWYaZHQYmAn2z9bkTGGNmuwHMbDuApOZAgpmlBO37zewgUBU4ZGbrg/VTgGuDPp+e2A6wCKiT56NzzjlXoCIJkdrAlrDlzKAtXBOgiaQFkhZJ6h3WvkfSFEnLJT0ZjGx2ACUkJQX9rgPq5rDv24H3w5YNmCVpqaRBEdSeZ6Nnb2DFlj0FuQvnnCvyIgkR5dCW/cHsCUAi0AUYAIyTVClo7wQ8BLQFGgEDLfRg9/7ASEmfAd8BR/9rp1JXQiHy67DmDmbWGrgMuFdSco4FS4MkpUpKzcrKiuAQ/9veg0eYsHgzP//HAp54J40Dh47mvpJzzhVDkYRIJv89SqgDbM2hzzQzO2Jmm4B1hEIlE1geTIUdBaYCrQHMbKGZdTKzdsBcYMOJjUm6ABgH9DWznSfazWxr8Hs78DahqbYfMbOxZpZkZknVq0f0zf3/UrFMCWYNS+bGi+rxzwWb6DlyLvM3+GkY55zLLpIQWQIkSmooqSShEcT0bH2mAl0BJFUjNI2VEaxbWdKJT/JuQFrQr0bwuxSh0cZzwXI9YApwc9g5EySVlVT+xN9AT2DNqR5wpCqULsEfr/4Zb951CaVKxHHTi4v544w0Dh09VlC7dM65IifXEAlGEIOBmUA6MMnM1kp6QlKfoNtMYKekNOBjYLiZ7TSzY4SmsmZLWk1oauyFYJ3hktKBVcA7ZvZR0P5bQife/5HtUt6awHxJK4HPgHfN7IPTO/zctW1QhXfv68TNF9dn3PxNXD3mUzZ8+11B79Y554oEhU5PxK6kpCTLrxswzk7/luGTV7H/0FF+1aspt3VoSFxcTqeMnHOu6JK01MyScu/p31g/Jd3Pq8nMB5JJTqzGH99N58Zxi9iy62C0y3LOuajxEDlF1cuX4oVfJvHXay9gzdf76DlyLmPnfsGRY8ejXZpzzp1xHiJ5IIl+bevywQOd6NC4Kv/33udc9ff5LNu8O/eVnXMuhniInIY6lcvwwi+TeP7mNuz9/gjXPfspI1LWc9RHJc65YsJD5DRJoleLs5k1NJlrWtVh9OwNXP/8Qr7aeSDapTnnXIHzEMkn5UuX4Kl+Lfn7gFZs3L6fy56ex0sLNnHseGxf/eacK948RPLZVS1rMfOBZNo1rMLv30njuuf8eyXOudjlIVIAalU6i5cGtmXkDS35cscBrhg9n+fmfOGjEudczPEQKSCSuKZVHVKGdaZrs+r8+f3PucHPlTjnYoyHSAGrVq4Uz93UhhH9WrLu2++47Ol5vLb4K2L9TgHOueLBQ+QMkMTPW9dh5gPJtK5XmUffXsOtLy9h+74fol2ac86dFg+RM6hWpbMYf1s7fndVcxZ+sZOeo+YyZVmmj0qcc0WWh8gZFhcnBnZoyLtDOtGoWlmGTVrJLS8tIXO334PLOVf0eIhESeMa5Xjzrvb87qrmpH65i54j5zLxs80+KnHOFSkeIlEUH4xKZg1NplW9Sjw8ZTV3jl/Kzv2Hol2ac85FxEOkEKhTuQyv3nYRv7niPOZuyKLXqHl8sGZbtMtyzrlceYgUEnFx4o5OjZg+uAM1ypfirn8t465Xl/oVXM65Qs1DpJBpdnYFpg3uwK96N+Wjddu5dMQc3kzd4udKnHOFUkQhIqm3pHWSNkp6+CR9+klKk7RW0oSw9nqSZklKD15vELR3k7RM0hpJr0hKCNolaXSwr1WSWodt6xZJG4KfW07nwAuzEvFx3NOlMR/c34lmZ1dg+ORV3PbyEr7Z66MS51zhkmuISIoHxgCXAc2BAZKaZ+uTCDwCdDCzFsADYS+PB540s/OAdsB2SXHAK0B/Mzsf+Ao4EQqXAYnBzyDg2WAfVYDHgYuC7TwuqXJeDrqoaFS9HBMHXczjVzVnYcZOeoyc498rcc4VKpGMRNoBG80sw8wOAxOBvtn63AmMMbPdAGa2HSAImwQzSwna95vZQaAqcMjM1gfrpwDXBn/3BcZbyCKgkqRzgF5AipntCvaTAvTO22EXHXFx4tYODfng/mSanV2eYZNWcs9ry9h14HC0S3POuYhCpDawJWw5M2gL1wRoImmBpEWSeoe175E0RdJySU8GI5sdQAlJSUG/64C6uewvkjpiVoNqZZk46BIevqwZH6Z/S69Rc/kw7dtol+WcK+YiCRHl0JZ9PiWB0PRTF2AAME5SpaC9E/AQ0BZoBAy00HxMf2CkpM+A74CjuewvkjpCG5AGSUqVlJqVlfUTh1a0xMeJuzqfy7R7O1K1bEnuGJ/Kfa8vZ4d/r8Q5FyWRhEgm/xklANQBtubQZ5qZHTGzTcA6QqGSCSwPpsKOAlOB1gBmttDMOplZO2AusCGX/UVSB8G2x5pZkpklVa9ePYJDLFqa16rA9MEdGdajCTPXfEOPEXOYtuJrP1finDvjIgmRJUCipIaSShIaQUzP1mcq0BVAUjVC01gZwbqVJZ34JO8GpAX9agS/SwG/Bp4L+kwHfhlcpXUxsNfMtgEzgZ6SKgcn1HsGbcVSyYQ4hnRP5N0hHWlQrSz3T1zB4NeXs9vPlTjnzqBcQyQYQQwm9IGdDkwys7WSnpDUJ+g2E9gpKQ34GBhuZjvN7BihqazZklYTmpJ6IVhnuKR0YBXwjpl9FLS/RyiANgZ97wnq2AX8gVAwLQGeCNqKtcSa5Xnzfy5heK+mzFr7DT1HzeWjz/1ciXPuzFCsT4EkJSVZampqtMs4I9Zu3cuwN1ay7tvv+Hnr2jx+ZQsqlikR7bKcc0WMpKVmlpR7T//GekxpUasi0+/rwH3dGjNtxVYuHTmHWWu/iXZZzrkY5iESY0olxPNgz6ZMu7cD1cqVYtCrSxk8YZnfGdg5VyA8RGLU+bUrMu3eDqEruNZ+w6Uj5jB95Va/gss5l688RGLYf67g6kT9qmUZ8vpyv4LLOZevPESKgSY1yzP5Lr+CyzmX/zxEiomE+Dju7dqYqfd2oHKZEtz2cir3T1zu50qcc6fFQ6SYaVGrIu/c15Eh3RN5b/U2uo/wOwM75/LOQ6QYKpUQz7AeTXh3SCcaVSvLsEkrGfTqUr8Hl3PulHmIFGNNapbnzbva8+jl5zFnfRY9R871Z7s7506Jh0gxFx8n7kxuxIz7OlKrUmnu+tcy7nt9uT+vxDkXEQ8RB4RGJW/f04EHezThgzXb6DFiDu+u8lGJc+6neYi4fysRH8d93RN5576O1Kp0FvdOWMZdry5l+3f+bHfnXM48RNyPNDu7Am/f055f927GR+u202PEXN5a6ldwOed+zEPE5SghPo67u5zLe0M60bhGOR58cyV3jl9K1nd+BZdz7j88RNxPalyjHJP+5xJ+c8V5zN2QRa9RfgWXc+4/PERcruLjxB2dGvHufR2pXeks7vrXMu6dsMxHJc45DxEXucSa5ZlyT3se6tmElLXf0mPkHCb7uRLnijUPEXdKSsTHMbhbIu/d34nEGuV46M2V3P5KKtv3+RVczhVHHiIuTxrXKMcbgy7hd1c159MvdtBz1FxmrNoa7bKcc2dYRCEiqbekdZI2Snr4JH36SUqTtFbShLD2epJmSUoPXm8QtHeXtEzSCknzJTUO2kcGbSskrZe0J2xbx8Jem346B+5OX1ycGNih4b+fVzJ4wnLu/pd/r8S54kS5zWdLigfWAz2ATGAJMMDM0sL6JAKTgG5mtltSDTPbHrz2CfAnM0uRVA44bmYHJa0H+ppZuqR7gHZmNjDbvu8DWpnZbcHyfjMrdyoHmJSUZKmpqaeyisuDo8eOM3ZeBqM+3MBZJeJ59IrzuL5NHSRFuzTn3CmStNTMkiLpG8lIpB2w0cwyzOwwMBHom63PncAYM9sNEBYgzYEEM0sJ2veb2cFgHQMqBH9XBHKaCxkAvB7JgbjoSoiP454ujXn//k40qVmOX01exS//+Rlbdh3MfWXnXJEVSYjUBraELWcGbeGaAE0kLZC0SFLvsPY9kqZIWi7pyWBkA3AH8J6kTOBm4M/hG5RUH2gIfBTWXFpSarCPq09WsKRBQb/UrKysCA7R5Zdzq4fOlfyhbwuWfbWbXqPmMn7hlxw/7ldwOReLIgmRnOYjsn8iJACJQBdCo4dxkioF7Z2Ah4C2QCNgYLDOUOByM6sDvASMyLbN/sBkMzsW1lYvGGLdCIySdG5OBZvZWDNLMrOk6tWrR3CILj/FxYmbL2nAzKHJtKlfmd9OW0v/FxaxeaePSpyLNZGESCZQN2y5Dj+eesoEppnZETPbBKwjFCqZwPJgKuwoMBVoLak60NLMFgfrvwG0z7bN/mSbyjKzrcHvDOAToFUE9bsoqVO5DONva8dfr7uA9K376P30XF5d6KMS52JJJCGyBEiU1FBSSUIf7tmvjJoKdAWQVI3QNFZGsG7lIDQAugFpwG6goqQmQXsPIP3ExiQ1BSoDC8PaKksqFbaPDsG2XCEmiX5JdZk5NJmkBlV4bNpafjFuMV/tPBDt0pxz+SDXEAlGEIOBmYQ+6CeZ2VpJT0jqE3SbCeyUlAZ8DAw3s53BVNRDwGxJqwlNjb0QbPNO4C1JKwmdExkettsBwET770vHzgNSg/4fA38Ov0LMFW61Kp3FK7e25c8//xlrvt5Lr1FzeXH+Jo75qMS5Ii3XS3yLOr/Et/DZtvd7Hn17DR99vp3W9Srx1+ta0rjGKV257ZwrQPl9ia9z+eqcimfx4i1JjLyhJRk7DnD56Hk8+8kXHD12PNqlOedOkYeIiwpJXNOqDrOGJtOtaQ3+8sHnXPOPT/n8m33RLs05dwo8RFxU1Shfmmdvas2YG1uzdc/3XPX3+Yz6cD2Hj/qoxLmiwEPERZ0krrjgHFKGdebyn53DqA830OeZ+az5em+0S3PO5cJDxBUaVcqW5On+rRj3yyR2HTjM1WMWMCLFRyXOFWYeIq7QubR5TWYNTeaqlrUYPXsDfccs8FGJc4WUh4grlCqVKcnIGy7khV8msWP/IfqOWcDfZq7j0NFjua/snDtjPERcodajeU0+HNqZa1rV5pmPN3Ll6Pms2LIn9xWdc2eEh4gr9CqWKcHfrm/Jy7e2Zf+ho/z8Hwv4ywef88MRH5U4F20eIq7I6NK0BjOHJnN9m7o8+8kXXPn3+SzfvDvaZTlXrHmIuCKlQukS/OW6C3j51rYcOHSUa5/9lD/OSOP7wz4qcS4aPERckdSlaQ1mDU2mf7t6jJu/id5Pz2VRxs5ol+VcseMh4oqs8qVL8H/X/IwJd1yEGfQfu4hH317Ndz8ciXZpzhUbHiKuyGvfuBofPNCJ2zs2ZMJnm+k1ci4fr9se7bKcKxY8RFxMKFMygceubM5bd7enTKkEbn1pCcPeWMGeg4ejXZpzMc1DxMWU1vUq8+6QjtzXrTHTV27l0hFzeW/1tmiX5VzM8hBxMadUQjwP9mzKtMEdOLtiKe55bRl3vbqU7d/9EO3SnIs5HiIuZrWoVZGp93Tg172b8dG67fQYMZc3U7cQ60/zdO5MiihEJPWWtE7SRkkPn6RPP0lpktZKmhDWXk/SLEnpwesNgvbukpZJWiFpvqTGQftASVlB+wpJd4Rt6xZJG4KfW07nwF3xkBAfx91dzuX9+zvRpGY5hk9exc0vfsbmnQejXZpzMSHXZ6xLigfWAz2ATGAJMMDM0sL6JAKTgG5mtltSDTPbHrz2CfAnM0uRVA44bmYHJa0H+ppZuqR7gHZmNlDSQCDJzAZnq6MKkAokAQYsBdqY2U9+Zdmfse5OOH7ceO2zzfzl/c85dtwY3qspA9s3IC5O0S7NuUIlv5+x3g7YaGYZZnYYmAj0zdbnTmDMiQ/0sABpDiSYWUrQvt/MTvwT0IAKwd8Vga251NELSDGzXcF+UoDeEdTvHABxceLmi+sza2gyFzeqwhMz0uj/wiK+2nkg2qU5V2RFEiK1gS1hy5lBW7gmQBNJCyQtktQ7rH2PpCmSlkt6MhjZANwBvCcpE7gZ+HPY9q6VtErSZEl1T6EO53JVq9JZ/HNgW5687gLSt+6j96h5vLxgE8eP+7kS505VJCGS01g/+/9tCUAi0AUYAIyTVClo7wQ8BLQFGgEDg3WGApebWR3gJWBE0P4O0MDMLgA+BF45hTpCHaVBklIlpWZlZeV2fK4YksT1SXWZOTSZtg2r8Lt30rhh7EIysvZHuzTnipRIQiQTqBu2XIcfTz1lAtPM7IiZbQLWEQqVTGB5MBV2FJgKtJZUHWhpZouD9d8A2gOY2U4zOxS0vwC0OYU6CLYx1sySzCypevXqERyiK65qVTqLV24NjUrWffMdlz09j7Fzv+CYj0qci0gkIbIESJTUUFJJoD8wPVufqUBXAEnVCE1jZQTrVg5CA6AbkAbsBipKahK09wDSg/XPCdtunxPtwEygp6TKkioDPYM2507LiVHJh8M6k9ykOv/33uf8/NlP2fDtd9EuzblCL9cQCUYQgwl9YKcDk8xsraQnJPUJus0EdkpKAz4GhgcjimOEprJmS1pNaErqhWCbdwJvSVpJ6JzI8GBbQ4LLhFcCQwimv8xsF/AHQsG0BHgiaHMuX9SoUJqxN7dh9IBWbN55gCtGz+eZjzZw5NjxaJfmXKGV6yW+RZ1f4uvyYsf+Qzw+fS3vrtrG+bUr8NdrW9K8VoXcV3QuBuT3Jb7OFTvVypVizI2tee6m1nyz9wf6PDOfESnrOXTUH37lXDgPEed+Qu/zzyFlaGeuvOAcRs/ewBWj55P6pc+iOneCh4hzuahctiSj+rfipVvb8v3hY1z33EIem7qG/YeORrs056LOQ8S5CHUNHsl7a4cG/GvxV/QcMccffuWKPQ8R505B2VIJPH5VCybf1Z6ywcOvhr6xgl0H/OFXrnjyEHEuD9rUr8yMIR0Z0q0x76zcyqUj5jBtxdd+m3lX7HiIOJdHpRLiGdazKTOGdKRulTLcP3EFt728hK17vo92ac6dMR4izp2mZmdXYMrd7XnsyuYsythFz5Fzef2zzT4qccWCh4hz+SA+TtzesSEzH0jmZ7Ur8siU1dz04mJ/+JWLeR4izuWjelXL8NodF/Gna85n5Za99Bo1l3HzMvyGji5meYg4l8/i4sQvLqpPyrBkLjm3Kn98N51rn/2U9X5DRxeDPEScKyDnVDyLF29J4un+F/LVzgNc6Td0dDHIQ8S5AiSJvhfWJmVYZ3q2qMnfZq2n7zMLWPP13miX5ly+8BBx7gyoVq4Uz9zYmudvbkPW/kP0HbOAv81c5zd0dEWeh4hzZ1CvFmeTMjSZqy+szTMfb+TK0fNZ+pXf0NEVXR4izp1hlcqU5Kl+LXnp1rYcOHSUa59dyKNvr2bv90eiXZpzp8xDxLko6dq0BinDOnN7x4a8/tlmLh0xhw/WfBPtspw7JR4izkVR2VIJPHZlc6YP7kiN8qW4619LeWDicvYc9Bs6uqIhohCR1FvSOkkbJT18kj79JKUFz0efENZeT9IsSenB6w2C9u6SlklaIWm+pMZB+7Cg3ypJsyXVD9vWsaD/CknTT+fAnStMzq9dkan3dmDopU2YsWobPUbO9VGJKxJyfca6pHhgPdADyASWAAPMLC2sTyIwCehmZrsl1TCz7cFrnwB/MrMUSeWA42Z2UNJ6oK+ZpUu6B2hnZgMldQUWB33uBrqY2Q3BtvabWblTOUB/xroratZu3ctDb64ifds+erWoye/7nM/ZFUtHuyxXjOT3M9bbARvNLMPMDgMTgb7Z+twJjDGz3QBhAdIcSDCzlKB9v5mduJmQARWCvysCW4M+H4f1WQTUieRAnIsVLWpVZPrgDvy6dzM+WZdFjxFzmLDYb+joCqdIQqQ2sCVsOTNoC9cEaCJpgaRFknqHte+RNEXScklPBiMbgDuA9yRlAjcDf85h37cD74ctl5aUGuzj6ghqd65IKhEfx91dzmXW0GR+Vqci//v2am5+8TMyd/sNHV3hEkmIKIe27P8kSgASgS7AAGCcpEpBeyfgIaAt0AgYGKwzFLjczOoALwEj/mun0k1AEvBkWHO9YIh1IzBK0rk5FiwNCsImNSsrK4JDdK5wql+17L9v6Lh88256jZzLqwu/5Ljf0NEVEpGESCZQN2y5DsHUU7Y+08zsiJltAtYRCpVMYHkwFXYUmAq0llQdaGlmi4P13wDan9iYpEuBR4E+ZnboRLuZnZjyygA+AVrlVLCZjTWzJDNLql69egSH6FzhJYVu6DhzaDKt61fmsWlruf75hWzwGzq6QiCSEFkCJEpqKKkk0B/IfmXUVKArgKRqhKaxMoJ1KwehAdANSAN2AxUlNQnaewDpwfqtgOcJBcj2EzuQVFlSqbB9dAi25VyxUKdyGcbf1o6nrm9JRtZ+Lh89jxEp6/3WKS6qEnLrYGZHJQ0GZgLxwD/NbK2kJ4BUM5sevNZTUhpwDBhuZjsBJD0EzJYkYCnwQrDNO4G3JB0nFCq3Bbt8EigHvBlahc1m1gc4D3g+6B8H/Dn8CjHnigNJXNumDl2aVucPM9IYPXsD76/exl+uu4DW9SpHuzxXDOV6iW9R55f4ulj28efbefTt1Wzb9wMD2zfgoZ5NKVsq138bOveT8vsSX+dcIdW1WQ1mDevMTRfV56UFX9Jz5FzmrPeLSdyZ4yHiXBFXrlQCf7j6fN686xJKlYjjln9+xrA3VrD7gN86xRU8DxHnYkTbBlV4b0gn7uvWmOkrt3LpiDlMW/G1f0nRFSgPEediSOkS8TzYsykzhnSkbpUy3D9xBbe9vISte76PdmkuRnmIOBeDmp1dgbfubs9vr2zOooxd9Bgxh/EL/UuKLv95iDgXo+LjxG0dGzIr+JLib6etpZ9/SdHlMw8R52Jc3SqhLyn+7fqWbAy+pPi3mev44Yh/SdGdPg8R54oBSVzXpg6zh3WmT8vQ8917jZrLZ5v8+e7u9HiIOFeMVC1Xiqf6tWTCHRdx3Iwbxi7kDzPSfFTi8sxDxLliqH3janxwfzI3XVSfF+dv4vKn5/Hpxh3RLssVQR4izhVTZYMvKb52x0UcPW7cOG4x909czvbvfoh2aa4I8RBxrpjr0Lgas4YmM6R7Iu+v/obuf5vDpCVb/EuKLiIeIs45SpeIZ1iPJswcmkzzWhX41VuruO3lJXy7z0cl7qd5iDjn/q1htbK8fufFPH5VcxZm7KTHiDm8/tlm/5KiOykPEefcf4mLE7d2aMj79yfT7JwKPDJlNf2eX8i6b/xLiu7HPEScczlqWK0sbwy6mL9edwFfZO3niuBJioePHo92aa4Q8RBxzp2UJPol1WX2g1248oJzGD17A1ePWUD6tn3RLs0VEh4izrlcVSlbklH9W/HcTW3Y/t0P9HlmPiP9+e4ODxHn3Cnoff7ZzBramct/dg5Pz97AZU/PY1HGzmiX5aIoohCR1FvSOkkbJT18kj79JKVJWitpQlh7PUmzJKUHrzcI2rtLWiZphaT5khoH7aUkvRHsa/GJ/sFrjwTt6yT1yvthO+fyqkrZkjzdvxWv3NaOI8eO03/sIn49eRV7Dx6JdmkuCnINEUnxwBjgMqA5MEBS82x9EoFHgA5m1gJ4IOzl8cCTZnYe0A7YHrQ/C/zCzC4EJgC/CdpvB3abWWNgJPCXYB/Ngf5AC6A38I+gNudcFHRuUp1ZD3Tmfzo3YvKyTLqPmMOMVVv9S4rFTCQjkXbARjPLMLPDwESgb7Y+dwJjzGw3gJlth39/8CeYWUrQvt/MDgbrGFAh+LsisDX4uy/wSvD3ZKC7JAXtE83skJltAjYGtTnnouSskvE8ctl5TLu3A+dULM3gCcu545VUtu31JykWF5GESG1gS9hyZtAWrgnQRNICSYsk9Q5r3yNpiqTlkp4MGz3cAbwnKRO4Gfhz9v2Z2VFgL1A1wjoAkDRIUqqk1KysrAgO0Tl3Os6vXZG372nPb644j0+/2EmPEXN5daE/SbE4iCRElENb9v8yEoBEoAswABgnqVLQ3gl4CGgLNAIGBusMBS43szrAS8CIXPYXSR2hRrOxZpZkZknVq1fP+aicc/kqIT6OOzo1YtbQZFrVq8Rj09Zy/fMLWe9PUoxpkYRIJlA3bLkO/5l6Cu8zzcyOBFNN6wiFSiawPJgKOwpMBVpLqg60NLPFwfpvAO2z709SAqGprl0R1uGci7ITT1J86vqWZARfUvQnKcauSEJkCZAoqaGkkoRObk/P1mcq0BVAUjVC01gZwbqVg9AA6AakAbuBipKaBO09gPTg7+nALcHf1wEfWehM3XSgf3D1VkNCIfXZqRysc+7MkMS1beow+8EuXNWyFs98vJHLn57Hki/9SYqxJtcQCUYQg4GZhD7oJ5nZWklPSOoTdJsJ7JSUBnwMDDeznWZ2jNBU1mxJqwlNSb0QbPNO4C1JKwmdExkebOtFoKqkjcAw4OGgjrXAJEIh9AFwb7B951whVaVsSUb0u5AKpQkeAAAP7ElEQVRXb2/H4WPH6ff8Qh6ftoYDh45GuzSXTxTrl+MlJSVZampqtMtwrtg7cOgoT85cxysLv+ScCqX5XZ8W9GxxdrTLcjmQtNTMkiLp699Yd86dEWVLJfC7Pi2YfNcllC9dgkGvLuWOV1LJ3H0w95VdoeUh4pw7o9rUr8KMIR155LJmLNi4g14j/XLgosxDxDl3xpWIj+N/Op9LyrBkWtevzGPT1jLghUV8ueNAtEtzp8hDxDkXNXUqhy4H/uu1F5C2bR+9Rs3l77M3+N2BixAPEedcVEmiX9u6pAztzKXn1eSplPVcNmoe8zfsiHZpLgIeIs65QuHsiqUZ84vWvHxrW46ZcdOLi/nV5JXs/d7vDlyYeYg45wqVLk1rMPOBZO7uci6Tl2bSa+RcPvr822iX5U7CQ8Q5V+iULhHPr3s3Y+q9Hah4VgluezmVe19bxrf7foh2aS4bDxHnXKF1QZ1KvHNfRx7q2YSU9G+59Kk5jF/olwMXJh4izrlCrWRCHIO7JTLrgWRa1q3Eb6et5YaxC8nI2h/t0hweIs65IqJBtbK8envo7sDrvvmO3k/P49lPvuDosePRLq1Y8xBxzhUZJ+4O/OGwznRtWp2/fPA5Vz2zgOWbd0e7tGLLQ8Q5V+TUqFCa525qw3M3tWb3gcP8/NlPeWzqGvb94JcDn2keIs65IkkSvc8/h5RhydxySQNeW/wVPUfMZdbab6JdWrHiIeKcK9LKly7B7/q0YMo9HahUJnR34HteW+qXA58hHiLOuZhwYd3Q5cDDezXlw/TtdH9qDi8t2MQxvxy4QHmIOOdiRon4OO7t2piZDyTTql4lfv9OGn2emc/qzL3RLi1meYg452JOw2plGX9bO565sRVZ3x3i6n8s4M/vf84PR/zuwPktohCR1FvSOkkbJT18kj79JKVJWitpQlh7PUmzJKUHrzcI2udJWhH8bJU0NWgfHta+RtIxSVWC176UtDp4zZ9565w7KUlceUEtUoZ15rrWdXhuzhdc/vQ8FmfsjHZpMSXXZ6xLigfWAz2ATGAJMMDM0sL6JAKTgG5mtltSDTPbHrz2CfAnM0uRVA44bmYHs+3jLWCamY3P1n4VMNTMugXLXwJJZhbxPaL9GevOOYAFG3fw8JRVbNn1Pf2S6vDIZedRuWzJaJdVKOX3M9bbARvNLMPMDgMTgb7Z+twJjDGz3QBhAdIcSDCzlKB9fw4BUh7oBkzNYd8DgNcjORDnnPspHRpXY9YDnbmr87lMWfY13UfM4e3lmeT2D2n30yIJkdrAlrDlzKAtXBOgiaQFkhZJ6h3WvkfSFEnLJT0ZjGzCXQPMNrN94Y2SygC9gbfCmg2YJWmppEER1O6cc/92Vsl4Hr6sGTOGdKR+1TIMfWMlt7y0hC27Dua+sstRJCGiHNqyR3cCkAh0ITR6GCepUtDeCXgIaAs0AgZmW/dko42rgAVmtiusrYOZtQYuA+6VlJxjwdIgSamSUrOysn7i0JxzxVGzsysw+a72/L5PC5Z+uYueI+cybl6G34crDyIJkUygbthyHWBrDn2mmdkRM9sErCMUKpnA8mAq7CihKavWJ1aSVJXQdNm7Oey3P9nCxcy2Br+3A28H6/6ImY01syQzS6pevXoEh+icK27i48Qt7Rswa1hnLjm3Kn98N51r/vEpa772y4FPRSQhsgRIlNRQUklCH+7Ts/WZCnQFkFSN0DRWRrBuZUknPsm7AWlh610PzDCz//pqqaSKQGdgWlhb2eD8CZLKAj2BNZEcpHPOnUztSmfx4i1JPHNjK7bt/YG+Yxbw/95L5/vDfjlwJHINkWAEMRiYCaQDk8xsraQnJPUJus0EdkpKAz4GhpvZTjM7Rmgqa7ak1YSmxl4I2/yPRhuBa4BZZnYgrK0mMF/SSuAz4F0z++BUDtY553Jy4nLg2cM6c32bOjw/N4Oeo+Ywb4NPh+cm10t8izq/xNc5d6oWZezkf6esJmPHAa5pVZvfXHEeVcuVinZZZ0x+X+LrnHPFysWNqvLe/Z24r1tjZqzaSren5vDGks3+WN4ceIg451wOSpeI58GeTXlvSCea1izPr99aTf+xi9i43R/LG85DxDnnfkJizfJMHHQxf732AtZ9+x2XPz2P0bM3cPioXw4MHiLOOZeruDjRr21dPhzWmZ4tajIiZT1XjJ7Hki935b5yjPMQcc65CFUvX4pnbmzNPwcmcfDwMa5/biGPTFnN3oPF97G8HiLOOXeKujWryayhydzZqSFvLNlM9xGfMG3F18XyPlweIs45lwdlSyXw6BXNmT64I7UqncX9E1dwy0tL2LyzeN2Hy0PEOedOw/m1K/L2PR343VXNWfrlLnqMnMOzn3zBkWJyHy4PEeecO03xcWJgh4Z8+GBnujStzl8++Jyr/j6f5Zt3R7u0Auch4pxz+eScimfx/M1JjL25DXsOHuHnz37Kb6etYd8PsXvi3UPEOefyWc8WZ/Phg5255ZIGvLroK3qMmMP7q7fF5Il3DxHnnCsA5Uol8Ls+LZh6Tweqli3F3a8t487xS9m65/tol5avPEScc64AtaxbiemDO/C/lzdjwcYd9Bgxh3/O38SxGLkPl4eIc84VsIT4OAYln8usockkNajCEzPSuHrMAlZl7ol2aafNQ8Q5586QulXK8PKtbfn7gFZ8sy/0AKzHi/iJdw8R55w7gyRxVctazA5OvI8PTrzPWvtNtEvLEw8R55yLggqlS/z7xHvlMiUZ9OpS7v7XUr7d90PuKxciHiLOORdFLetW4p37OjK8V1Nmf76dS5+aw6sLvywyJ94jChFJvSWtk7RR0sMn6dNPUpqktZImhLXXkzRLUnrweoOgfZ6kFcHPVklTg/YukvaGvfbbU6nDOeeKmhLxcdzbtTEzH0jmgroVeWzaWq599lPSt+2Ldmm5yvUZ65LigfVADyATWAIMMLO0sD6JwCSgm5ntllTDzLYHr30C/MnMUiSVA46b2cFs+3gLmGZm4yV1AR4ysytPtY6c+DPWnXNFiZkxbcVW/jAjjb3fH2FQciOGdE+kdIn4M1ZDfj9jvR2w0cwyzOwwMBHom63PncAYM9sNEBYgzYEEM0sJ2vfnECDlgW7A1HyowznnijRJXN2qNh8O68zVrWrzj0++oPeouSzYuCPapeUokhCpDWwJW84M2sI1AZpIWiBpkaTeYe17JE2RtFzSk8GIItw1wGwzCx+3XSJppaT3JbU4hTqccy4mVC5bkr9d35IJd1wEwC/GLea+15cXuhPvkYSIcmjLPgeWACQCXYABwDhJlYL2TsBDQFugETAw27oDgNfDlpcB9c2sJfB3/jNCiaSOUEdpkKRUSalZWVk5H5VzzhUB7RtX44MHknng0kRmrv2G7k8Vrm+8RxIimUDdsOU6wNYc+kwzsyNmtglYRyhUMoHlwRTUUUKB0PrESpKqEpqmevdEm5ntM7P9wd/vASUkVYuwjhPbGGtmSWaWVL169QgO0TnnCq/SJeJ54NImpAxNpk39yjwxI42fF5IT75GEyBIgUVJDSSWB/sD0bH2mAl0Bgg/8JkBGsG5lSSc+ybsB4SfCrwdmmNm/x2eSzpak4O92QY07I6zDOediVv2qZXn51rY83f9CMncd5Kq/z+evH3zOD0eORa2mXEMkGEEMBmYC6cAkM1sr6QlJfYJuM4GdktKAj4HhZrbTzI4RmsqaLWk1oSmpF8I235//nsoCuA5YI2klMBrobyE51pG3w3bOuaJJEn0vDJ1473th6MR7r1FzmbchOlP3uV7iW9T5Jb7OuVj26cYdPDp1DZt2HODqC2vxmyubU61cqdPaZn5f4uucc66Qat+4Gu/f34kh3RN5d/U2uj81hzeWbD5jD8DyEHHOuSKudIl4hvVowvv3d6JpzfL8+q3V3DB2EQcPHy3wfScU+B6cc86dEY1rlGfioIuZlLqF5Zv3UKZkwX/Ee4g451wMiYsT/dvVo3+7emdmf2dkL84552KSh4hzzrk88xBxzjmXZx4izjnn8sxDxDnnXJ55iDjnnMszDxHnnHN55iHinHMuz2L+BoySsoCv8rh6NaBwPpOy4BTHY4biedzF8ZiheB73qR5zfTOL6GFMMR8ip0NSaqR3sowVxfGYoXged3E8Ziiex12Qx+zTWc455/LMQ8Q551yeeYj8tLHRLiAKiuMxQ/E87uJ4zFA8j7vAjtnPiTjnnMszH4k455zLMw+RHEjqLWmdpI2SHo52PQVFUl1JH0tKl7RW0v1BexVJKZI2BL8rR7vW/CYpXtJySTOC5YaSFgfH/IakktGuMb9JqiRpsqTPg/f8klh/ryUNDf7bXiPpdUmlY/G9lvRPSdslrQlry/G9Vcjo4PNtlaTWp7NvD5FsJMUDY4DLgObAAEnNo1tVgTkKPGhm5wEXA/cGx/owMNvMEoHZwXKsuR9ID1v+CzAyOObdwO1RqapgPQ18YGbNgJaEjj9m32tJtYEhQJKZnQ/EA/2Jzff6ZaB3traTvbeXAYnBzyDg2dPZsYfIj7UDNppZhpkdBiYCfaNcU4Ews21mtiz4+ztCHyq1CR3vK0G3V4Cro1NhwZBUB7gCGBcsC+gGTA66xOIxVwCSgRcBzOywme0hxt9rQk9vPUtSAlAG2EYMvtdmNhfYla35ZO9tX2C8hSwCKkk6J6/79hD5sdrAlrDlzKAtpklqALQCFgM1zWwbhIIGqBG9ygrEKOBXwPFguSqwx8yOBsux+J43ArKAl4JpvHGSyhLD77WZfQ38DdhMKDz2AkuJ/ff6hJO9t/n6Gech8mPKoS2mL2GTVA54C3jAzPZFu56CJOlKYLuZLQ1vzqFrrL3nCUBr4FkzawUcIIamrnISnAPoCzQEagFlCU3lZBdr73Vu8vW/dw+RH8sE6oYt1wG2RqmWAiepBKEAec3MpgTN354Y3ga/t0ervgLQAegj6UtCU5XdCI1MKgVTHhCb73kmkGlmi4PlyYRCJZbf60uBTWaWZWZHgClAe2L/vT7hZO9tvn7GeYj82BIgMbiCoyShE3HTo1xTgQjOBbwIpJvZiLCXpgO3BH/fAkw707UVFDN7xMzqmFkDQu/tR2b2C+Bj4LqgW0wdM4CZfQNskdQ0aOoOpBHD7zWhaayLJZUJ/ls/ccwx/V6HOdl7Ox34ZXCV1sXA3hPTXnnhXzbMgaTLCf3rNB74p5n9KcolFQhJHYF5wGr+c37gfwmdF5kE1CP0P+L1Zpb9pF2RJ6kL8JCZXSmpEaGRSRVgOXCTmR2KZn35TdKFhC4mKAlkALcS+odkzL7Xkn4P3EDoSsTlwB2E5v9j6r2W9DrQhdDder8FHgemksN7GwTqM4Su5joI3GpmqXnet4eIc865vPLpLOecc3nmIeKccy7PPEScc87lmYeIc865PPMQcc45l2ceIs455/LMQ8Q551yeeYg455zLs/8P53OFKRgGzbUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo: \n",
    "\n",
    "[ ] model2: try softmax as activation  \n",
    "[ ] add batchnorm layer to model1 and model2  \n",
    "[ ] do  7-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare activation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong way to set initial weights \n",
    "# because no inplace functions are allowed for Variables with'requires_grad=True'\n",
    "# Ref: https://discuss.pytorch.org/t/how-to-initiate-parameters-of-layers/1460\n",
    "def wrong_weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.manual_seed(RSEED)\n",
    "        m.weight.normal_() # error! \n",
    "        m.bias.normal_() # error!\n",
    "        \n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.manual_seed(RSEED)\n",
    "        m.weight.data.normal_() \n",
    "        m.bias.data.normal_() \n",
    "            #alternatively set initial bias to zero\n",
    "            # m.bias.data.fill_(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "initial weights: \n",
      "error: (tensor(1.0115), tensor(0.9651))\n",
      "ReLU\n",
      "initial weights: \n",
      "error: (tensor(1.9250), tensor(0.8557))\n",
      "Softplus\n",
      "initial weights: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([759])) that is different to the input size (torch.Size([759, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: (tensor(1.7451), tensor(0.7730))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BCEloss \n",
    "criterion = nn.BCELoss(size_average=True)\n",
    "\n",
    "model_relu = BCModel(X.shape[1], H1, H2, nn.ReLU() )\n",
    "acts = [nn.Sigmoid(), nn.ReLU(), nn.Softplus()]\n",
    "\n",
    "for act in acts: \n",
    "    actname = act.__class__.__name__\n",
    "    print(actname)\n",
    "    model = BCModel(X.shape[1], H1, H2, activation=act)\n",
    "    model.apply(weight_init)\n",
    "    print(\"initial weights: \")\n",
    "#     model.print_params()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Train\n",
    "    ls = []\n",
    "    for epoch in range(100):\n",
    "        #forward\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        #loss\n",
    "        l = criterion(y_pred, y)\n",
    "        ls.append(l)\n",
    "        #zero-out grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #backward pass\n",
    "        l.backward()\n",
    "        \n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "    f,ax = plt.subplots()\n",
    "    f.suptitle(actname)\n",
    "    ax.plot(ls)\n",
    "    print(f\"error: {ls[0], ls[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side: setting a random seed for pytorch\n",
    "- Must set the seed before calling a random number generating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6147,  0.3810])\n",
      "tensor([ 0.6147,  0.3810])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "print(torch.rand(2))\n",
    "\n",
    "torch.manual_seed(2)\n",
    "print(torch.rand(2)) # gives the same random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6147,  0.3810])\n",
      "tensor([ 0.6371,  0.4745])\n"
     ]
    }
   ],
   "source": [
    "# However, thess will not.\n",
    "\n",
    "torch.manual_seed(2)\n",
    "print(torch.rand(2))\n",
    "\n",
    "print(torch.rand(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6147,  0.3810])\n",
      "tensor([ 0.6147,  0.3810])\n",
      "tensor([ 0.6147,  0.3810])\n"
     ]
    }
   ],
   "source": [
    "# Set the seed manually right before calling the random generator \n",
    "for i in range(3):\n",
    "    torch.manual_seed(2)\n",
    "    print(torch.rand(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example: nn Linear module's weight initialization from a normal distribution with a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: \n",
      " tensor([[-0.5209,  1.0293, -0.3506,  0.1164, -0.1888, -1.4995,  0.1282,\n",
      "         -0.5361],\n",
      "        [ 0.0801, -0.1853,  0.7937,  0.9629,  0.7823,  0.4834, -1.8192,\n",
      "         -0.5442],\n",
      "        [ 1.9123,  0.2977, -0.7049,  0.4994, -0.0474,  1.3253,  0.9269,\n",
      "          0.2274]])\n",
      "normal call: \n",
      " tensor([[-1.3042, -1.1097, -1.2188,  1.1676, -1.0574, -0.1188, -0.3298,\n",
      "          0.0958],\n",
      "        [-1.1233, -0.0919, -0.1320, -0.2751, -0.2350,  0.0937, -0.7650,\n",
      "          1.8299],\n",
      "        [-0.1752,  0.6990, -0.6861,  0.7202,  0.1963,  0.6142,  1.1566,\n",
      "          0.4296]])\n",
      "normal call: \n",
      " tensor([[ 0.1665,  0.7911,  0.8560,  0.4094, -1.1371, -1.2034, -1.0190,\n",
      "          0.3157],\n",
      "        [-1.4702, -0.2134, -0.8707,  1.6159, -0.2356,  0.9444,  0.5461,\n",
      "         -1.3575],\n",
      "        [ 0.1757, -0.1319, -0.2735,  0.3355,  0.1885,  2.1432, -0.2779,\n",
      "          0.5511]])\n"
     ]
    }
   ],
   "source": [
    "print(\"original: \\n\", model.l1.weight.data)\n",
    "print(\"normal call: \\n\", model.l1.weight.data.normal_())\n",
    "print(\"normal call: \\n\", model.l1.weight.data.normal_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: \n",
      " tensor([[ 0.1665,  0.7911,  0.8560,  0.4094, -1.1371, -1.2034, -1.0190,\n",
      "          0.3157],\n",
      "        [-1.4702, -0.2134, -0.8707,  1.6159, -0.2356,  0.9444,  0.5461,\n",
      "         -1.3575],\n",
      "        [ 0.1757, -0.1319, -0.2735,  0.3355,  0.1885,  2.1432, -0.2779,\n",
      "          0.5511]])\n",
      "normal call: \n",
      " tensor([[-0.5108,  1.0283, -0.3532,  0.1230, -0.1816, -1.4972,  0.1421,\n",
      "         -0.5243],\n",
      "        [ 0.0744, -0.1843,  0.7960,  0.9592,  0.7783,  0.4826, -1.8291,\n",
      "         -0.5514],\n",
      "        [ 1.9113,  0.2979, -0.7041,  0.4983, -0.0488,  1.3252,  0.9240,\n",
      "          0.2255]])\n",
      "normal call: \n",
      " tensor([[-0.5108,  1.0283, -0.3532,  0.1230, -0.1816, -1.4972,  0.1421,\n",
      "         -0.5243],\n",
      "        [ 0.0744, -0.1843,  0.7960,  0.9592,  0.7783,  0.4826, -1.8291,\n",
      "         -0.5514],\n",
      "        [ 1.9113,  0.2979, -0.7041,  0.4983, -0.0488,  1.3252,  0.9240,\n",
      "          0.2255]])\n"
     ]
    }
   ],
   "source": [
    "print(\"original: \\n\", model.l1.weight.data)\n",
    "torch.manual_seed(RSEED)\n",
    "print(\"normal call: \\n\", model.l1.weight.data.normal_())\n",
    "torch.manual_seed(RSEED)\n",
    "print(\"normal call: \\n\", model.l1.weight.data.normal_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classifying with minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/root/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([9])) that is different to the input size (torch.Size([9, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    }
   ],
   "source": [
    "N,D =  train_dataset.len, train_dataset.data.shape[1]\n",
    "model = BCModel(D, H1, H2, activation=act)\n",
    "model.apply(weight_init)\n",
    "print(\"initial weights: \")\n",
    "# model.print_params()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "train_ls = []\n",
    "dev_ls = []\n",
    "for epoch in range(5000):\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        #forward\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        #loss\n",
    "        l = criterion(y_pred, y_batch)\n",
    "        train_ls.append(l)\n",
    "        #zero-out grads\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #backward pass\n",
    "        l.backward()\n",
    "\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "#     if (epoch%49 == 0):\n",
    "# #         dev_l = criterion(dev_ypred, dev_y)\n",
    "#         dev_ls.append(dev_l)\n",
    "#         print(f\"Epoch {epoch}: {train_ls[-1], dev_ls[-1]}\")\n",
    "        \n",
    "        \n",
    "f,ax = plt.subplots()\n",
    "ax.plot(ls)\n",
    "print(f\"error: {ls[0], ls[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test acc:  0.44047619047619047\n"
     ]
    }
   ],
   "source": [
    "#Test loop\n",
    "# test loss\n",
    "test_ls = []\n",
    "isCorrects = []\n",
    "with torch.no_grad():\n",
    "    for i, (xtest_batch, ytest_batch) in enumerate(test_loader):\n",
    "#         print(i)\n",
    "        ypred_batch = model(xtest_batch).view(ytest_batch.size())\n",
    "        test_l = criterion(ypred_batch, ytest_batch).item()\n",
    "\n",
    "        # make a decision at 0.5\n",
    "        decision_batch = (ypred_batch > 0.5).type(ytest_batch.dtype)\n",
    "#         pdb.set_trace()\n",
    "        # collect isCorrects\n",
    "        isCorrect_batch = (decision_batch==ytest_batch).numpy()\n",
    "        acc_batch = sum(isCorrect_batch)/len(isCorrect_batch)\n",
    "        print('test acc: ', acc_batch)\n",
    "#         pdb.set_trace()\n",
    "#         isCorrects.extend(isCorrect_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg test batch loss: 0.6349934861063957\n",
      "Test accuracy:  0.6733067729083665\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test loop\n",
    "# test loss\n",
    "test_ls = []\n",
    "isCorrects = []\n",
    "with torch.no_grad():\n",
    "    for i, (xtest_batch, ytest_batch) in enumerate(test_loader):\n",
    "        ypred_batch = model(xtest_batch).view(ytest_batch.size())\n",
    "        test_ls.append(criterion(ypred_batch, ytest_batch).item())\n",
    "\n",
    "        # make a decision at 0.5\n",
    "        decision_batch = (ypred_batch > 0.5).type(ytest_batch.dtype)\n",
    "#         pdb.set_trace()\n",
    "        # collect isCorrects\n",
    "        isCorrect_batch = (decision_batch==ytest_batch).numpy()\n",
    "#         pdb.set_trace()\n",
    "        isCorrects.extend(isCorrect_batch)\n",
    "        \n",
    "f,ax = plt.subplots()\n",
    "f.suptitle('Test batch loss')\n",
    "ax.plot(test_ls)\n",
    "print('Avg test batch loss:', np.mean(test_ls))\n",
    "print('Test accuracy: ', sum(isCorrects)/len(isCorrects))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at misclassified examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### side: batch norm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'num_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-540-bb8116501d9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'num_features'"
     ]
    }
   ],
   "source": [
    "bn = nn.BatchNorm1d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### side: transform\n",
    "*Note*: the loaded data is already normalized. See where the LunaDataset is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define transform objects to apply for data samples as a class so that we don't need to specify the settings (ie. parameters to the transform object) everytime the transformation is applied to samples.   \n",
    "Key: `__call__(self, sample)` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size\n",
    "    Args:\n",
    "        output_size (int or tuple): Desired output size. If tuple, output is matched to \n",
    "        output size. If int, smaller of image dimensions is matcehd to output_size keeping\n",
    "        ratio the same as the original image.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "#         if isinstance(output_size, tuple):\n",
    "#             self.\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        input: a data point (sample) from the dataset\n",
    "        output: transformed sample \n",
    "        \"\"\"\n",
    "        pass\n",
    "#         return transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Try a deeper network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple batch norm layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bn = nn.BatchNorm1d()\n",
    "N,D =  train_dataset.len, train_dataset.data.shape[1]\n",
    "criterion = nn.BCELoss(size_average=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepBCModel(nn.Module):\n",
    "    def __init__(self, dims, \n",
    "                 hidden_activation=nn.ReLU(), \n",
    "                 output_activation=nn.Sigmoid()):\n",
    "        \"\"\"\n",
    "        dims: a list of dimensions of layer. [inDims, H1, H2,...].\n",
    "        It doesn't includ the output layer's size, which is fixed to 1\"\"\"\n",
    "        super(DeepBCModel,self).__init__()\n",
    "        \n",
    "        self.__build_layers__(dims)\n",
    "        self.n_layers = len(dims)\n",
    "        self.n_batch_norms = self.n_layers - 1 # Q:don't need for the last layer(right before softmax)\n",
    "        \n",
    "#         self.batch_norm = nn.BatchNorm1d() #todo\n",
    "        self.h_activation = hidden_activation\n",
    "        self.o_activation = output_activation\n",
    "        \n",
    "    def __build_layers__(self, dims):\n",
    "#         assert(len(self.layers) == 0)\n",
    "#         for i in range(len(dims)-1):\n",
    "#             self.add_module(f'h{i}', self.h_activation(nn.Linear(dims[i],dim[i+1])))\n",
    "#         self.add_module(f'h{len(dim)-1}', self.o_activation(nn.Linear(dims[-1],1)))\n",
    "                            \n",
    "        for i in range(len(dims)-1):\n",
    "            self.add_module(f'li{i}', (nn.Linear(dims[i],dims[i+1])))\n",
    "        self.add_module(f'li{len(dims)-1}', nn.Linear(dims[-1],1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = x\n",
    "        \n",
    "        for (mname, m) in self.named_children():\n",
    "            if not isinstance(m, nn.Linear):\n",
    "#                 print(mname, ': pass')\n",
    "                continue\n",
    "                \n",
    "            if (str(self.n_layers-1) in mname):\n",
    "#                 print(mname, ': last layer')\n",
    "                act = self.o_activation\n",
    "            else:\n",
    "#                 print(mname, \": middle layer\" )\n",
    "                act = self.h_activation\n",
    "                \n",
    "            y_pred = act(m(y_pred))\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loss(model, criterion, train_dataset, exclude_indices):\n",
    "    \"\"\"\n",
    "    Compute loss on training dataset except data indexed at\n",
    "    exclude_indices.\n",
    "    Args:\n",
    "    - model: trained model with forward function\n",
    "    - criterion: loss function that takes in (ypred, y)\n",
    "    - train_dataset (Dataset): training dataset \n",
    "    - exclude_indices: indices to exclude from train_dataset \n",
    "        when computing the loss, eg: batch indices used to \n",
    "        fit the current model\n",
    "    \"\"\"\n",
    "    n = len(train_dataset)\n",
    "    if isinstance(exclude_indices, torch.Tensor):\n",
    "        exclude_indices = exclude_indices.numpy()\n",
    "    include_indices = [i for i in range(n) if i not in exclude_indices]\n",
    "    samples = train_dataset[include_indices]\n",
    "    x = samples[0]\n",
    "    y = samples[1]\n",
    "#     pdb.set_trace()\n",
    "#     x_tensor = torch.tensor(x)\n",
    "#     y_tensor = torch.stack(y)\n",
    "#     pdb.set_trace()\n",
    "    with torch.no_grad():\n",
    "        ypred = model(x).type_as(y)\n",
    "        loss = criterion(ypred, y).item()\n",
    "    return loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test get_train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([137])) that is different to the input size (torch.Size([137, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.30285930633545"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excludes = range(32)\n",
    "get_train_loss(model, criterion, train_dataset, excludes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test DeepBCModel constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepBCModel(\n",
      "  (li0): Linear(in_features=96, out_features=200, bias=True)\n",
      "  (li1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (li2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (li3): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (h_activation): ReLU()\n",
      "  (o_activation): Sigmoid()\n",
      ")\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "N,D =  train_dataset.len, train_dataset.data.shape[1]\n",
    "\n",
    "dims = [D, 200,200,200]\n",
    "M = DeepBCModel(dims)\n",
    "criterion = nn.BCELoss(size_average=True)\n",
    "\n",
    "print(M)\n",
    "print(M.n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=96, out_features=200, bias=True)\n",
      "Linear(in_features=200, out_features=200, bias=True)\n",
      "Linear(in_features=200, out_features=200, bias=True)\n",
      "Linear(in_features=200, out_features=1, bias=True)\n",
      "ReLU()\n",
      "Sigmoid()\n"
     ]
    }
   ],
   "source": [
    "for m in M.children():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check forward function\n",
    "dataiter = iter(train_loader)\n",
    "x1, y1 = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "M(x1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "nEpoch = 1000\n",
    "H1 = 200; H2 = 200; H3 = 100; H4 = 100\n",
    "dims = [D, H1, H2, H3, H4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepBCModel(dims)\n",
    "model.apply(weight_init)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([137])) that is different to the input size (torch.Size([137, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/root/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([160])) that is different to the input size (torch.Size([160, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "debug = False\n",
    "train_ls = []\n",
    "train_ls_v2 = []\n",
    "\n",
    "train_accs = []\n",
    "for epoch in range(nEpoch):\n",
    "#     print(\"=\"*30)\n",
    "#     print(f'epoch {epoch}')\n",
    "    train_isCorrects = [] \n",
    "    for i, (x_batch, y_batch, i_batch) in enumerate(train_loader):\n",
    "        if debug:\n",
    "            print(x_batch.size())\n",
    "            print(y_batch.size())\n",
    "            print(i_batch.size())\n",
    "            pdb.set_trace()\n",
    "\n",
    "        #forward\n",
    "        ypred_batch = model(x_batch).view(y_batch.size())\n",
    "        \n",
    "        #loss\n",
    "        l = criterion(ypred_batch, y_batch)\n",
    "        train_ls.append(l.item())\n",
    "        #zero-out grads\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #backward pass\n",
    "        l.backward()\n",
    "\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if debug:\n",
    "            print(ypred_batch.size(), ypred_batch.dtype)\n",
    "            print(y_batch.size(), y_batch.dtype)\n",
    "            print(i_batch)\n",
    "            pdb.set_trace()\n",
    "            \n",
    "        # Compute training loss and accuracy\n",
    "        \n",
    "        l_v2 = get_train_loss(model, criterion, train_dataset, i_batch)\n",
    "        train_ls_v2.append(l_v2)\n",
    "        # make a decision at 0.5\n",
    "        # boolean tensor is uint8 type. Cast it to tensor.float32\n",
    "        decision_batch = (ypred_batch > 0.5).view(y_batch.size()).type(y_batch.dtype)\n",
    "        # collect isCorrects\n",
    "        isCorrect_batch = (decision_batch==y_batch).numpy()\n",
    "#         print(decision_batch.size(),  isCorrect_batch.shape)\n",
    "#         pdb.set_trace()\n",
    "        batch_acc = sum(isCorrect_batch)/len(isCorrect_batch)\n",
    "        train_accs.append(batch_acc)\n",
    "#         print(f'\\t batch{i} acc: {batch_acc}')\n",
    "\n",
    "    # Dev accuracy\n",
    "#     if (epoch%49 == 0):\n",
    "#         dev_l = criterion(dev_ypred, dev_y)\n",
    "#         dev_ls.append(dev_l)\n",
    "#         print(f\"Epoch {epoch}: {train_ls[-1], dev_ls[-1]}\")\n",
    "#     print(f'epoch{epoch} acc: {sum(train_accs)/len(train_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axes = plt.subplots(3,1)\n",
    "axes[0].plot(train_ls)\n",
    "axes[1].plot(train_accs)\n",
    "axes[2].plot(dev_ls) #Devset error\n",
    "print(f\"Train batch losses: {train_ls[0], train_ls[-1]}\")\n",
    "print(f\"Train accuracy: {train_accs[0], train_accs[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devset error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch losses: (7.771225452423096, 4.605170249938965)\n",
      "Train accuracy: (0.71875, 0.8333333333333334)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Dev  losses: {dev_ls[0], dev_ls[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg test batch loss: 9.206343412399292\n",
      "Test accuracy:  0.6733067729083665\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8luWZ9//PkTv7wpaEkIRAgBBQlrBEhKK4IChK0NpCdWq1rVadbm4zz6/zzPza33Rev3k6z6jt1HaqVp3ax9a6tZYgKosLWkEJSMIOYQ9ZSSAJ2Zfj+SM3nRgTCLmX616O9+uVV+5c93Vf1zchHDnv8zqv8xRVxRhjTHiIcDqAMcYY/7Gib4wxYcSKvjHGhBEr+sYYE0as6BtjTBixom+MMWHEir4JWSIyVUQ6/XSuLSJyxyD3vUFESn2dyZj+WNE3PiciZ3t9dItIS6+vv+rBcQddaIdw7FgRUREZ64vjG+OUSKcDmNCnqonnHovIUeAeVd3gXCJjwpe19I3jRMQlIv+viBwWkVMi8jsRGeF+LkFE/iAidSJyRkQ+FpGRIvIYcBnwjPsdw2PnOf79IlIhIuUi8r1e2xe6j1fvfu6nInKuIbTJ/Xm/+/i3uF+zUkRKRKRBRA6KyOJep5rkfvfRICJrRWTkIL//GSLygfv7KxGRZb2eu1lE9olIo4icEJHvu7ePEZG33K+pFZF3BnMuY6zom0Dw98BS4ApgLNAB/NT93D30vCPNBFKA7wLtqvoIsJWedw2J7q/74wIWABOBm4B/FpEr3M91uI83CrgSKHCfD2CR+/MU9/FfF5ErgaeBB4ARwGLgRK9z/Q3wVSDd/fwDF/rGRSQWWAO8DqS6fxaviMgE9y7PAXeqahIwC/jAvf3/Afa7fybpwP93oXMZA1b0TWC4D/iBqparaivwz8BXREToKcypwCRV7VTVraradJHH/5Gqtqjqp8ALwO0AqvqJ+3hdqnoIeAa46jzHuQd4UlXfVdVuVT2uqgd6Pf9rVT3kzvcqPUX6Qq50f35cVTtU9W1gPfAV9/ZOYJqIJKlqrft7gJ6fSwYwTlXbVXUTxgyCFX3jKHdhzwLWursqzgCf0vO7mQw8C7wPvCoiZSLyryLiusjT9G6NH6OnWCIil4rImyJSJSINwA/paTkPJAs4dJ7nK3s9bgYSB9qxlwzguH525sNj9LyzAbgF+BJwXETeEZF89/b/HygH3hWRUhF5eBDnMsaKvnGWu9idBK5V1RG9PmJV9ZSqtqnqD1V1Kj1dLiuB2869fJCnyer1eBw9xRLg18B2et5FDAN+DMh5jn0CmDTob25wyt2ZehtHz88EVd2sqsuBNGAd8KJ7e72qPqCq4+n5o/BPIrLQy9lMCLKibwLBk8BPRCQLQERGi0iB+/F17hZ5BNBAT3dHl/t1VfT01V/Ij0QkTkTygK8BL7m3JwH1qnpWRKYB3zr3AlVtA+r7HP8Z4D4RWSQiESKSJSK5Q/2m3T4AIkTkQRGJFJEl9FzfeMV9Efs2ERlGT3dOI+7vXURWiMgE9zulevf2rgHOYcxfWdE3geB/AxuAd0SkEfgImON+LhP4Mz0FbxewFnjZ/dxPgTtF5LSI/O8Bjt0FfAwcAd4Cftyr//sh4B4ROQv8kv/+Y3DOD+kpvmdEZIWqfgDcD/wnPYV2Iz0XnofMfQ1jOfBloBZ4HPiK+xoDwDfp6e6pB+4E7nJvvwR4j56fyybgUVXd4kkWEx7EFlExxpjwYS19Y4wJI1b0jTEmjFjRN8aYMGJF3xhjwogVfWOMCSNW9I0xJoxY0TfGmDBiRd8YY8KIFX1jjAkjVvSNMSaMWNE3xpgwYkXfGGPCiBV9Y4wJI1b0jTEmjFjRN8aYMGJF3xhjwogVfWOMCSORTgfoKyUlRbOzs52OYYwxQWXbtm2nVDX1QvsFXNHPzs6mqKjI6RjGGBNUROTYYPaz7h1jjAkjVvSNMSaMWNE3xpgwYkXfGGPCiBV9Y4wJI1b0jTEmjFjRN8aYMBJw4/TDxf7KRt4oKXc6xqBFuiK4Y/54RiVEOx3FGOMBK/oO+fGa3fyltBYRp5MMjip0dHXzyNIpTkcxxnjAir4Dqhtb2Xyolu9fm8PDQVJEv/rMFgqLy3l4SS4SLH+pjDGfY336DnhzZyXdCgV5GU5HGbSCmRkcrW1m18kGp6MYYzxgRd8Bq4vLmTomiclpSU5HGbQbpo8hyiWsLj7pdBRjjAes6PtZ2elmth07HVStfIAR8dEsmpzKmpIKurvV6TjGmCGyou9nb5RUAD3dJcGmIC+DivpWth0/7XQUY8wQWdH3s9XF5czKGsG45Hino1y0JZemERsVQWFx8Aw1NcZ8lhV9PzpUc5bd5Q1B17VzTkJMJIunprF2ZwWdXd1OxzHGDMEFi76IPCci1SKyq9e2lSKyW0S6RST/PK+9QUT2i0ipiPzAW6GD1ZriCkTgphnpTkcZsoK8dE6dbWfz4VqnoxhjhmAwLf3fADf02bYLuBXYNNCLRMQF/BJYBlwK3C4ilw4tZvBTVVYXn2Re9ijGDI91Os6QXT1lNIkxkdbFY0yQumDRV9VNQF2fbXtVdf8FXjoPKFXVw6raDvwBuHnISYPc3opGDtU0sWJWcHbtnBMb5WLptDTe3FVJW2eX03GMMRfJl336mcCJXl+Xubd9jojcKyJFIlJUU1Pjw0jOKSwpxxUhLJsevF075xTkZdDY2smmA6ecjmKMuUi+LPr93avf7wBvVX1aVfNVNT819YKLuQcdVaWwuJwrclJCYsKyK3JSGBkfZV08xgQhXxb9MiCr19djgbCsEp+eOEPZ6RZWBOmonb6iXBEsm5HO+j1VNLd3Oh3HGHMRfFn0twKTRWSCiEQDtwGrfXi+gFVYXE50ZARLpqU5HcVrCmZm0NLRxca91U5HMcZchMEM2XwR2AxMEZEyEblbRL4oImXAAuANEXnbvW+GiKwFUNVO4LvA28Be4GVV3e2rbyRQdXUrb5RUcM2UVIbFRjkdx2vmTRjF6KQY6+IxJshccGplVb19gKf+1M++5cCNvb5eC6wdcroQ8MmROqob24L2hqyBuCKE5TMzeGHLMRpaO0LqD5oxoczuyPWx1cXlxEe7WDw1dLp2zinIS6e9q5u3d1U6HcUYM0hW9H2oo6ubN3dVsOTSNOKiXU7H8bpZWSMYOzKOQvckcsaYwGdF34c+LD3FmeaOoJxRczBEhIK8DP5Seoras21OxzHGDIIVfR8q3FHOsNhIFuWG3r0H56zIy6CrW3nTuniMCQpW9H2ktaOLdXuqWDY9nejI0P0xTx2TRM7oRFbbKB5jgkLoViOHvbe/mrNtnSE3aqcvEaFgZgZbj9ZRUd/idBxjzAVY0feR1cXlpCTGsGBSstNRfK4gLx3V/14VzBgTuKzo+8DZtk427q3mphljcEX0NwVRaJmYmsj0zGF2o5YxQcCKvg9s2FNFW2d3yHft9FYwM4PisnqO1TY5HcUYcx5W9H2gsLicjOGxzBk30ukofrPc/QdujXXxGBPQrOh72ZnmdjYdrKEgL4OIMOjaOSdzRBz540daF48xAc6Kvpe9tauSji4Nq66dcwryMthX2ciBqkanoxhjBmBF38sKS8qZkJLAtIxhTkfxuxtnpBMhWGvfmABmRd+Lqhtb2XyoloK8DETCp2vnnNSkGL4wKYXC4nJU+10kzRjjMCv6XrS2pIJuhYKZwb8O7lAV5KVztLaZnSfrnY5ijOnHYBZReU5EqkVkV69to0RkvYgcdH/ud5iKiHSJyA73R8ivmlVYUsHUMUlMTktyOopjbpiWTpRLrIvHmAA1mJb+b4Ab+mz7AbBRVScDG91f96dFVWe5P1YMPWbgKzvdzLZjp8PyAm5vw+OjuCo3lTUlFXR3WxePMYHmgkVfVTcBdX023ww87378PHCLl3MFnXPj00Nl8XNPFORlUFHfyrbjp52OYozpY6h9+mmqWgHg/jx6gP1iRaRIRLaISEj/YSgsLmdW1giyRsU7HcVx112SRmxUBKt3WBePMYHG1xdyx6lqPvA3wM9EZFJ/O4nIve4/DkU1NTU+juR9h2rOsru8Iey7ds5JiIlk8dQ01u6soLOr2+k4xphehlr0q0QkHcD9ubq/ndwLpaOqh4H3gNkD7Pe0quaran5qavAtOFJYXI4ILA/jUTt9FeRlUNvUzubDtU5HMcb0MtSivxq4y/34LuDPfXcQkZEiEuN+nAIsBPYM8XwBS1UpLC7n8gmjSBsW63ScgHH1lFQSYyKti8eYADOYIZsvApuBKSJSJiJ3Az8BlojIQWCJ+2tEJF9EnnG/9BKgSESKgXeBn6hqyBX9vRWNHKppsq6dPmKjXCydlsZbuytp6+xyOo4xxi3yQjuo6u0DPLW4n32LgHvcjz8CZniULgisLi4nMkJYNt26dvpakZfBH7efZNOBUyy5NM3pOMYY7I5cj5zr2rlicgqjEqKdjhNwFuakMDI+ym7UMiaAWNH3wKcnznDyTAsFM61rpz9RrgiWzUhn/Z4qmts7nY5jjMGKvkcKi8uJjoxg6TTruhjIirwMWjq62Li33wFexhg/s6I/RF3dypqSCq6dMpqk2Cin4wSsy7JHkTYsxrp4jAkQVvSH6OMjtdQ0ttmonQtwRQg3zcjgvf011Ld0OB3HmLBnRX+ICosriI92ce3UgWagMOcU5KXT3tXNut2VTkcxJuxZ0R+C9s5u3txVwZJL04iLdjkdJ+D1zEkUR6Etmm6M46zoD8FfSk9xprnDZtQcJBGhYGYGfyk9Re3ZNqfjGBPWrOgPQWFxOcNiI7lycvDNE+SUgrwMurqVtbusi8cYJ1nRv0itHV2s21PFsunpREfaj2+wpo5JYvLoRBvFY4zDrGpdpHf3VXO2rZMVs6xr52KICAV5GWw9WkdFfYvTcYwJW1b0L1JhSTkpiTHMn5jsdJSgs3xmOqrwhl3QNcYxVvQvwtm2TjbureamGWNwRYjTcYLOxNREpmcOsy4eYxxkRf8irN9TSVtnt92Q5YEVeRkUl9VzrLbJ6SjGhCUr+hehsLiCzBFxzBk30ukoQesm9+R0a6yLxxhHWNEfpDPN7Ww6UMPymelEWNfOkGWOiCN//EhbUcsYhwxm5aznRKRaRHb12jZKRNaLyEH3536bviJyl3ufgyJyV3/7BIs3d1XS2a3WteMFK2ZlsL+qkf2VjU5HMSbsDKal/xvghj7bfgBsVNXJwEb3158hIqOAHwGXA/OAHw30xyEYFBaXMzElgWkZw5yOEvSWTU8nQmBNibX2jfG3CxZ9Vd0E1PXZfDPwvPvx88At/bz0emC9qtap6mlgPZ//4xEUqhta2Xy4luV5GYhY146nUpNi+MKkFFYXl6OqTscxJqwMtU8/TVUrANyf+5tqMhM40evrMve2zxGRe0WkSESKampqhhjJd9burEAVCmbaOrjeUpCXzrHaZnaerHc6ijFhxZcXcvtrEvfbrFPVp1U1X1XzU1MDbz6b1cXlPdMIpCU5HSVk3DAtnSiX2Jh9Y/xsqEW/SkTSAdyf+1sLrwzI6vX1WCDo/oefqGtm+/EzNu2Clw2Pj+Kq3FTWlFTQ3W1dPMb4y1CL/mrg3Gicu4A/97PP28BSERnpvoC71L0tqLyxs2c8uS1+7n0FeRlU1LdSdOy001GMCRuDGbL5IrAZmCIiZSJyN/ATYImIHASWuL9GRPJF5BkAVa0D/gXY6v74sXtbUFm9o9y9CEi801FCznWXpBEbFWFdPMb4UeSFdlDV2wd4anE/+xYB9/T6+jnguSGnc1hp9Vn2VDTww+WXOh0lJCXERLL4kjTW7qzgRwWXEumyewWN8TX7X3Yea0rKEYGbbNSOzxTMzKC2qZ2PDtU6HcWYsGBFfwCqSmFxOZdPGEXasFin44Ssq6ekkhQTaV08xviJFf0B7Klo4FBNk0274GOxUS6WThvDW7sraevscjqOMSHPiv4ACosriIwQlk23rh1fK8hLp7G1k00HTjkdxZiQZ0W/H+e6dq6YnMKohGin44S8hTkpjIyPYrV18Rjjc1b0+7H9+BlOnmmxsfl+EuWK4MYZ6WzYU0Vze6fTcYwJaVb0+1FYXE50ZARLp6U5HSVsFORl0NLRxca9/d3cbYzxFiv6fXR1K2/srODaKaNJio1yOk7YuCx7FGnDYmwUjzE+ZkW/j48P11LT2GajdvzMFSEsn5nBe/trqG/pcDqOMSHLin4fhSXlJES7uHZqf7NFG18qyMugvaubdbsrnY5iTMiyot9Le2c3b+6qZMmlacRFu5yOE3byxg4na1QchbZoujE+Y0W/l7+UnuJMc4d17ThERCiYmcFfSk9Re7bN6TjGhCQr+r2sLi5neFwUV04OvIVcwsWKWRl0dStrd1kXjzG+YEXfrbWji3W7K1k2fQzRkfZjccqUtCQmj060UTzG+IhVN7d391XT1N5lXTsOExEK8jLYerSOivoWp+MYE3I8Kvoi8oCI7BKR3SLyYD/PXy0i9SKyw/3xQ0/O50uri8tJSYxh/sRkp6OEvYK8DFThDbuga4zXDbnoi8h04FvAPCAPWC4ik/vZ9QNVneX++PFQz+dLja0dvLOvmptmjMEV0d967safJqQkMCNzuHXxGOMDnrT0LwG2qGqzqnYC7wNf9E4s/9qwt4q2zm5b/DyAFOSlU1xWz7HaJqej+FRHVzdrSsppabdppb2ts6ub1z89SWuH/Wx786To7wIWiUiyiMQDNwJZ/ey3QESKReRNEZnW34FE5F4RKRKRopqaGg8iDU1hcQWZI+KYnTXS7+c2/VvunuwulFv7bZ1dfOd32/nu7z/lpxsOOB0n5LxUdIIHX9rB7z8+7nSUgDLkoq+qe4F/A9YDbwHFQN8pErcD41U1D3gCeH2AYz2tqvmqmp+a6t/hkqeb2tl0oIblM9OJsK6dgJExIo7LskdSWBya/fqtHV3c93+2sW5PFTmjE3n+o6NUN7Q6HStktHZ08cTGUgBeLjqBqjqcKHB4dCFXVZ9V1TmqugioAw72eb5BVc+6H68FokQkxZNzettbuyvp7FYbtROACvIy2F/VyP7KRqejeFVzeyd3P7+V9w/U8L9uncGzd+XT1a384t1Sp6OFjN99fJzKhlZumpnOvspGdpc3OB0pYHg6eme0+/M44FbgxT7PjxERcT+e5z5fQK2AXVhczsSUBKZlDHM6iulj2fR0IqRngfpQ0djawdef28rmQ7U8tjKP2+eNY3xyAivzs3jxk+OUnW52OmLQa2rr5FfvlfKFScn86xdnEBMZwctFJ5yOFTA8Haf/mojsAQqB76jqaRG5X0Tudz//ZWCXiBQDPwdu0wB6n1Xd0Mrmw7Usz8vA/bfJBJDUpBgW5qSwurg8JN6e17d08LVnP2H78dP8/PbZ3Dpn7F+f+961OQjy1y4JM3TPbz7KqbPtPLJ0CsPjorhh+hi7oNuLp907V6rqpaqap6ob3dueVNUn3Y9/oarT3M/PV9WPvBHaW97YWYEqrMizdXADVcHMDI7VNrPzZL3TUTxS19TO3/x6C3vKG/jPr87564XqczJGxPHV+eN4dXsZR06F9oglX6pv6eCp9w9z7dTRzB3fMzBjVX4WDa2drNtT5XC6wBDWd+QWFpdzSfowckYnOR3FDOD6aWOIcklQj+KpaWzj9qe3UFp9lqfvnMvSaWP63e/bV+cQ7YrgZzaSZ8ie/fAI9S0dPLwk96/bFkxMJnNEHK9YFw8QxkX/RF0z24+focBa+QFteHwUV+WOZk1JBd3dwdfFU1nfylee3szxumb+6+uXcfWUgddpSE2K4esLs1ldXB5yF6/9oa6pnWc/OMyNM8YwPXP4X7dHRAgr88fyYekpu2ZCGBf9Ne5b/G3x88BXkJdORX0rRcdOOx3lopSdbmbVU5upbmjjt3fP4ws5Fx64dt+iiSRGR/L4+v1+SBhannr/EC0dXZ9p5Z/z5bk9109e23bS37ECTtgW/cLicmaPG0HWqHino5gLuO6SNGKjIoKqi+foqSZWPbmZM83tvHDP5VyWPWpQrxsRH809V07k7d1VlJSd8XHK0FHd0Mrzm49yy6zMfrtrx46MZ+GkFF7ZdiIo3zF6U1gW/dLqs+ypaLBWfpBIiIlk8SVprN1ZQWdXt9NxLqi0+iyrntpMS0cXv//WfGZljbio13/zimxGxkfx2Drr2x+sX75bSmeX8sB1/U3/1WNl/ljKTrew5XBAjRr3u7As+oXF5YjATTOtPz9YrMjLoLapnY8OBfZ/2H2VDdz29Ga6FV66b8Fn+pYHKyk2ivuvmsT7B2rYerTOBylDS9npZn7/yXFW5mcxPjlhwP2unzaGYbGRYT9mP+yKvqpSWFLO5RNGkTYs1uk4ZpCuyk0lKSYyoLt4dpbVc9vTW4iMiODl++aTmzb0UWF3LsgmJTGGR9/eHxL3KPjSExtLEYTvXZtz3v1io1zcPCuTN3dVUt/S4ad0gSfsiv6eigYO1zSxIi/T6SjmIsRGuVg6bQxv7a6krTPwbrLZduw0f/PMFhJjInn5vgVMTE306Hhx0S6+e80kPj5Sx19KA/vdjZOOnGri1e1lfHX+ODJGxF1w/1X5WbR1dgd048HXwq7ory4uJzJCuGF6/2OlTeBaMSuDxtZO3t/v/5lYz+fjw7Xc+ezHJCdE89J9CxiX7J3BAbdfPo6M4bH8+zpr7Q/kZxsOEO2K4NtXn7+Vf870zGFMHZMU1mP2w6roqypriiu4YnIKoxKinY5jLtIXJiUzKiGawgBaUeuDgzXc9V+fMGZ4LC/dt4DMQbQ2Bysm0sX3F0+m+MQZNu6t9tpxQ8X+ykZWF5fz9YXZpCbFDOo1IsKq/CyKy+rZVxmek7CFVdHffvwMJ8+0sMJm1AxKUa4Ilk0fw4Y9VTS3953F2/827q3i7ueLyE5O4KX7FvjkGtGX5o4lOzmeR9ftD/uhhn09vn4/idGR3Ldo4kW97pbZmUS5hFeKynyULLCFVdEvLC4nOjKCJZemOR3FDNGKvAxaOrocb/m+tauC+1/YxpS0JP5w73xSEgfX0rxYUa4IHrwul32VjazdFTjvcJy2s6yet3dXcfeVExgRf3Hv2kclRLPk0jT+9OlJ2jsDfwiwt4VN0e/qVt7YWcG1U0aTFBvldBwzRJdljyJtWAyrHbwQ9+cdJ/nO7z9lRuZwfvetyy+66FysgrwMctMSeXz9gaC4T8EfHl23nxHxUdx9xYQhvX5lfhZ1Te28sy/8JmELm6L/8eFaahrbbLGUIBcRISyfmcH7+2scGXb3insJvvzxI/nt3ZczzA8NCFeE8PCSXA7XNPH6jvAddXLO1qN1vH+ghvuvmjTkBtyiyamMGRbLy2HYxRM2Rb+wpJyEaBfXTh14wisTHAryMmjv6mbd7kq/nveFLcf4+1dLuCInhd98Yx6JMZF+O/f108YwPXMY/7HxQFh2SZyjqjz69n5SEmO4a0H2kI/jihBunZPJe/urqQqzZSo9XTnrARHZJSK7ReTBfp4XEfm5iJSKSImIzPHkfEPV3tnN2p2VLLk0jbholxMRjBfljR3OuFHxfu3iefbDI/zT67tYPHU0v74z3++/RyLCI0uncKKuJazvKP1LaS0fH6nju9dM8vjfYGV+Ft0Kr20Pr9b+kIu+iEwHvgXMA/KA5SLSd+KLZcBk98e9wK+Gej5PfFja0xVgXTuhQUQoyEvno0O1nDrb5vPz/fLdUv5lzR6WTR/Dr+6YS2yUMw2Hq3NTmTt+JE+8czAsV4FSVR5dt5+M4bHcfvk4j483ISWBedmjeLWoLKzug/CkpX8JsEVVm1W1E3gf+GKffW4Gfqs9tgAjRMTvE94UFlcwPC6KKyen+vvUxkcK8jLo6lbe3OW7Lh5V5fH1B/j3t/dz86wMnrh9NtGRzvWIigh/t3QKVQ1tvLDlmGM5nLJxbzU7Tpzh+4snExPpnT+8K/PHcvhUE9uCbNpuT3jyG7wLWCQiySISD9wIZPXZJxPo/V60zL3Nb1rau1i3u5Jl08c4+h/WeNfUMcPITUv02e30qspP3tzHzzceZFX+WB5fNYtIl/O/PwsmJbMwJ5lfvXeIpjbn71Xwl+5u5bH1BxifHM+X5o698AsG6cYZ6SREu8Kqy2zIv8Wquhf4N2A98BZQDPT9LexvtfHPvY8SkXtFpEhEimpqvHuL/bv7q2lq77KunRBUMDODrUfrqKhv8epxu7uVfy7cw1ObDnPH/HH85NaZuCL6+1V2xiNLp1Db1M5vPjrqdBS/Wburgr0VDTx0XS5RXvzjmxATyfKZGawpqQibP6KeLoz+rKrOUdVFQB1wsM8uZXy29T8W+FzTTFWfVtV8Vc1PTfVuF0xhcTkpiTHMn5js1eMa5y3Py0AV3vDitAzd3co/vr6T33x0lLuvmMC/3DydiAAq+ABzxo1k8dTRPPX+obCYLbKzq5vH1x9g8uhEnzTeVl02lub2Lt7YGR43v3k6eme0+/M44FbgxT67rAbudI/imQ/Uq6rffrKNrR28s6+a5TPTA6qlZrxjQkoCMzKHe62Lp7Orm797tZgXPznBd66ZxD/ddAkigfl78/DSXBpaO3n2g8NOR/G513eUc7imiUeW5vrk//GccSOZmJoQNpOwefo+6TUR2QMUAt9R1dMicr+I3O9+fi1wGCgFfg1828PzXZT1e6po6+y2xc9D2Iq8DIrL6jl6qsmj43R0dfPASzv44/aTPLIkl7+/fmrAFnyAaRnDuWlGOs9+eIRaP4xgckp7Zzf/sfEA0zOHcf0038yMe24Stq1HT3O45qxPzhFIPO3euVJVL1XVPFXd6N72pKo+6X6sqvodVZ2kqjNUtcgboQersLiczBFxzM4a6c/TGj86t/rZmpKht/bbOrv49u+280ZJBf/zxql8b/HAS+4FkoeWTKalo4unNoVua/+VbSc4UdfCI0un+PSP8K2zM3FFCK9sC/0x+84PR/CR003tfHDwFMvz0gOuT9Z4T8aIOC7LHklh8dB6DVs7urj3t9tYv6eKf14xjXsXTfJyQt/JGZ3ELbMzef6joyF5V2lrRxdPbCxl7viRXJ3r2+HWo4fFcs2UVF7bVhaWJNnxAAAWkklEQVTy8xuFbNF/c1clnd1qi5+HgRV5GeyvamR/ZeNFva65vZNv/mYrmw7W8JNbZ3DXF7J9E9CHHlycS1e38st3S52O4nW/+/g4lQ2t/J2PW/nnrMzPorqxjU0HA2uRHm8L2aJfWFzOxJQEpmUMczqK8bFlM9KJEC7qgm5jawd3PvsJWw7X8tjKPG6b5/kdnk4YlxzPqsuyePGT45SdbnY6jtc0tXXyn++WsjAnmQWT/DPy7tqpo0lJjOblraHdxROSRb+6oZUtR2pZnpcR0BfjjHekJMawMCeFwpLyQd1OX9/cwR3PfsKOE2f4+e2zuXWO9272ccL3rs1BRPj5xr4jpoPXbz46Sm1TO48sneK3c0a5Ivji7Ew27K0K6YvjIVn039hZgSqssFE7YaNgZgbHapvZebL+vPvVnm3j9l9vYW95A//51TksD4Huv/Thcdxx+Xhe234yJEaf1Ld08NT7h1g8dTRzxvl3EMbK/Cw6u5U/fXrSr+f1p5As+quLy7kkfRg5o5OcjmL85PrpY4hyCavPM998dWMrt/96C4dqzvL0nXNZ6qMhgE7426snEe2K4Gcbgr+1/+wHh2lo7eThpbl+P3duWhKzskbwctGJkJ2ELeSK/om6Zj49fsbG5oeZ4XFRXJU7mjUlFf2uJVtR38JtT23hRF0L//X1y7h6Smitq5CaFMPXF2ZTWFIe1At+155t49kPj3DTjHSmZQx3JMOq/CwOVJ2lpOz87xqDVcgV/TXuW/Jt1E74KchLp7KhlaI+MyaeqGtm1VObqW5s4//cPY8v5KQ4lNC37ls0kcToSB5fd8DpKEP21KbDtHR08dAS5+6VWJ6XTmxURMhOwhZyRX91cTmzx40ga1S801GMny25NI24KNdnRvEcOdXEV57aTH1zBy/cczn52aMcTOhbI+KjuefKiazbU0VJ2Rmn41y06oZWnv/oKLfMznS0a3ZYbBQ3Tk9n9Y5yWtpDb92CkCr6pdWN7K1osFZ+mIqPjmTxJaNZu7OCzq5uDlY18pWnNtPS0cXvvzWfWVkjnI7oc9+8IpuR8VE8FoSt/V+8W0pXt/JAANwRvTI/i8a2Tt7285Kc/hBSRb+wuAKR/74134SfgrwMapvaee4vR7jt6S10K7x03wKmZzrTP+xvSbFR3H/VJN4/UMPWo3VOxxm0stPNvPjJcVbmZzE+OcHpOFw+YRTjRsWHZBdPyBR9VaWwuJz5E5JJGxbrdBzjkKunpJIUG8m/rt1HlCuCl++bT25aeI3iunNBNqlJMfz72/uDZgTKzzceRET4/uIcp6MAEBEhrJw7lo8O1XKiLnRueoMQKvrH65o5Xtdsi6WEuZhIF1/Jz2JiSgIv37eAiamJTkfyu7hoF9+9JodPjtTxYekpp+Nc0OGas7y2/SRfvXwc6cPjnI7zV1+aOxYRQm4StpAp+uOTE/jkH6/j5llW9MPdP950CRsfuYpxyeF7Mf+2eVlkjojj0XUHAr61/7MNB4l2RfDtqwOjlX9Oxog4rpycyqtFJ+jqZxhwsAqZog8wKiGahJhIp2MYh4lI2E+/ERPp4vuLcyg+cYYNe6udjjOgfZUNFJaU8/WFPV1SgWbl3LGU17fy0aHAf8c0WCFV9I0x/+3WOWPJTo7nsXX7+71hLRD8dP0BEqMjuW/RRKej9GvJpWkMj4vi5aLQ6eLxdLnEh0Rkt4jsEpEXRSS2z/NfF5EaEdnh/rjHs7jGmMGKckXw0JJc9lU2snZX4K3/WlJ2hrd3V3HPlRMZER/tdJx+xUa5uGVWBm/vruRMc7vTcbxiyEVfRDKB7wP5qjodcAG39bPrS6o6y/3xzFDPZ4y5eMtnZpCblsjj6w8E3OIgj607wMj4KL55RbbTUc5rZX4W7Z3drPbSWsxO87R7JxKIE5FIIB4IjZ+KMSHCFSE8vGQKh2uaeP08k9H529ajdbx/oIb7r5pEUmyU03HOa3rmcC5NHxYyY/aHXPRV9STwKHAcqADqVXVdP7t+SURKRORVEcnq71gicq+IFIlIUU1NaK9aY4y/XT8tjRmZw/nZhgO0dzrf2ldV/v3t/aQmxXDngmyn4wzKqvyx7DrZwO7y4J+EzZPunZHAzcAEIANIEJE7+uxWCGSr6kxgA/B8f8dS1adVNV9V81NTfbsWpjHhRkR4ZGkuZadbAqK1+mHpKT45Usd3r8khLtrldJxBuXlWJtGuCF4JgQu6nnTvXAccUdUaVe0A/gh8ofcOqlqrqueWoPk1MNeD8xljhuiq3FTyx4/kiXcO0trh3CRiqsqj6w6QOSKO2+b1+8Y/II1MiGbJtDRe33GSts7gnoTNk6J/HJgvIvHSMyh6MbC39w4i0nsSnBV9nzfG+EdPa38KVQ1tvLDlmGM5NuytpvjEGb6/OIeYyOBo5Z+zKj+LM80dbAzg+x4Gw5M+/Y+BV4HtwE73sZ4WkR+LyAr3bt93D+kspmekz9c9zGuMGaIFk5K5IieFX713iKa2Tr+fv7tbeWzdfrKT44NyXeIrclJIHx4bEF1knvBo9I6q/khVp6rqdFX9mqq2qeoPVXW1+/l/UNVpqpqnqteo6j7vxDbGDMUjS3OpbWrnNx8d9fu51+6qYF9lIw9el0uUK/juC3VFCF+eO5ZNB2qoqG9xOs6QBd9P3hgzZLPHjeS6S0bz1PuHqG/p8Nt5O7u6eXz9AXLTEoN6UsQvzx1Lt8IftwfvwulW9I0JMw8tyaWhtZNnPjjst3O+vqOcwzVNPLwkF1dE8M6LND45gfkTRwX1wulW9I0JM9MyhnPTzHSe+/AItWfbLvwCD7V3dvOzDQeYnjmM66eN8fn5fG1VfhbHapv55EjwLFLTmxV9Y8LQQ9fl0tLRxVObfN/af7noBGWnW3hk6ZSQmP102fR0EmMig3YSNiv6xoShnNGJfHH2WJ7/6ChVDa0+O09rRxdPvHOQ/PEjuTo3NG68jIt2UZCXwdqdFTS2+u+6iLdY0TcmTD2weDJd3cov3y312Tle2HKMqoa2kGnln7MqfywtHV28URJ4s5deiBV9Y8LUuOR4Vl2WxYufHPfJOrBNbZ386r1DLMxJZsGkZK8f30mzskYweXRiUI7Zt6JvTBj73rU5iAhPvHPQ68f+zUdHqW1q55GlU7x+bKeJCKvys9h+/Ayl1Y1Ox7koVvSNCWPpw+O44/LxvLb9JIdrznrtuPUtHTz1/iEWTx3NnHEjvXbcQHLL7EwiIyToJmGzom9MmPv2NZOIdkXwsw3ea+0/88FhGlo7eXhprteOGWhSk2K4dupoXtt+ko4AW6DmfKzoGxPmUhJj+MbCbApLytlX2eDx8WrPtvHch0e4aUY60zKGeyFh4FqVn8Wps228tz941gGxom+M4b5Fk0iMieTxdQc8PtaT7x+ipaOLh5ZM9kKywHb1lFRSk2KC6oKuFX1jDMPjo/jWlRNZt6eKkrIzQz5OVUMrv918jFtmZ5IzOsmLCQNTpCuCW+dk8s6+aqobfXe/gzdZ0TfGAPCNhdmMjI/iUQ9a+794p5SubuXBxaHbl9/XyrlZdHUrr38aHJOwWdE3xgCQFBvF3149iU0HaoY0r8yJumb+sPU4qy7LYlxyvA8SBqac0YnMGTeCl4vKgmISNo+Kvog85F4kZZeIvCgisX2ejxGRl0SkVEQ+FpFsT85njPGtr83PJjUphkfX7b/oAvbEOwcREb53bY6P0gWuVflZlFaf5dMTQ+8a8xdPFkbPpGc1rHxVnQ64gNv67HY3cFpVc4CfAv821PMZY3wvLtrF967N4ZMjdXxYemrQrztcc5bXtp/kjsvHkz48zocJA9NNM9OJi3LxShBc0PW0eycSiBORSCAeKO/z/M3A8+7HrwKLJZQm4DAmBH3lsiwyR8Tx6LoDg27t/2zDQaJdEfzt1ZN8nC4wJcVGceOMdAqLK2hu9/9SlBfDkzVyTwKP0rNAegVQr6rr+uyWCZxw798J1AOfm4RDRO4VkSIRKaqpCZ7xrsaEophIFw8snkzxiTNsGMQi4PsqGygsKecbC3u6hsLVqvyxnG3r5M2dlU5HOS9PundG0tOSnwBkAAkickff3fp56eeaDqr6tKrmq2p+ampoTL9qTDC7dU4mE1ISeGzdfrq7z9/af3zdARKjI7l30UQ/pQtM8yaMIjs5PuDH7HvSvXMdcERVa1S1A/gj8IU++5QBWQDuLqDhQHAuN2NMGIl0RfDgdZPZV9nIGzsHnj64+MQZ1u2p4luLJjIiPtqPCQOPiLAyP4uPj9Rx9FST03EG5EnRPw7MF5F4dz/9YmBvn31WA3e5H38ZeEeDYUyTMYaCmRlMSUvipxsO0DnA3DKPrT/AyPgovrEw27/hAtStczKJEHh1W+BOwuZJn/7H9Fyc3Q7sdB/raRH5sYiscO/2LJAsIqXAw8APPMxrjPGTiAjhoSW5HK5p4k/93Hj0yZE6Nh2o4f6rJpEUG+VAwsCTPjyORbmpvLqtjK4LdIs5xaPRO6r6I1WdqqrTVfVrqtqmqj9U1dXu51tVdaWq5qjqPFX1/YKcxhivuX5aGjMyh/MfGw/S3vnfrX1V5dG395OaFMOdC7KdCxiAVuVnUdnQygcHA3NQit2Ra4wZkIjwyNJcyk63fOYC5Yelp/jkaB3fvSaHuGiXgwkDz+JLRjMyPipg59m3om+MOa+rclO5LHskT7xzkNaOrr+28jNHxHHbvCyn4wWcmEgXt8zOZN2eSuqa2p2O8zlW9I0x59XT2p9CVUMbL2w5xoa91RSX1fP9xTnERForvz8r52bR0aX8eUfgTcIW6XQAY0zgmz8xmSsnp/Cr9w6RnBhNdnI8X5oz1ulYAevSjGHMyBzOK0VlfGPhBKfjfIa19I0xg/Lwklxqm9o5UHWWh5bkEumy8nE+q/LHsqeigV0n652O8hn2r2aMGZTZ40Zy04x0ZmQOZ/nMDKfjBLwVeZlER0YE3CRs1r1jjBm0n98+G1XFFWHzJl7I8Pgobpg2htd3lPMPN15CbFRgXP+wlr4xZtBcEWLdOhdhVX4W9S0drN9T5XSUv7J/PWOM8ZEvTEomc0RcQE3CZkXfGGN8JCJC+PLcsXxYeoqTZ1qcjgNY0TfGGJ/68tyxqMJrATIJmxV9Y4zxoaxR8SzMSeaVbScuuDaBP1jRN8YYH1uVn8WJuha2HKl1OooVfWOM8bXrp40hKTYyICZhs6JvjDE+FhvlYkVeBmt3VtDQ2uFoFk/WyJ0iIjt6fTSIyIN99rlaROp77fNDzyMbY0zwWZWfRVtnN4XF5Y7mGPIduaq6H5gFICIu4CTwp352/UBVlw/1PMYYEwpmjh3OlLQkXi4q46uXj3csh7e6dxYDh1T1mJeOZ4wxIaVn4fSxFJ84w/7KRsdyeKvo3wa8OMBzC0SkWETeFJFpXjqfMcYEnS/OziQyQhydhM3joi8i0cAK4JV+nt4OjFfVPOAJ4PUBjnGviBSJSFFNTWCuK2mMMZ5KTozhukvS+NOnJz+z5rA/eaOlvwzYrqqfm1FIVRtU9az78VogSkRS+tnvaVXNV9X81NRUL0QyxpjAtOqysdQ2tfPOvmpHzu+Non87A3TtiMgYERH343nu8zl/d4Ixxjhk0eRURifFONbF41HRF5F4YAnwx17b7heR+91ffhnYJSLFwM+B21TV+fuQjTHGIZGuCL40dyzv7q+mqqHV7+f3qOirarOqJqtqfa9tT6rqk+7Hv1DVaaqap6rzVfUjTwMbY0ywWzl3LN0Kf9zu/4XT7Y5cY4zxs4mpiVyWPZJXik7g784PK/rGGOOAlflZHD7VxLZjp/16Xiv6xhjjgJtmpBMf7fL7qlpW9I0xxgEJMZEsn5nOmpIKmto6/XZeK/rGGOOQVflZNLd38cbOCr+d04q+McY4ZO74kUxMSfDrmH0r+sYY45CeSdiy2Hr0NIdrzvrlnFb0jTHGQV+ak4krQnjFTwunW9E3xhgHjR4Wy9W5qby2rYzOLt9PwmZF3xhjHLYyP4vqxjY2HfT9LMNW9I0xxmHXTh1NckK0XxZOH/JyicYYY7wjOjKCb14xgZb2Lp+fy4q+McYEgO9ck+OX81j3jjHGhBEr+sYYE0as6BtjTBgZctEXkSkisqPXR4OIPNhnHxGRn4tIqYiUiMgczyMbY4wZqiFfyFXV/cAsABFxASeBP/XZbRkw2f1xOfAr92djjDEO8Fb3zmLgkKoe67P9ZuC32mMLMEJE0r10TmOMMRfJW0X/NuDFfrZnAr2njytzb/sMEblXRIpEpKimxvd3pBljTLjyuOiLSDSwAnilv6f72fa5BSFV9WlVzVfV/NTUVE8jGWOMGYA3bs5aBmxX1ap+nisDsnp9PRYoP9/Btm3bdkpE+nYTXYwU4JQHr/enYMoKwZU3mLJCcOUNpqwQXHk9yTp+MDt5o+jfTv9dOwCrge+KyB/ouYBbr6rnXSJGVT1q6otIkarme3IMfwmmrBBceYMpKwRX3mDKCsGV1x9ZPSr6IhIPLAHu67XtfgBVfRJYC9wIlALNwDc8OZ8xxhjPeFT0VbUZSO6z7clejxX4jifnMMYY4z2heEfu004HuAjBlBWCK28wZYXgyhtMWSG48vo8q/Q0xo0xxoSDUGzpG2OMGUDIFH0RuUFE9rvn+fmB03nOR0SeE5FqEdnldJYLEZEsEXlXRPaKyG4RecDpTOcjIrEi8omIFLvz/rPTmS5ERFwi8qmIrHE6y4WIyFER2emeb6vI6TznIyIjRORVEdnn/v1d4HSmgQxmLjOvnSsUunfcc/8coGckURmwFbhdVfc4GmwAIrIIOEvPFBXTnc5zPu5pM9JVdbuIJAHbgFsC+GcrQIKqnhWRKOBD4AH3NCABSUQeBvKBYaq63Ok85yMiR4F8VQ34ce8i8jzwgao+476JNF5Vzzid60J6zWV2eT9T23gsVFr684BSVT2squ3AH+iZ9ycgqeomoM7pHIOhqhWqut39uBHYSz9TaQQK9zxPZ91fRrk/ArZlIyJjgZuAZ5zOEkpEZBiwCHgWQFXbg6Hguw00l5lXhErRH9QcP8YzIpINzAY+djbJ+bm7S3YA1cB6VQ3kvD8D/gfQ7XSQQVJgnYhsE5F7nQ5zHhOBGuC/3F1nz4hIgtOhBmmgucy8IlSK/qDm+DFDJyKJwGvAg6ra4HSe81HVLlWdRc+0H/NEJCC70ERkOVCtqtucznIRFqrqHHqmX/mOu6syEEUCc4BfqepsoAkI6Gt9cMG5zLwiVIr+Rc/xYwbP3Tf+GvA7Vf2j03kGy/12/j3gBoejDGQhsMLdT/4H4FoRecHZSOenquXuz9X0rJ8xz9lEAyoDynq9y3uVnj8Cge58c5l5RagU/a3AZBGZ4P5LeRs98/4YD7kvjD4L7FXVx53OcyEikioiI9yP44DrgH3Opuqfqv6Dqo5V1Wx6fmffUdU7HI41IBFJcF/Mx91VshQIyBFoqloJnBCRKe5Ni4GAHHzQx/nmMvMKb0y45jhV7RSR7wJvAy7gOVXd7XCsAYnIi8DVQIqIlAE/UtVnnU01oIXA14Cd7n5ygP+pqmsdzHQ+6cDz7hEQEcDLqhrwQyGDRBrwp552AJHA71X1LWcjndf3gN+5G4KHCfC5v/qby8wn5wmFIZvGGGMGJ1S6d4wxxgyCFX1jjAkjVvSNMSaMWNE3xpgwYkXfGGPCiBV9Y4wJI1b0jTEmjFjRN8aYMPJ/AWiRrXDp4PS4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test loop\n",
    "# test loss\n",
    "test_ls = []\n",
    "test_isCorrects = []\n",
    "with torch.no_grad():\n",
    "    for i, (xtest_batch, ytest_batch) in enumerate(test_loader):\n",
    "        ypred_batch = model(xtest_batch).view(ytest_batch.size())\n",
    "        test_ls.append(criterion(ypred_batch, ytest_batch).item())\n",
    "\n",
    "        # make a decision at 0.5\n",
    "        decision_batch = (ypred_batch > 0.5).type(ytest_batch.dtype)\n",
    "#         pdb.set_trace()\n",
    "        # collect isCorrects\n",
    "        isCorrect_batch = (decision_batch==ytest_batch).numpy()\n",
    "#         pdb.set_trace()\n",
    "        test_isCorrects.extend(isCorrect_batch)\n",
    "        \n",
    "f,ax = plt.subplots()\n",
    "f.suptitle('Test batch loss')\n",
    "ax.plot(test_ls)\n",
    "print('Avg test batch loss:', np.mean(test_ls))\n",
    "print('Test accuracy: ', sum(isCorrects)/len(isCorrects))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
