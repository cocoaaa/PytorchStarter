{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Processing (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images\n",
    "import skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as plib\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6]); print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast-cancer-wisconsin.data.csv  names_train.csv.gz\n",
      "diabetes.csv.gz                   \u001b[1m\u001b[34mprocessed\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[34mdogscats\u001b[m\u001b[m/                         \u001b[1m\u001b[34mraw\u001b[m\u001b[m/\n",
      "dogscats.zip                      shakespeare.txt.gz\n",
      "names_test.csv.gz\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "An abstract class representing a Dataset.\n",
       "\n",
       "All other datasets should subclass it. All subclasses should override\n",
       "``__len__``, that provides the size of the dataset, and ``__getitem__``,\n",
       "supporting integer indexing in range from 0 to len(self) exclusive.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        - csv_file (string): path to the csv file\n",
    "        - root_dir (string): directory with all the images\n",
    "        - transform (callable, optional): optional transform to be applied to a sample\n",
    "        \"\"\"\n",
    "        all_data = pd.read_csv(csv_file, header=None)\n",
    "        self.data = np.array(all_data.iloc[:, 1:-1]) #ignore first column (patient ID)\n",
    "        self.target = np.array(all_data.iloc[:, -1].map({2:0, 4:1}))\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"returns a sample of format (feature 1,...,featureD, class)\"\n",
    "        return (self.data[idx, :], self.target[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './data/breast-cancer-wisconsin.data.csv'\n",
    "dataset = BreastCancerDataset(fpath, './data')\n",
    "a = dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, '1', 3, 1, 1], dtype=object), 0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.data.iloc[10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dataset[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(dirpath, fmt=None):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    - dirpath (Path object): directory to inspect\n",
    "    - fmt (string): file format including '.', eg: '.png', '.jpg', '.csv'\n",
    "    Returns a dictionary of counts for each filetype in dirpath\"\"\"\n",
    "    import collections\n",
    "    counts =  collections.Counter(f.suffix for f in dirpath.iterdir())\n",
    "    if fmt is None:\n",
    "        return counts\n",
    "    else:\n",
    "        return counts[fmt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCatDataset(Dataset):\n",
    "    def __init__(self, dirpath, animalType):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        - dirpath (Path object): path to a folder that contains \n",
    "        'dogs' and 'cats' subfolers. For instance, `data/dogscats/train` or \n",
    "        `data/dogscats/test`\n",
    "        - animalType (string): 'dog' or 'cat'\n",
    "        \n",
    "        Sample of this dataset will be a dictionary of {\"image\": img, \"class\": 0 or 1}\n",
    "        \"\"\"\n",
    "        self.animalType = animalType\n",
    "        self.animalClass = 0 if animalType == 'dog' else 1\n",
    "        self.full_dirpath = dirpath / (animalType + \"s\")\n",
    "        self.num_data = count_files(self.full_dirpath, fmt='.jpg')\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.full_dirpath / f'{self.animalType}.{idx}.jpg'\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader Rhythm\n",
    "1. Define custom dataset\n",
    "  - __init__(self): download, read data, etc\n",
    "  - __getitem__(self, idx): return one item on the index\n",
    "  - __len__(self): return the data length\n",
    "  \n",
    "  \n",
    "2. Creat a new dataloader instance by passing the custom dataset and batch size, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template custom Dataset class: [resource](https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel.html)\n",
    "Two python dictionary, `partition` and `labels`  \n",
    "- `partition['train']` = a list of string ids for training data points    \n",
    "  `partition['dev']` = a list of string ids for dev data points  \n",
    "  `partition['test']` = a list of string ids for test points  \n",
    "\n",
    "- labels:  `labels[somdID]` = label of the `someID` data point for someID in allIDs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. custom dataset\n",
    "class OldDiabetesDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "        self.x_data = xy[:,:-1]\n",
    "        self.y_data = xy[:, -1]\n",
    "        self.len = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"a sample is [x_data[idx], y_data[idx]]\"\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, ids):\n",
    "        # Ideally we wouldn't load all data here.\n",
    "        # Rather, read each file when __getitem__ is called\n",
    "        xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "        self.x_data = xy[:,:-1]\n",
    "        self.y_data = xy[:, -1]\n",
    "        self.len = xy.shape[0]\n",
    "        \n",
    "        self.ids = ids\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"Returns a sample in the format of [x_data[idx], y_data[idx]]\"\n",
    "        ID = self.ids[index]\n",
    "        return self.x_data[ID], self.y_data[ID]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the datapoint indices into train, dev, test groups.\n",
    "xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "labels = xy[:,-1]\n",
    "RSEED = 11\n",
    "from sklearn.model_selection import train_test_split\n",
    "tr_dev_ids, test_ids = train_test_split(labels, test_size=0.33, random_state=RSEED) #stratified \n",
    "train_ids, dev_ids = train_test_split(tr_dev_ids, test_size=0.5, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {'train': train_ids, 'dev': dev_ids, 'test': test_ids}\n",
    "train_dataset = DiabetesDataset(partition['train'])\n",
    "dev_dataset = DiabetesDataset(partition['dev'])\n",
    "test_dataset = DiabetesDataset(partition['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. new dataloader instance\n",
    "data_params = {'batch_size': 32,\n",
    "              'shuffle': True,\n",
    "              'num_workers':2}\n",
    "train_loader = DataLoader(dataset=train_dataset, **data_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
